[{"title":"LLM开发学习","url":"/post/f293a03a.html","content":"\n# 大模型如何完成工作？\n\n## 内在模型与提示词\n\n<!-- more -->\n\n**Q1:** 如何让大模型能够完成某个领域场景的实际工作，并且能够提升和干预效果？\n\n**A1**：从影响大模型的能力和效果的两个因素入手：\n\n* **模型**（内在）：可以理解为知识和能力的混合体。\n\n  经过微调的模型包含了学到的知识、逻辑，也包含执行具体某个任务的能力。\n\n  缺点：训练与更新需要大量的随时间和成本 -> 导致模型知识不够及时，变更困难，黑盒难控制，能力扩展难度高。\n\n* **提示词(prompt)** （外在）：可以理解为知识和指令的混合体\n\n  prompt作用：\n\n  * prompt可以给大模型直接表达需求 **(zero-shot)** \n  * 可以给它示例 **(few-shot)** 解释需求\n  * 可以一步步教它思考 **(chain of thought)** 一起完成需求\n  * 给它背景信息 **(context)** ，帮助其理解问题和回顾历史\n\n  因此，prompt有很好的灵活性和透明性，能够轻量级地完成很多工作。\n\n  但是，受限于大模型性能与成本，**prompt的大小有限**，加上每次请求都要携带大量信息来维持状态，在性能上也有一定缺陷。\n\n针对以上两个因素，可以做什么来 **干预模型** 呢？\n\n* 针对模型本身：**fine-tune**，微调，影响的是模型的权重\n\n  ![image-20240125135244030](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202401251355775.png)\n\n* 针对输入：**in-context learning**，即prompt learning\n\n  ![image-20240125135530980](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202401251355039.png)\n\n## 引入检索\n\n**Q2** ：目前提示词中包含很多内容，如何让大模型在海量的文章中总结回答？\n\n**A2**： 问题分析：\n\n1. 提示词包含很多内容 -> 受限与token大小\n2. 海量文章 -> 相应时间过长\n\n理想情况：能否不提高token数量，且需提升大模型推理？\n\n![image-20240125140209591](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202401251402664.png)\n\n解决：对prompt进行压缩提炼。\n\n常见做法：外部引入检索流程，增加一部粗筛召回的逻辑，减少候选范围。\n\n好处：\n\n* 精简了prompt\n* 给大模型界定了范围，一定程度上使得大模型能够在更可靠的知识内容基础上总结推理，提高了输入的可信度\n* 从提升模型返回角度上来看，增加检索流程，可以对提示词进行检索增强(RAG)，比如对接知识图谱，业务知识库，能够提高输出的质量\n\n\n\n## 检索方式选择\n\n目前业内主流的方式是采用 **向量检索** 来做检索增强。\n\n\n\n##  基本流程与相关技术\n\n### Tokenization与Embedding\n\n#### Tokenization\n\ntoken：作为模型的原始输入，是语义风格的最小单位。\n\ntoken可以是：一个单词，一个词根，一个标点等等\n\n对于LLM而言，外部输入或者训练的数据都是文本或文档，将其token化的过程就是tokenization.\n\n即tokenization为：将一段文本分割成单个的词语或标记的过程。\n\n如下：\n\n![image-20240125144002015](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202401251440064.png)\n\n对于英文，一个token一般对应4个字符或四分之三个单词；\n\n对于中文，token一般对应一个或半个词。\n\n不同的模型有不同的 **token限制** ，需要 **注意** 的是，此处的token限制，是 **输入的prompt和模型输出(completion)的token数之和** ，因此输入的prompt越长，输出的上限就越低。\n\n\n\n**temperature与token**\n\ntemperature：即准确性概率。想要高准确性则将其尽可能置小，需要创造性就可以调高，范围为[0-1]\n\n当我们不一定想选概率最大的token时，可以通过temperature来控制\n\n\n\n#### embedding\n\n作用：将token序列变成向量\n\n距离相近的向量 -> 有相近的含义\n\nembedding是对数据的压缩，且压缩的过程参考了语意和领域知识，可方便地进行相似性计算。\n\n\n\n### 向量数据库VectorDB\n\n相似性计算：向量的距离可以用来衡量两个向量的相似度。常见的方式：\n\n* 余弦距离：通过两个向量的夹角的余弦，来确定其相似性。\n\n  夹角为0：1， 90：0， 180：-1\n\n  所以其取值范围为：[-1, 1]\n\n* 欧式距离：两个点之间的连线距离\n\n* 向量内积\n\n向量数据库作用：\n\n* 检索增强：使用向量数据库做初筛，选择相似度高的候选材料，提供给大模型\n* 增加时效性\n* 提高可信度和溯源：基于向量数据库检索出来的资料回答\n* 隐私与权限问题\n* 多轮会话的context存储：大模型无记忆，可以通过向量数据库保存历史会话及上下文信息，每次对话将历史会话交给大模型，间接记忆。\n* 天生多模态：统一的向量格式存储，能够处理来自各种类型的数据源，例如文本、图像、音频、视频等。\n\n参考：\n\n[一文探秘LLM应用开发(4)](https://mp.weixin.qq.com/s?__biz=MzA5MTIxNTY4MQ==&mid=2461139684&idx=1&sn=152bbf6a8b1f365da36c8d0640262ff4&chksm=873960cab04ee9dcaf4d4c6857a5bb0fa118548dfb4a48bae27e005c16381a9b065f65e78bcd&cur_album_id=2959126655292211206&scene=189#wechat_redirect)\n\n\n\n### 微调finetune\n\n* 上游任务(upstream task)：无监督学习时做的任务\n* 下游任务(downstream task)：如情感分析，主体分类，文本生成\n\n**Q**： 如何弥合上下游任务之间的gap，对齐大模型能力和用户实际需求？\n\n**A**： 根据大模型的特点：如训练成本高，以及利用大模型学习到的知识的初衷，有一个较直接的做法是：\n\n设计不同目标的下游任务来和大模型组合起来一起完成具体的任务。该过程即为：目标函数挖掘(Object Engineering)。\n\n根据此思路：\n\n1. 收集训练该领域任务需要的标注数据，重新学习，从而使模型具备该领域任务的能力。\n2. 同时，学习特定领域知识时，之前在预训练中学到的知识不能忘记\n3. 即将大模型的参数作为初始参数来学习，从而使其在保留历史知识和能力的基础上，又能适配下游任务具体的要求。此过程即为**微调(finetune)** \n\n即整体过程为：预训练(pretrain) + 微调(finetune)\n\n微调的**本质作用** 即为：通过调整模型的权重来更好地拟合数据，从何提高LLM在特定任务或领域的性能。\n\n\n\n**问题** ：每种任务都做一个适配任务，太麻烦\n\n**Q** ：能否改变大模型适配下游任务的路线，让任务适配大模型，采用统一的模式处理不同任务？\n\n**A**： 通过构建合适的prompt来适配大模型做不同任务。\n\n以GPT(Generative Pre-trained Transformer)为例，可以将具体问题变成大模型的文字接龙的方式来激发模型完成任务。\n\n如：情感分析问题，输入：\n\n````text\nI love this movie. It is [MASK]\n````\n\n则其会基于学到的知识补全为good，然后再将good这样的标签映射(Verbalizer)为\"positive\"，以此完成情感分析。\n\n整个过程无需修改模型参数，大模型一直在做自己擅长的文字接龙。\n\n**zero-shot 与 few-shot**\n\n![image-20240125160127999](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202401251601094.png)\n\n`zero-shot`：直接输入需求\n\n`few-shot`：先输入示例学习，然后输入需求\n\n**总结**：将下游任务统一为一种模式，可以通过提示词学习(prompt learning / in-context learning)，仅需少量数据(few-shot)或者无需数据(one-shot)，即可完成下游工作\n\n\n\n同时，在微调阶段，通过基于任务指定样例进行监督学习(instruct tuning指令微调)，可以使大模型以zero-shot的方式回答用户，甚至可以读懂样例中未出现的新指令类型（泛化性），并生成正确答案。\n\n\n\n问题：模型越来越大，全量参数微调难以工作。\n\n\n\n#### 参数高效微调PEFT(Parameter-Efficient FineTuning / Delta Tuning)\n\n参数高效微调：希望使用少量的参数以逼近全量参数微调的效果\n\n实现思路：区别于原来全量微调，\n\n1. 固定原有模型参数，只微调变化的部分(少量参数, delta parameters)，从而减少计算成本和时间。\n2. 同时，只存储微调部分的参数，而不保存全部模型，减少存储空间。\n\n三个方向：\n\n* **增量式(Addition-based)** ：增加原始模型中不存在的额外可训练神经模块或参数。\n\n  * [具体类型参考](https://mp.weixin.qq.com/s?__biz=MzA5MTIxNTY4MQ==&mid=2461139904&idx=1&sn=172e92206322ce3c8077e5cdff70502a&chksm=873961eeb04ee8f85bc49cafa1c462f5e0b3eef4ba4a02425118eea7373251a98665e9931996&cur_album_id=2959126655292211206&scene=189#wechat_redirect)\n\n* **指定式(Specification-based)** ：指定原始模型中的特定的某些参数可训练，其余参数被冻结\n\n* **重参数化(Reparameterization)** ：用低维子空间参数来重参数化原来存在的参数，以减少计算量。\n\n  重参数化方法往往基于一类相似的假设：即预训练模型的适配过程本质上是低秩或者低维的。大白话讲，就是对它先进行精简计算然后再适配回原有结构并不会对模型影响很大。\n\n**注**：全量微调在大部分情况下还是效果最好的，因此，参数高效优化更多是一种折衷。\n\n[微调相关工具推荐](https://mp.weixin.qq.com/s?__biz=MzA5MTIxNTY4MQ==&mid=2461140122&idx=5&sn=ffa1be89a5285a0938c8e8736da0aed9&chksm=873966b4b04eefa26e66d2ec2c603f065457185b5dc6d4872d74894c3c108e9532148bd65818&cur_album_id=2959126655292211206&scene=189#wechat_redirect)\n\n\n\n### Prompt\n\n#### In-context learning\n\n除了问题描述之外，提供环境信息、输入、预期输出等信息，以上附加信息即为上下文(context)。\n\n对于模型来讲，我们仍然可以以这样人类熟悉的方式与模型进行交互，让它按照我们的预期工作，这就是上下文学习（In-Context-Learning），缩写为ICL。\n\n上下文学习是一种智能涌现(emergence)，其发生的前提是它拥有了和人类似的思维模式。\n\n模型发生智能涌现可能的原因是当学习的资料及模型参数规模大到一定程度（10B以上），引发了质变，从而将模型中本来蕴含的知识和逻辑激发出来，表现出了智能。\n\n总体而言，ICL的**作用** 为：允许语言模型通过以演示的形式组织若干个示例或指定来学习任务。即类比学习。\n\n形式：\n\n* **zero-shot**：不提供上下文，只提供问题或 需求\n\n  注：未提供示例，但是可以提供其他限定约束信息，如：仅回答，无需解释\n\n* **one-shot**：提供一个例子\n\n* **few-shot**：提供多个示例\n\n\n\n**Q：**In-contetxt learning 只是给大模型提供上下文输入，并没有修改模型权重，为什么有效？\n\n**A：**（相关解释，可参考）\n\n* 提示示例会产生元梯度(meta-gradients)，这些元梯度会在推理时的前向传播过程中反映出来。而在微调时，示例实际上会产生真正的梯度，用于更新权重。因此，ICL可以取得与微调类似的效果。\n\n  >【Why Can GPT Learn In-Context? Language Models Implicitly Perform Gradient Descent as Meta-Optimizers】\n\n* 把In-context learning看作是一种隐式的贝叶斯推理。大模型在进行进行In-Context Learning时，可通过使用Prompt来 \"定位 \"它在预训练过程中学到的相关概念。从理论上讲，我们可以将其视为以Prompt为条件的潜在概念的贝叶斯推理，而这种能力来自于预训练数据的结构（长期一致性）。从这个角度讲，解释了角色扮演以及夸奖大模型的有效性，因为它影响到了条件概率分布。\n\n  > 【How does in-context learning work? A framework for understanding the differences from traditional supervised learning】\n  >\n  > 《 An Explanation of In-context Learning as Implicit Bayesian Inference 》\n  >\n  > 《Rethinking the Role of Demonstrations: What Makes In-Context Learning Work? 》\n\n\n\n**Q**： 如何提高In-context learning的学习能力？\n\n**A**： 指令学习(Instruct learning)，主要又有两方面可以提升：\n\n1. 提升模型的zero-shot能力，即不提供例子也能智能回答\n2. 让模型识别更多任务类型以及回答方式\n\n\n\n#### Instruct learning\n\n发生时间：微调阶段。所以一般也叫指令微调(IT)\n\n指定微调的**核心**：不是学习知识，而是学习更多的**任务类型以及回答方式和风格**。\n\n方式：通过构建指令格式的实例，然后以有监督的方式对大模型进行微调。\n\n作用：指令微调可以帮助LLM拥有更好的推理能力， 从而展现出**泛化到未见过任务**的卓越能力。也就是说，就算微调的指令中没有设计相关的任务，大模型在新任务上的表现也会优于微调之前。\n\n\n\n#### Chain of Thought(COT)\n\n使用场景：无需大模型一次性完成任务，而是通过一步步分解，推理来完成任务。\n\n作用：能使大型语言模型解决算术推理（arithmetic Arithmetic）、常识推理（commonsense Reasoning）和符号推理（ symbolic reasoning）等类型的复杂任务\n\n触发COT：不一定非要提供推理步骤示例，zero-shot同样管用，最简单的额方式是在prompt中增加\"Let's think step by step\"等相关字句即可。\n\n\n\n#### Self-consistency COT\n\n利用\"自一致性\"（self-consistency）的解码策略，以取代在思维链提示中使用的贪婪解码策略，也就是说让大模型通过**多种方式去生产答案** ，最后根据 **多次输出进行加权投票** 的方式选择一种最靠谱的答案。\n\n缺点：速度慢，资源消耗量大\n\n\n\n#### Least-to-Most\n\n思路：它在解决复杂问题时，先引导模型把问题拆分成子问题；然后再让大模型逐一回答子问题，并把子问题的回答作为下一个问题回答的上文，直到给出最终答案。\n\n即是一种 **循序渐进** 引导大模型解决问题的方式。\n\n使用：可以在prompt中增加如\"what subproblems must be solved before answering this inquiry\"之类的提示\n\n\n\n#### Self-Ask\n\n与Least-To-Most类似，对于一个大模型没有在训练时直接见到的问题，通过诱导大模型以自我提问的问题，将问题分解为更小的后续问题，而这些问题可能在训练数据中见到过，这样就可以通过自问自答的方式，最终获得正确答案。\n\n使用：通过构建prompt示例，给出所有的follow up questions\n\n![图片](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202402010936562.png)\n\n\n\n#### Meta-prompting\n\n思路：使用大模型写Prompt，然后用其提供的Prompt再去提问，从而获得效果改进。\n\n[示例](https://chat.openai.com/share/77c59aeb-a2d6-4df8-abf6-42c8d19aba3d)\n\n\n\n#### Knowledge Generation Prompting\n\n方式：通过知识生成来增强Prompt，提升大模型的效果。\n\n基本思路：\n\n1. 基于问题让大模型给出问题的相关知识\n2. 再将知识整合到问题中，从而让大模型给予 **更细致有针对性** 的回答。\n\n\n\n#### Iterative Prompting\n\n迭代型提示：与大模型交互时，不要将其看作时独立的过程，而是将前一次的回答作为上下文提供给大模型。\n\n作用：可以有效提高模型信息的挖掘能力，并消除一些无关的幻觉。\n\n\n\n#### Tree of Thoughts(TOT)\n\n![图片](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202402010936829.png)\n\nTOT是在COT(Chain of Thought)之上的扩展，并能够探索连贯的子步骤（思维），作为解决问题的中间步骤。\n\nCOT：和大模型的一次交互，但是复杂问题一次无法解决。\n\n可以诱导大模型将复杂问题拆分成多层的树结构，每一步选择都以树的模式(BFS / DFS)动态选择最合适的路径。其允许大模型通过考虑多种不同的推理路径和自我评估选择来决定下一步行动方案，并在必要时前瞻或回溯以做出全局选择，从而尽心深思熟虑的决策。\n\n基本过程如下：\n\n1. 系统将问题分解，并生成一个推理”思维“候选者的列表\n2. 对以上思维进行评估，系统衡量每个想法产生所需解决方案的可能性\n3. 最后对方案进行排序\n\n\n\n#### Graph of Thoughts(GOT)\n\n将这个结构变成DAG，进一步完善推理过程。\n\n相比于TOT，主要变化为：\n\n* 聚合：将几个想法融合成一个统一的想法\n* 精化：从单个思想进行连续迭代，以提高其精度\n* 生成：有利于从现有思想中产生新的思想\n\n\n\n#### Algorithm-of-Thoughts(AoT)\n\nTOT与GOT的问题：会与大模型产生多次交互，从而导致高昂的运算成本，整体交互逻辑也比较复杂。\n\n如何尽量减少对大模型的查询交互，甚至将迭代过程直接放在大模型内部完成？ - > AOT\n\n实现方式：通过使用算法示例\n\n\n\n#### Program-aided Language Model(PAL)\n\n大模型问题：不擅长数学计算与逻辑执行\n\n思路：让大模型根据问题生成解决该问题的程序，然后将程序放在python等程序解释器上运行，从而产生实际的结果。\n\n但是目前，普通的数学应用题，大模型无需外部支持也能算对，所以PAL的使用场景变为复杂的数据分析和工具、API接口调用等场景。\n\n\n\n#### Retrieval Augmented Generation(RAG)\n\n通过检索方式，将问题相关背景知识作为上下文一并传给大模型，以便有效地提高模型准确性以及减少幻觉。\n\n工作流程：\n\n1. 用户向LLM应用提出问题\n2. 基于问题再数据库中检索出相关问题\n3. 将检索出的top n 数据传给LLM应用，LLM应用基于用户问题以及检索到的相关信息进行合并形成最终的prompt、\n4. 将prompt提交给大模型\n5. 大模型产生输出返回给LLM应用，进而返回给用户。\n\n使用RAG架构的LLM应用，好处：\n\n* 破解prompt learning受限context window的问题\n* 能够尽量减少大模型幻觉带来的问题\n* 减少了为了微调而准备问题对，大大减少了复杂度\n* prompt构造过程的操作空间大，为后续干预模型结果，完成特定业务需求提供了必要手段。\n\n\n\n#### prompt的问题\n\n* context window限制，即token长度限制\n\n* prompt的技巧性、繁琐性、稳定性问题\n\n* prompt的安全及权限隔离问题：如何防止大模型被利用与被攻击？\n\n  提供攻击：通过包装好的提示，欺骗大模型执行非预期的操作。主要有以下三类：\n\n  * 提示注入：将恶意或非预期内容添加到提示中，以劫持语言模型的输出。\n  * 提示泄露：从LLM的响应中提取敏感或保护信息\n  * 越狱：绕过安全和审查功能\n\n\n\n\n\n\n\n","tags":["LLM","prompt","tokenization","向量数据库","微调"],"categories":["Learning","LLM"]},{"title":"向量数据库的非必要性","url":"/post/b32394ab.html","content":"\n# 向量数据库的非必要性\n\n检索增强RAG（Retrieval Augmented Generation)\n\n1. 快速在全部潜在文档中搜索一小部分相关文档\n   * 确定相关文档子集：向量嵌入，最邻近搜索\n2. 将这部分文档内容加入到模型的提示信息中，再将其发送给LLM\n\n\n\n向量数据库：存储和计算大量文档的最近邻信息\n\n向量数据库问题：\n\n* 数据一致性\n* 有限的查询语言\n\n\n\n<!-- more -->\n\n实施RAG时，不一定使用向量数据库。即用向量嵌入来改进检索效果，但同时不必依赖于向量数据库。\n\n\n\n* 向量嵌入\n* BM25：计算query与文档相似度得分 -> 是关键字搜索\n\n召回率差距不大，但是维护向量数据库与嵌入式向量有成本\n\n\n\n优化：使用向量重排BM25\n\n可以先用BM25提取前50个结果，然后用向量嵌入对其进行重排。\n\n即使用向量嵌入作为后期过滤器，所以只需一个向量检索服务（任何KV存储），就可以对少量向量进行高效且精确的 k-NN （k最邻近）重排。无需向量数据库。\n\n\n\n参考：\n\n[向量数据库不是必须的](https://mp.weixin.qq.com/s/VifnL0oiK6sC5EGs9YIzPQ)\n\n[向量数据库（第 2 部分）：了解其内部结构](https://juejin.cn/post/7270864903014416418)\n\n\n\n\n\n# 改进召回（Retrieval）与引入重排（Reranking）\n\nllamaindex的思路与实现：\n\n### 基于LLM的召回或重排\n\n概念：使用LLM来决定哪些文档/文本块与给定查询相关。\n\n为避免大文档chunk化带来的内容分裂，在建库阶段可做一定优化，利用smmary index对大文档进行索引。\n\n* prompt：由一组候选文档组成（重要）\n* LLM的任务：选择相关的文档集，并使用内部指标对其进行相关性评分。\n\n召回过程可以执行多次，形成批次，可以更大范围召回相关文档，然后将每个批次的召回结果打分进行汇总，获取最终的候选文档。\n\nllama-index提供两种形式的抽象：\n\n* LLM Retriever(ListIndexLLMRetriever)（作为独立的检索模块）\n\n  * 模块定义：通过列表索引定义。\n\n    列表索引：将一组节点存储为一个平面列表\n\n    使用：在一组文档上建立列表索引，然后使用LLM检索器从索引中检索文档\n\n  * 作用：通过该召回模式，可以替代传统的向量检索模式。\n\n  * 缺点：比较慢，适合召回文档比较少的情况，但是可以省去重排阶段。\n\n* LLM Reranker(LLMRerank)（重排模块）\n\n  * 本方案的典型实现，被定义为NodPostProcessor抽象的一部分\n  * 作用：用于初始检索传递后的第二阶段处理。\n  * 后处理器可以单独使用，也可以作为RetrieverQueryEngine调用的一部分使用\n  \n\n基于LLM的召回或重排的问题：\n\n* 速度慢\n\n* 增加了LLM的调用成本\n\n* 由于打分是分批进行的，所以存在着无法全局对齐的问题\n  \n  \n  \n### 基于相对轻量的模型和算法\n\n是LLM模式的一种简化，采用BM25，Cohere Rerank等方法对召回结果进行粗排，在效果和性能上取得折中。\n\n\n\n### 基于规则\n\n在粗排阶段，粗排模型可以使用一些规则替代，有时候高质量的规则会有更好的表现。\n\n在Llamaindex中可以设置后处理器(postprocessor)，其可以在索引返回结果后修改查询结果。\n\n在Llamaindex中，Postprocessor可以联合使用，形成链式规则\n\n  \n\n参考：\n\n[改进召回（Retrieval）和引入重排（Reranking）提升RAG架构下的LLM应用效果](https://mp.weixin.qq.com/s/QdBynJnV2S1Rc0LUjzCuLw)\n\n  \n\n  \n","tags":["LLM","向量数据库","检索增强","改进召回","引入重排"],"categories":["Learning","LLM"]},{"title":"LLM Agent","url":"/post/a3856614.html","content":"\nAgent功能：给定既有目标或复杂任务，让机器自己去思考如何分解完成，整个过程无需人类参与。是一种高度主动的自主行为。\n\n\n\n<!-- more -->\n\nAgent与RAG等LLMChain的本质区别：\n\nLLMChain的解决问题的核心流程：人确定的，LLM在过程中只起到局部作用\n\nAgent解决问题：整个流程都是AI自主确定，LLM在其中其决定性作用。AI-Native\n\nLangchain对Agent的定义：\n\n> The core idea of agents is to **use an LLM to choose a sequence of actions to take**.\n>\n> In chains, a sequence of actions is **hardcoded(in code)**.\n>\n> In agents, a **language model** is used as a reasoning engine to determine which actions to take and in while order.\n\n![image-20240201093547959](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202402010935105.png)\n\n**注**：Agent不是算法，而是一种基于LLM的工程实现。其核心依托于LLM的能力，通过外在的prompt来激发大模型的规划推理等智能能力，\n\n\n\n## 架构\n\n### 架构1\n\n![image-20240201095200531](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202402010952593.png)\n\nAgent大致组成可以看作如上：\n\n* **Brain大脑**：记忆、决策、推理、规划\n* **Perception感知**：感知与处理外部环境的多模式信息\n* **Action行动**：使用工具以及影响周围环境\n\n一般而言，Agent工作流程如下：\n\n1. 感知模块感知外部环境，将多模式信息转换为可被Agent理解的表达\n2. 大脑Brain草鱼信息处理活动，如思考、决策、记忆以及知识的存储操作\n3. 行动模块在工具的帮助下执行，并对周围环境产生影响\n\n\n\n#### Brain\n\n功能：记忆、决策、推理、规划\n\n**记忆**\n\n存储了Agent的相关知识以及过去的观察、行动序列等\n\n* 短期记忆：以上下文会话为主。一般作为context提供给大模型\n* 长期记忆：以知识内容为主。通常存储在外部存储中，如向量数据库，按需检索。\n\n**存在的问题**：\n\n* 记忆容量有限，短期记忆长度突破模型context window会导致记忆截断\n  * 解决方案：提高上下文长度，总结提炼记忆内容，利用向量等数据结构压缩记忆\n* 长期记忆检索困难\n  * 解决方案：检索指标：近期性、相关性、重要性。最终召回结果由这些指标加权排序获得。\n\n\n\n**推理与规划**\n\n是大模型智能涌现的结果。\n\n能力激发方式：prompt技术\n\n\n\n#### Perception感知\n\n功能：多种模态信息的输入。包含文本、图像、声音等输入读取。\n\n\n\n#### Action\n\n功能：Agent的文本输出、工具利用\n\n大模型对工具的利用包含三个方面：\n\n* 学习工具\n* 使用工作\n* 制作工具\n\n\n### 架构2\n工业界，Agent可以表示为：\n\nAgent = LLM + Planning & Reasoning(规划&推理) + Tool Use + Memory\n\n代表架构：\n\n![image-20240201104630030](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202402011046108.png)\n\n<center style=\"font-size:14px;color:#C0C0C0;text-decoration:underline\">Overview of a LLM-powered autonomous agent system. <h href=\"https://lilianweng.github.io/posts/2023-06-23-agent/\">Image source:Lil'Log</h></center> \n\n目前的Agent实现，常见的有两类（其理论基础都来自于Prompt技术）：\n\n* Re-Act\n* Plan-Execute\n\n\n\n### Re-Act\n\n基本工作模式：基于问题一步步分析推理，每一步都思考(Reasion)产生一个动作(Action)，获得反馈后，进一步思考，得到下一步返回，直到解决问题。\n\nReAct的prompt格式大致如下：\n\n````yaml\nThought: ...\nAction: ...\nObservation: ...\n... (Repeated many times)\n````\n\n\n\n对其进一步改进的是：Plan-And-Solve。\n\n其思维过程更加像人，大致过程如下：\n\n1. 首先不着急生成下一步动作，而是对问题进行拆解，生成待执行任务列表\n2. 分步执行，并根据实际情况，不断完善更新整个执行计划。\n\n\n\n","tags":["LLM","Agent"],"categories":["Learning","LLM"]},{"title":"LangChain","url":"/post/ba778c11.html","content":"# LangChain\n\n作用：用于开发由语言模型驱动的应用程序的框架。\n\n主要能力：\n\n* 可以将LLM模型与外部数据源进行连接\n* 允许与LLM模型进行交互\n\n<!-- more -->\n\n基础功能：\n\n* LLM调用：支持多种模型接口、用于测试的Fake LLM, 缓存的支持，用量记录，流模式\n* Prompt管理：支持各种自定义模板\n* 拥有大量文档加载器：如Email, markdown, pdf...\n* 对索引的支持：\n  * 文档分割器\n  * 向量化\n  * 对接向量存储与搜索\n* Chains:\n  * LLM Chain\n  * 各种工具Chain\n  * LangChainHub\n\n\n\n## 概念解析\n\n### Loader 加载器\n\n作用：从指定源进行数据加载\n\n\n\n### Document 文档\n\n使用loader读取到数据后，数据源需转换成Document对象，方便后续使用。\n\n\n\n### Text Splitters 文本分割\n\n作用：用于分割文本。\n\n**Q: 为什么需要进行文本分割？**\n\n**A：**将文本当作prompt发送给api，或者使用其embedding功能，都有字符长度限制，所以需要将文本进行分割。\n\n\n\n### Vectorstores 向量数据库\n\n数据相关性搜索本质：向量运算\n\n所以需要将加载进来的Document进行向量化，将其存储到对应的向量数据库中。\n\n\n\n### Chain 链\n\n可以将其理解为任务，一个Chain就是一个任务。\n\n是对组件调用的序列，也可以包括其他链。\n\n\n\n\n\n### Agent 代理\n\n**作用**：可以理解为其可以动态选择和调用chain或已有的工具\n\n![image-20240118144044926](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202401181440013.png)\n\n**代理类型**：\n\n* 动作代理：决定要采取的动作，并逐个执行这些动作。\n  * 适用于小型任务\n* 计划和执行代理：先制定一套要采取的行动计划，然后逐个执行这些行动。\n  * 复杂长时间任务，初始规划有助于保持长期目标和专注。\n\n\n\n**相关概念解析**：\n\n* 代理程序(Agent)：应用程序的逻辑所在。提供了一个接口，接受用户输入以及代理程序已经执行的步骤列表，并返回代理动作(AgentAction)或代理结束(AgentFinish)\n  * 代理动作：对应要使用的工具以及该工具的输入\n  * 代理结束：表代理程序已完成，并包含向用户返回的信息\n* 工具(Tools)：代理程序可以执行的操作。提供的工具高度取决于代理程序要执行的任务\n* 工具包(ToolKits)：为特定用例设计的工具组合。\n* 代理执行器(Agent Executor)：包装了一个代理程序和一组工具 。负责循环迭代运行代理程序，知道满足停止条件为止\n\n\n\n**构建代理的典型方法：**\n\n* PromptTemplate：负责接收用户输入和先前步骤，并构建要发送给语言模型的提示\n* 语言模型：接收PromptTemplate构建的提示，并返回一些输出\n* 输出解析器：将以上语言模型的输出解析为AgentAction或AgentFinish对象\n\n\n\n**代理类型**\n\n* **zero-shot-react-description**：使用 *ReAct* 框架根据工具的 `描述 description` 来决定使用哪个工具。可以提供任意数量的tools, 每个tool都需要都描述。**无记忆**。\n* **conversational-react-description**：类似zero-shot，但是有记忆\n* **react-docstore**：使用ReAct框架与文档存储进行交互。必须提供以下两个工具：\n  * Search工具：搜索相关文章\n  * Lookup工具：在检索到的文章中找到相关的信息块\n* **self-ask-with-search**：查找问题的事实性答案。\n\n\n\n### Embedding嵌入\n\n作用：将一个内容实体映射为向量，从而获得内容之间的相似度。用于衡量文本的相关性\n\n使用场景：根据用户提供的语料片段与prompt内容计算相关度，然后将最相关的语料片段作为上下文放到prompt中，以提高completion的准确率\n\n\n\n### fine-tuning 微调\n\n作用：在不改动模型的基础上，在顶层增加特性映（提供上下文），使微调后的模型更符合实际情况。\n\n主要目的：节省每次 completion 提供相同 prompt 的 tokens，把类似的 prompt 可以训练成: 只需要更改具体问题，而不用重复写 context、example.\n\n使用场景：\n\n* 想让模型按照某种格式来识别prompt，或按照某种格式回答。\n* 想让模型按照某种语气、性格来回答\n* 想让回答的completion具有某种倾向\n\n对大量数据进行fine-tuning，训练后的模型，按照prompt格式书写，则completion会自动按照期望的格式返回。\n\n类似于Masked Language Modeling(MLM)，系统会将回答识别为「答案: [mask] 」，模型去预测 mask 的内容，或者理解为「完形填空」\n\n\n\n相比于fine-tuning最大的优势为：不用进行训练，并且可以实时添加新内容，不用加一次就训练一次，各方面成本都低于fine-tuning\n\n\n\n\n\n参考：\n\n[快速了解 OpenAI 的 fine-tune 和 Embedding 能力](https://zhuanlan.zhihu.com/p/609359047)\n\n[LangChain 中文入门教程](https://liaokong.gitbook.io/llm-kai-fa-jiao-cheng/)\n\n[Langchain 代理 (Agents) ，赋能超级 LLMs](https://zhuanlan.zhihu.com/p/639479632)\n\n\n\n\n\n\n\n","tags":["LLM","LangChain"],"categories":["Learning","LLM"]},{"title":"MySQL锁","url":"/post/d940f18d.html","content":"# 锁\n\n![image-20240201152603455](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202402011526617.png)\n\n<!-- more -->\n\n## 按粒度\n\n### 全局锁\n\n**定义**：即对整个数据库实例加锁\n\n**应用场景**：全库逻辑备份(`mysqldump`)\n\n**实现方式**：mysql提供了全局加**读锁**的方法，`FLUSH TABLES WITH RED LOCK`(FTWRL),，当需要整个库处于**只读**状态时，可以使用以上命令。使用后其他线程的更新类语句会被阻塞。\n\n**风险点：**\n\n* 如果在主库上备份，那么在备份期间都不能执行更新，业务基本上就能停止。\n* 如果在从库上备份，那么备份期间从库不能执行主库同步过来的binlog，会导致主从延迟。\n\n**解决办法：**\n\n* `mysqldump`使用参数`--single-transaction`，启动一个事务，确保拿到一致性视图。而由于MVCC的支持，这个过程中数据是可以正常更新的。【需要支持事务】\n\n\n\n### 表级锁\n\n**定义**：即对当前操作的整张表加锁。MyISAM与InnoDB都支持表级锁。\n\nMYSQL中有两种表级锁：\n\n1. 表锁\n2. 元数据锁(Meta Data Lock， MDL)\n\n#### 1. 表锁\n\n**实现方式**：`lock table table_name read/write`\n\n如：`lock table t1 read , t2 wirte`，则其他线程写t1，读写t2都会被阻塞。\n\n同时，本线程在`unlock tables`之前，只允许执行读t1，读写t2的操作，且不能访问其他表。\n\n**释放锁**\n\n1. `unlock tables`\n2. 会话退出后会释放所有表锁。\n\n\n\n#### 2. 元数据锁MDL\n\nMDL不需要显式使用，在访问一个表时会被自动加上。\n\n* 当对一个表做增删改查(CRUD)操作的时候，加 **MDL读锁**(Shared Read /  Shared Write)；\n* 当要对表做结构变更操作的时候，加 **MDL 写锁**。\n\n作用：防止进行CRUD操作时，其他线程对表结构做变更。\n\n\n\n**[风险点：](https://www.cnblogs.com/keme/p/11065025.html#221-%E6%80%8E%E4%B9%88%E8%A7%A3%E5%86%B3%E4%BA%86%E8%BF%99%E4%B8%AAmdl%E9%94%81)**\n\n如对表进行以下操作：\n\n```sql\n注: 表t 是 innodb 表，mysql版本是5.7.24 自动提交开启\n1. sessionA:\n# begin显式开启事务，所以其不会autocommit\nbegin;\nselect * from t limit 1;\n\n2. sessionB:\nselect * from t limit 1;\n\n3. sessionC:\nalter table t add f int ;\n#会mdl锁住\n\n4. sessionD:\nselect * from t limit 1;\n```\n\n如上操作：\n\n1. A先启动，会对表t加上一个MDL读锁\n\n2. 然后B也需要MDL读锁，正常执行。\n\n3. C为对表进行结构修改，需要获取MDL写锁，但是A获取的MDL读锁还未释放，所以C获取锁失败，被阻塞。\n\n   > Q：为什么A获取的MDL读锁还未释放？\n   >\n   > A：事务中的 MDL 锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会**等到整个事务提交后再释放。** \n   >\n   > 一般行锁都有锁超时时间。但是MDL锁没有超时时间的限制，只要事务没有提交就会一直锁住。\n\n4. 之后所有在表t上申请读锁的操作都会被C阻塞。\n\n   >Q：为什么？\n   >\n   >A：所有对表的增删改查操作都需要先申请MDL 读锁，而这时读锁没有释放，对表alter ，产生了mdl写锁，所有锁会形成一个优先级队列，**写锁优先级高于读锁**，所以一旦出现写锁等待，会将后续所有读写操作都阻塞。\n\n**结果**：很容易造成线程爆满\n\n**解决办法：**\n\n由前面分析可得，产生如上风险的原因是有**长事务**一直未提交，所以造成**锁未释放**。\n\nQ：如何找到长事务？\n\nA：在MySQL的`information_schema`库的`innobd_trx`表中，可以查到当前执行中的事务\n\n```sql\n# 查看事务超过60s的事务\nmysql> select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60\\G;\n# trx_started 表示什么时候执行的这个事务\n```\n\n该命令会返回一系列信息，包括：\n\n````sql\n# 事务状态\ntrx_state：RUNNING\n# 事务开始时间\ntrx_started: 2019-06-21 12:44:22\n# 执行事务的线程id\ntrx_mysql_thread_id: 17\n\n# 然后通过线程id定位\n# 查看所有线程\nmysql> show full processlist;\n````\n\n![image-20240201152854924](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202402011528034.png)\n\n先查看host字段，查看到底是谁连接了数据库，然后进去commit（提交事务）或者rollback ,哪如果不是localhost 环境，是程序连接了，这时候就要kill掉了。\n\n即整体解决方案为：\n\n1. 找到长事务\n2. 若做DDL(data definition language)的表刚好有长事务在执行，暂停DDL或者kill掉这个长事务\n\n即我们为什么建议在低峰期做ddl变更。\n\n\n\n#### 3. 意向锁\n\n定义：意向锁为一种**不与行级锁冲突的表级锁**。\n\n* 意向共享锁(Intention Shared Lock, IS)：一个事务在获取（任何一行/或者全表）S锁之前，一定会先在所在的表上加IS锁。\n* 意向排他锁(Intention Exclusive Lock, IX)：一个事务在获取（任何一行/或者全表）X锁之前，一定会先在所在的表上加IX锁。\n\n**意向锁是表级锁，不会与行级锁发生冲突，意向锁之间也不会发生冲突。其只会和共享表锁(lock table ... read)以及独占表锁(lock table... write)发生冲突。**\n\n表锁与行锁满足：读读共享、读写互斥、写写互斥。\n\n**意向锁作用**：\n\n* 无`意向锁`，需要加`独占表锁`时：遍历表中所有记录查询是否有`独占锁`，效率低；\n* 有`意向锁`，则加`独占锁`之前会先加表级别的`意向独占锁`，则加`独占表锁`时，可以直接查看是否有`意向独占锁`从而判断是否有锁冲突。\n\n即意向锁的作用为：**快速判断表中是否有记录被加锁。**\n\n\n\n#### 4. AUTO-INC 锁\n\n表中主键通过`AUTO_INCREMENT`设置为自增，之后插入数据时，可以不指定主键的值，数据库会自动给其赋递增的值，这主要通过`AUTO-INC锁`实现。\n\nAUTO-INC锁是一个特殊的表锁机制。锁**不是等事务提交后才释放，而是执行完插入语句后就立即释放。**\n\n执行过程：\n\n1. 在插入数据时，会加一个表级别的 AUTO-INC 锁\n2. 然后为被 `AUTO_INCREMENT` 修饰的字段赋值递增的值\n3. 等插入语句执行完成后，才会把 AUTO-INC 锁释放掉。\n\n那么，一个事务在持有 AUTO-INC 锁的过程中，其他事务的如果要向该表插入语句都会被阻塞，从而保证插入数据时，被 `AUTO_INCREMENT` 修饰的字段的值是连续递增的。\n\n面对大量插入语句时：性能低。\n\n\n\n 在 MySQL 5.1.22 版本开始，InnoDB 存储引擎提供了一种**轻量级的锁**来实现自增。\n\n一样也是在插入数据的时候，会为被 `AUTO_INCREMENT` 修饰的字段加上轻量级锁，**然后给该字段赋值一个自增的值，就把这个轻量级锁释放了，而不需要等待整个插入语句执行完后才释放锁**。\n\n用AUTO-INC还是轻量级锁：`innodb_autoinc_lock_mode`：\n\n* 值为0：AUTO-INC\n\n* 值为2：轻量级锁\n\n  > 效率最高\n  >\n  > 但是搭配binlog的日志格式为statement一起使用时，在[主从复制中会发生数据不一致](https://xiaolincoding.com/mysql/lock/mysql_lock.html#auto-inc-%E9%94%81)情况。\n\n* 值为1：\n\n  * 普通insert语句，自增锁在申请之后就马上释放\n  * insert ... select这种批量插入语句，自增锁等语句结束后释放。\n\n\n\n\n\n\n\n### 页级锁\n\n**定义**：介于行级锁与表锁之间。\n\n表锁：速度快，冲突多。\n\n行锁：冲突少，速度慢。\n\n所以采取折中的页级锁，一次取相邻的一组记录。\n\n[BDB](https://www.mysqlzh.com/doc/218.html) 引擎支持页级锁。\n\n\n\n### 行级锁\n\n**定义**：对某一行数据进行加锁。\n\n粒度最小的锁，发生冲突的概率最低，并发度最高。但是加锁慢，开销大，容易死锁。\n\nMYSQL中只有InnoDB支持行级锁，行级锁分为共享锁和排他锁。\n\n**实现方式**：行级锁不是直接锁记录，而是**锁索引**。\n\n* 主键索引：直接锁定主键索引\n* 非主键索引：先锁定该非主键索引，再锁定相关的主键索引。\n\n**Q1**：普通`select`语句会对记录加锁吗？\n\n**A1**：不会，其属于`快照读`（MVCC实现）\n\n**Q2**：查询时需要加锁怎么办？\n\n**A2**：使用以下两种方式，即锁定读\n\n````sql\n//对读取的记录加共享锁\nselect ... lock in share mode;\n\n//对读取的记录加独占锁\nselect ... for update;\n````\n\n以上语句使用时需在同一个事务中，因为事务提交后锁就会释放。\n\n**Q3**：怎么保证在同一事务中？\n\n**A3**：使用`begin`， `start transaction`或`set autocommit = 0 `显式开启事务\n\n锁分类（按属性）：【读读共享、读写互斥、写写互斥】\n\n* 共享锁（S锁）\n* 排他锁（X锁）\n\n**行级锁类型主要三类：**\n\n1. Record Lock，记录锁，锁一条记录\n2. Gap Lock，间隙锁，锁定一个范围，但是不包含记录本身\n3. Next-Key Lock，临键锁，Record Lock + Gap Lock，锁定一个范围以及记录本身\n\n\n\n#### Record Lock记录锁\n\n锁住一条记录，记录锁有S锁与X锁之分。\n\n如：\n\n````sql\n# 开启事务\nbegin;\n# 给t1表中id =  1的记录加上X型的记录锁\nselect * from t1 where id = 1 for update;\n````\n\n\n\n#### Gap Lock间隙锁\n\n**只存在与可重复读(RR)级别**。\n\n目的：解决可重复读隔离级别下**幻读**的现象。即防止插入幻读记录。\n\n如：id有3， 5的记录，在(3, 5)加上间隙锁，则其他事务无法插入id = 4的记录，防止了幻读的发生。\n\n间隙锁虽然存在S锁与X锁，但是并无区别。间隙锁是**兼容**的，**即两个事务可以同时持有包含共同间隙范围的间隙锁，并不存在互斥关系**，因为间隙锁的目的是防止插入幻影记录而提出的。\n\n\n\n#### Next-Key Lock临键锁\n\n锁定一个范围，并且锁定记录本身。\n\n如：id有3， 5的记录，在(3, 5]加上间隙锁，则其他事务无法插入id = 4的记录，也无法修改id = 5的记录。\n\n所以，next-key lock的**作用**为：即保护了记录，又能组织其他事务将新纪录插入到被保护记录的前方的间隙中。\n\n由于next-key lock包含记录锁，所以依然满足S锁与X锁的特性。即一个事务获取了 X 型的 next-key lock，那么另外一个事务在获取相同范围的 X 型的 next-key lock 时，是会被阻塞的。\n\n\n\n#### 插入意向锁\n\n事务插入记录时，需判断：插入位置是否已被其他事务加了间隙锁，若有，则需等待锁释放，在此期间，会生成一个**插入意向锁**，表明事务想要在某个区间插入新纪录，但是现在处于等待状态。\n\n> 注：MySQL 加锁时，是先生成锁结构，然后设置锁的状态，如果锁状态是等待状态，并不是意味着事务成功获取到了锁，只有当锁状态为正常状态时，才代表事务成功获取到了锁\n\n插入意向锁属于**特殊的间隙锁**，普通间隙锁锁住的为一个区间，插入意向锁锁住的就是一个点。\n\n尽管「插入意向锁」也属于间隙锁，但两个事务却不能在同一时间内，一个拥有间隙锁，另一个拥有该间隙区间内的插入意向锁（当然，插入意向锁如果不在间隙锁区间内则是可以的）。\n\n\n\n### select语句的锁定范围\n\n#### 普通select：select * from t1 where id = 1\n\n普通select查询为快照读，其通过MVCC实现无锁查询，InnoDB不会为其加任何锁。\n\n**Q**：什么锁都没有？\n\n**A**：前面提到，InnoDB不会为其加任何锁，即不会存在行锁，但是对数据表进行DML和DDL操作时，MySQL会为该表加上MDL锁，**MDL锁是sever层实现的表级锁**，适用于所有存储引擎。所以：\n\n* 对表进行增删改查(DML)，加MDL读锁(Shared Read与Shared Write都属于MDL读锁，互相兼容)\n* 对表进行结构更改(DDL)，加MDL写锁\n\n因此，我们所说的普通查询不加锁，指的是不加行级锁，实际上持有MDL锁。\n\n\n\n#### select .. for update\n\n属于锁定语句，会对表记录加X型的行级锁。对于不同隔离级别，其加的行级锁种类不同。\n\n**1. RC读已提交**\n\n行级锁种类只有记录锁。\n\n\n\n**2. RR可重复读**\n\n行级锁种类除记录锁外还有间隙锁与临键锁，不同场景下加锁不同。\n\n\n\n参考：\n\n[史上最全MySQL各种锁详解](https://juejin.cn/post/6931752749545553933#heading-8)\n\n[MySQL 全局锁和表锁](https://www.cnblogs.com/keme/p/11065025.html#222-%E6%88%91%E8%BA%AB%E4%B8%8A%E5%8F%91%E7%94%9F%E7%9A%84%E8%B6%A3%E4%BA%8B)\n\n[小林Coding MySQL 有哪些锁？](https://xiaolincoding.com/mysql/lock/mysql_lock.html)","tags":["MySQL","锁"],"categories":["Learning","DataBase"]},{"title":"MVCC Log","url":"/post/e921d68a.html","content":"# 三大日志binlog, redo log, undo log\n\n<img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202402011432181.png\" alt=\"img\" style=\"zoom:50%;\" />\n\n<!-- more -->\n\n## redo log重做日志\n\n作用：使MySQL拥有崩溃恢复能力。是InnoDB独有的。\n\n更新表数据时，在buffer pool存在要更新的数据时，直接在Buffer Pool更新数据所在页，然后将其设置为脏页。\n\n然后将“在某个数据页做了什么修改”记录到redo log buffer中，接着刷盘到redo log文件中。是物理日志。\n\n>每条 redo 记录由“**表空间号+数据页号+偏移量+修改数据长度+具体修改的数据**”组成\n\n![img](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202402011432927.png)\n\n### Buffer Pool\n\n**Q: Why Buffer Pool?**\n\n**A**：以通常思维来看数据修改。\n\n1. 从磁盘中读取记录\n2. 在内存中修改该记录\n\n修改结束后，该条记录是直接写回磁盘，还是缓存起来呢？\n\nA：缓存起来。以便下次查询命中了该记录，可以直接读取缓存中的记录，无需从磁盘读。 - > Buffer Pool\n\n\n\n**Q：Buffer Pool缓存什么？**\n\nInnoDB存储数据以页为单位，默认页大小为16k.\n\nBuffer Pool同理，以页划分。\n\n在 MySQL 启动的时候，**InnoDB 会为 Buffer Pool 申请一片连续的内存空间，然后按照默认的`16KB`的大小划分出一个个的页， Buffer Pool 中的页就叫做缓存页**。此时这些缓存页都是空闲的，之后随着程序的运行，才会有磁盘上的页被缓存到 Buffer Pool 中。\n\n所以，MySQL 刚启动的时候，使用的虚拟内存空间很大，而使用到的物理内存空间却很小，这是因为只有这些虚拟内存被访问后，操作系统才会触发缺页中断，申请物理内存，接着将虚拟地址和物理地址建立映射关系。\n\n【小林BufferPoolhttps://xiaolincoding.com/mysql/log/how_update.html#buffer-pool-%E7%BC%93%E5%AD%98%E4%BB%80%E4%B9%88】\n\n\n\n\n\n### 刷盘时机\n\n刷盘目的：保证数据持久性与一致性。【顺序写】\n\n**1. 事务提交**\n\n事务提交时，log buffer中的redo log会被刷新到磁盘。\n\n可以通过`innodb_flush_log_at_trx_commit`参数控制。\n\n\n\n**2. log buffer空间不足时**\n\nlog buffer中redo log已占满总容量的一半左右，会刷盘。\n\n\n\n**3. 事务日志缓冲区满**\n\nInnoDB 使用一个事务日志缓冲区（transaction log buffer）来暂存事务的重做日志条目。当缓冲区满时，会触发日志的刷新，将日志写入磁盘。\n\n\n\n**4. CheckPoint检查点**\n\nInnoDB定时执行checkpoint操作，将内存中的脏数据刷新到磁盘，同时将响应的redo log一起刷新，以保证数据一致性。\n\n\n\n**5. 后台刷新线程**\n\nInnoDB启动了后台线程，周期性地（1s）将Buffer Pool中的脏页刷新到磁盘（WAL Write-Ahead Logging，预写日志，即写操作并不是立刻写到磁盘上，而是先写日志，然后在合适的时间再写到磁盘上），并将相关redo log一起刷新。\n\n\n\n**6. 正常关闭服务器**\n\nMySQL关闭时，redo log会刷盘。\n\n\n\n### 刷盘策略innodb_flush_log_at_trx_commit\n\n`innodb_flush_log_at_trx_commit`取值：\n\n* **0**：每次事务提交时不进行刷盘操作。【后台线程1s刷】\n\n  性能最高，但最不安全。MySQL挂了或宕机可能丢失最近1s的事务。\n\n  ![img](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202402011432974.png)\n\n* **1**：每次事务提交时都进行刷盘操作。\n\n  性能最低，但是最安全。不会有数据丢失。【为保证事务一致性，需使用1】\n\n  ![img](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202401071355264.png)\n\n* **2**：每次事务提交时，只把log buffer中的redo log写入page cache（操作系统的文件系统缓存）。\n\n  性能与安全性都介于以上两种之间。MySQL挂了不会丢数据，操作系统宕机或断点可能丢1s.\n\n  ![img](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202402011433456.png)\n\n默认值：1\n\n\n\n此外，`InnoDB` 存储引擎有一个后台线程，每隔`1` 秒，就会把 `redo log buffer` 中的内容写到文件系统缓存（`page cache`），然后调用 `fsync` 刷盘。\n\n所以，无事务提交的redo log，也可能刷盘。\n\n![img](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202402011433836.png)\n\n\n\n### 日志文件组\n\nredo log日志文件不止一个，是以日志文件组形式存在，每个redo日志文件大小一样。\n\n采用环形数组形式，从头开始写，写到末尾又回头循环写。\n\n<img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202402011433819.png\" alt=\"img\" style=\"zoom:50%;\" />\n\n日志文件组两个重要属性：\n\n* **write pos**：当前记录的位置，一边写一边后移。\n\n  刷盘记录redo log到日志文件组时，write pos后移更新。\n\n* **checkpoint**：当前要擦除的位置，也是往后推移\n\n  MySQL加载日志文件组恢复数据时，会清空加载过的redo log，checkpoint后移更新。\n\n\n\n**write pos 追上checkpoint?**\n\n表示日志文件组已满，不能再写入新的redo log，MySQL阻塞，将Buffer Pool中脏页刷新进磁盘，然后标记redo log可以擦除的记录，并擦除，推进checkpoint.\n\n\n\n**注**：MySQL 8.0.30 之前可以通过 `innodb_log_files_in_group` 和 `innodb_log_file_size` 配置日志文件组的文件数和文件大小，但在 MySQL 8.0.30 及之后的版本中，这两个变量已被废弃，即使被指定也是用来计算 `innodb_redo_log_capacity` 的值。而日志文件组的文件数则固定为 32，文件大小则为 `innodb_redo_log_capacity / 32` 。\n\n在使用 MySQL 8.0.30 及之后的版本时，推荐使用 `innodb_redo_log_capacity` 变量配置日志文件组\n\n\n\n## binlog归档日志\n\n作用：记录更新语句的原始逻辑，是逻辑日志，属于MySQL Server层。\n\n不管用什么存储引擎，只要发生了表数据更新，都会产生 `binlog` 日志。\n\n`MySQL`数据库的**数据备份、主备、主主、主从**都离不开`binlog`，需要依靠`binlog`来同步数据，保证数据一致性。\n\n`binlog`会记录所有涉及**更新数据的逻辑操作**，并且是顺序写。\n\n\n\n### 记录格式\n\n有3种格式，可通过`binlog_format`参数指定：\n\n* **statement**：记录SQL语句原文。\n\n  同步数据时，会执行记录的SQL语句。\n\n  问题：更新的字段为当前时间`now()`时，同步执行会与源库时间不一致。\n\n  解决：指定row\n\n* **row**：除简单SQL外，还包含操作的具体数据。\n\n  看不到详细信息，需通过`mysqlbinlog`工具解析。\n\n  优点：可以保证同步数据的一致性。【通常都用】\n\n  缺点：占用空间较大，恢复与同步更消耗IO资源，影响执行速度。\n\n  解决：折中方案，mixed.\n\n* **mixed**：MySQL判断SQL语句是否可能引起数据不一致，会则使用`row`，不会则使用`statement`。\n\n\n\n### 写入机制\n\n1. 事务执行过程中，先将日志写入到`binlog cache`\n\n2. 事务**提交**时，将`binlog cache`写入到`binlog`文件中。（追加写，写满换新文件）\n\n   > 1. 先write到文件系统的page cache，速度快\n   > 2. 再fsync，持久化到磁盘\n   >\n   > **write和fsync的时机**：由参数`sync_binlog`控制\n   >\n   > * **0**：每次提交事务只write，由系统判断什么时候fsync（默认）\n   >\n   >   优点：性能得到提升\n   >\n   >   缺点：机器宕机，page cache中的binlog会丢失\n   >\n   > * **1**：每次提交事务都执行fsync\n   >\n   > * **N**：N > 1，即每次提交事务都write，累积N个事务后fsync\n   >\n   >   优点：出现IO瓶颈时，放大N，可以提升性能\n   >\n   >   缺点：机器宕机后，会丢失最近的N个事务的binlog\n\n因为一个事务的`binlog`不能被拆开，无论这个事务多大，也要确保一次性写入，所以系统会给每个线程分配一个块内存作为`binlog cache`。\n\n\n\n### 主从复制实现\n\n![img](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202401071355262.png)\n\n主从复制过程一般是异步的。过程一般有3个阶段：\n\n1. 写入binlog[主库]\n2. 同步binlog[从库创建线程连接主库的log dump线程，复制到从库，写到暂存日志relay log]\n3. 回放binlog[从库，回放更新]\n\n完成主从复制后，可以实现：\n\n* **写数据：只写主库**\n* **读数据：只读从库**\n\n从而，写请求锁表时，不会影响读请求执行。\n\n**Q：从库数量越多越好？**\n\n**A**：No. 从库数量多，其连接上来的IO线程也多，主库需要创建同样数量的log dump线程来处理复制请求，对主库的资源消耗量高。\n\n一般，一个主库一般跟 2～3 个从库（1 套数据库，1 主 2 从 1 备主）\n\n\n\n## 两阶段提交\n\nredo log：使InnoDB有了崩溃恢复的能力\n\nbinlog：保证了MySQL集群架构的数据一致性\n\n两个的写入时机：\n\n* redo log：事务**执行过程中**可以不断写入\n* binlog：**提交事务时**写入\n\n<img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202402011434621.png\" alt=\"img\" style=\"zoom:50%;\" />\n\n**Q：redo log 与 binlog之间的逻辑不一致会造成的问题？**\n\n**A**：假设场景为：redo log写完后，在写binlog的过程中出现异常\n\n       则会导致：redo log 与 binlog中的数据不一致。即会导致恢复时，主备 / 从库数据不一致。\n\n解决方案：InnoDB使用**两阶段提交**方案。\n\n原理：将redo log的写入拆分为两个步骤：\n\n1. prepare\n2. commit\n\n<img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202402011434146.png\" alt=\"img\" style=\"zoom:50%;\" />\n\n此时若发生binlog写入异常：\n\nMysql根据redo log恢复数据时，发现redo log还处于prepare阶段，且无对应的binlog日志，就会回滚事务。\n\n**Q：redo log commit阶段发生异常，会回滚事务吗？**\n\n**A**：不会，redo log虽然处于prepare截断，但是可以通过事务id找到对应的binlog日志，所以MySQL认为是完整的，会提交事务恢复数据。\n\n\n\n## undo log回滚日志\n\n想要保证事务的**原子性（Atomicity）**：异常发生时，对已执行的操作进行回滚。\n\n作用：事务还未执行完（未提交），发生故障，需要回滚到事务之前的数据。即保证事务原子性。此外，还是实现MVCC的关键因素之一。\n\n记录时机：事务未提交前，记录更新前的数据到undo log中。\n\n如（不同类型操作undo log的格式不同）：\n\n* 插入记录时，记录主键，回滚时删除对应记录\n\n* 删除记录时，记录所有内容，回滚时插入对应记录\n\n* 更新记录时，记录旧值与主键，回滚时更新为旧值\n\n  >更新操作产生的undo log都有一个roll_pointer指针和一个trx_id（事务id）：\n  >\n  >* trx_id：记录被哪个事务修改的\n  >* roll_pointer：将undo log串成一个链表，即版本链\n\n\n\n### undo log刷盘\n\n与数据页的刷盘策略一致，需通过redo log保证持久化。\n\nBuffer Pool中有undo页，对undo 页的修改会记录到redo log， redo log再刷盘。\n\n\n\n# MCVV\n\nMVCC: Multi-Version Concurrency Control，即多版本并发控制。\n\n作用：保证多并发事务同时读写数据库时数据的一致性和隔离性。\n\n实现方式：在每个数据行上维护多个版本的数据。当一个事务要对数据库中数据进行修改时，MVCC会为其创建一个数据快照，而不直接修改实际的数据行。\n\n\n\n## 快照读 vs. 当前读\n\n**快照读**\n\n不加锁的非阻塞读。\n\n读取数据的某个版本快照。普通select即为快照读。\n\n**当前读**\n\n读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁。\n\nselect lock in share mode(共享锁), select for update ; update, insert ,delete(排他锁)都是当前读。\n\n\n\n**1. 读操作**\n\n使用快照读。\n\n快照读基于事务开始时数据库中的状态创建，因此事务不会读取其他事务尚未提交的修改。\n\n具体操作如下：\n\n* 事务查找符合条件的数据行，并选择符合事务开始时间的数据版本进行读取。\n* 某个数据行有多个版本时：事务会选择不晚于其开始时间的最新版本。确保事务只读在其开始前已存在的数据。\n* 事务读取的是快照数据，因此其他并发事务对数据行的修改不影响当前读取。\n\n\n\n**2. 写操作**\n\n会生成新的数据版本，并将修改后的数据写入数据库。\n\n具体操作如下：\n\n* 事务为要修改的数据行创建一个新的版本，并将修改后的数据写入新版本。\n* 新版本的数据会带有当前事务的版本号，以便其他事务能够正确读取相应版本的数据。\n* 原始版本的数据仍然存在，供其他事务使用快照读取，这保证了其他事务不受当前事务的写操作影响。\n\n\n\n**3. 事务的提交与回滚**\n\n* 当一个事务提交时，它所做的修改将成为数据库的最新版本，并且对其他事务可见。\n* 当一个事务回滚时，它所做的修改将被撤销，对其他事务不可见。\n\n\n\n**4. 版本的回收**\n\n为了防止数据库中的版本无限增长，MVCC 会定期进行版本的回收。回收机制会删除已经不再需要的旧版本数据，从而释放空间。\n\n\n\nMVCC 通过创建数据的多个版本和使用快照读取来实现并发控制。读操作使用旧版本数据的快照，写操作创建新版本，并确保原始版本仍然可用。这样，不同的事务可以在一定程度上并发执行，而不会相互干扰，从而提高了数据库的并发性能和数据一致性。\n\n\n\n## InnoDB对MVCC的实现\n\n`MVCC` 的实现依赖于：**隐藏字段、Read View、undo log**。\n\n在内部实现中，\n\n1. `InnoDB` 通过数据行的 `DB_TRX_ID` 和 `Read View` 来判断数据的可见性，\n\n2. 如不可见，则通过数据行的 `DB_ROLL_PTR` 找到 `undo log` 中的历史版本。\n\n   每个事务读到的数据版本可能是不一样的，在同一个事务中，用户只能看到该事务<u>创建 `Read View` 之前</u>已经提交的修改和该事务本身做的修改。\n\n\n\n### 隐藏字段\n\nInnoDB为每行数据添加三个隐藏字段：\n\n* `DB_TRX_ID（6字节）`：即事务ID，表示最后一次插入或更新该行的事务 id。\n\n  此外，`delete` 操作在内部被视为更新，只不过会在记录头 `Record header` 中的 `deleted_flag` 字段将其标记为已删除\n\n* `DB_ROLL_PTR（7字节）`： 回滚指针，指向该行的 `undo log` 。\n\n  如果该行未被更新，则为空\n\n* `DB_ROW_ID（6字节）`：即隐式主键，如果没有设置主键且该表没有唯一非空索引时，`InnoDB` 会使用该 id 来生成聚簇索引\n\n\n\n### ReadView\n\n````c\nclass ReadView {\n  /* ... */\nprivate:\n  trx_id_t m_low_limit_id;      /* 目前出现过的最大的事务 ID+1，即下一个将被分配的事务 ID。大于等于这个 ID 的事务均不可见 */\n\n  trx_id_t m_up_limit_id;       /* 活跃事务列表 m_ids 中最小的事务 ID，如果 m_ids 为空，则 m_up_limit_id 为 m_low_limit_id。小于这个 ID 的事务均可见 */\n\n  trx_id_t m_creator_trx_id;    /* 创建该 Read View 的事务ID */\n\n  trx_id_t m_low_limit_no;      /* 事务 Number, 小于该 Number 的 Undo Logs 均可以被 Purge(清除) */\n\n  ids_t m_ids;                  /* 创建 Read View 时的活跃事务列表 */\n\n  m_closed;                     /* 标记 Read View 是否 close */\n}\n\n````\n\nRead View即为事务进行快照读时产生的读视图。\n\n作用：主要是用于做**可见性判断**。当某个事务执行快照读时，会对该记录创建一个read view，将其作为条件用于判断当前事务能看到哪个版本的数据。\n\n\n\n#### 可见性算法\n\n**注**：\n\n1. ReadView与SQL绑定，而非与事务绑定。所以即使在同一事务中，每次SQL启动时的`low_trx_id`和`up_trx_id`也是不同。\n2. `db_trx_id`指的是数据行中的`db_trx_id`字段，分配的事务ID只有操作了数据行，才会更新该字段值。（越晚创建id越大）\n\n**up_limit_id**\n\n表示“低水位”，即当前活跃事务列表的最小事务id(最早创建的事务)，若读取的数据行上的`db_trx_id`小于`up_limit_id`，表明这条记录的最后修改在readview创建之前，因此这条记录可以被看见。\n\n\n\n**low_limit_id**\n\n表示“高水位”，即当前活跃事务的最大id(最晚创建的事务) + 1，若读取的数据行上的`db_trx_id`大于`lpw_limit_id`，表明这条记录的最后修改在readview创建之后，因此这条记录不可以被看见。\n\n\n\n若读取的数据行上的`db_trx_id`在`up_limit_id`与`low_limit_id`之间，则查找该数据行上的`db_trx_id`是否在ReadView上的`m_ids`列表中。（即该事务是否为活跃事务）\n\n* 在其中，说明该条记录的最后修改在ReadView创建之时，被另一个活跃事务所修改，所以该条记录不可见。\n* 不在其中，说明该条记录的最后修改在ReadView之后，所以可见。\n\n\n\n综合以上，可见性算法的流程为：\n\n![可见性算法](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202401071355068.png)\n\n\n\n#### ReadView生成时机\n\n**1. RR（Repeatable Read）**\n\n* 每个事务执行`SELECT`语句时：\n  * **首次**执行：会讲当前系统所有活跃事务拷贝到一个列表中生成ReadView\n  * **后续**执行：复用其之前生成的ReadView\n* `UPDATE, DELETE, INSERT`：对一致性读snapshot无影响\n\nRR隔离级别，第一次创建ReadView后，其就会一直持续到事务结束。\n\n即在事务执行过程中，数据的可见性不会变，所以在事务内部不会出现数据不一致的情况。\n\n\n\n**2. RC（Read Commited)**\n\n* **每次**`SELECT`执行，都会重新将当前系统中的所有活跃事务拷贝到一个列表中生成ReadView\n\n问题：两个查询之间有事务提交，就会出现数据不一致。\n\n\n\n### undo log\n\nInnoDB有两种undo log：\n\n* **insert undo log**：指在 `insert` 操作中产生的 `undo log`。\n\n  因为 `insert` 操作的记录只对事务本身可见，对其他事务不可见。只在事务回滚时需要，故该 `undo log` 可以**在事务提交后直接删除**。不需要进行 `purge` 操作\n\n* **update undo log**：`update` 或 `delete` 操作中产生的 `undo log`。\n\n  除事务回滚需要之外，可能需要提供 `MVCC` 机制，因此不能在事务提交时就进行删除。提交时放入 `undo log` 链表，等待 `purge线程` 进行最后的删除\n\n不同事务或者相同事务的对同一记录行的修改，会使该记录行的 `undo log` 成为一条链表，链首就是最新的记录，链尾就是最早的旧记录。\n\n\n\n## purge\n\n* 为实现MVCC，更新或删除操作都是：设置一下老记录的`deleted_bit`，并不是真的删除。\n* 为节省磁盘空间，InnoDB有专门的purge线程来清理`deleted_bit`为`true`的记录。\n* 为不影响MVCC正常工作，purge线程自己也维护了一个read view(相当于系统中最老活跃事务的read view)\n* 若某个记录的`deleted_bit`为`true`，且`DB_TRX_ID`相对于purge线程的read view可见，这条记录一定时可以被安全清除的。\n\n\n\n参考：\n\n[什么是MySQL MVCC的ReadView？](https://blog.csdn.net/wtopps/article/details/118247884)\n\n[MVCC多版本并发控制原理总结（最终版）](https://www.cnblogs.com/jelly12345/p/14889331.html)\n\n\n\n","tags":["MySQL","MVCC","Log"],"categories":["Learning","DataBase"]},{"title":"Helm","url":"/post/cbb39f4b.html","content":"\n\n\n# Helm\n\n## 0 概述\n\n**为什么使用Helm?**\n\nK8s能够很好地组织和编排容器，但是缺少一个更高层次的应用打包工具。\n\n<!-- more -->\n\n组织应用的服务多时，k8s对其组织和管理会出现的问题：\n\n* 很难管理、编辑和维护大量服务。每个服务都有若干配置，缺乏更高层次的工具将这些配置组织起来\n* 不容易将这些服务作为一个整体统一发布。缺少工具定义应用与服务、服务与服务之间的依赖关系\n* 不能高效地共享和重用服务，不支持参数化配置和多环境配置\n* 不支持应用级别地版本管理。通过`kubectl rollout undo`只能进行单个Deployment的回滚，不支持整个应用的回滚\n* 不支持对部署的应用状态进行验证\n\n而通过Helm就可以解决以上问题。\n\n\n\n**Helm作用**：通过合并配置文件到一个可重用的包，从而可以自动创建、打包、配置、部署k8s应用。简单来说，Helm也就是一个Package manager。\n\n\n\n**概念介绍**：\n\n`Chart`：一个描述K8s相关资源的文件集合。\n\n`Release`：一个运行的`chart`实例。\n\n`Helm repositories`：即存放`helm charts`的库。 Artifact Hub: 类似于docker hub\n\n\n\n**Helm的适用场景**：\n\n适用场景：\n\n- 有多个需被统一管理和部署的k8s应用\n- K8s应用经常更新与部署\n- 多团队多用户合作开发部署k8s应用\n\n\n\n## 1 Chart\n\n### 1.1 文件目录结构\n\n如下：\n\n```text\nmychart/\n  Chart.yaml          # 包含了chart信息的YAML文件\n  LICENSE             # 可选: 包含chart许可证的纯文本文件\n  README.md           # 可选: 可读的README文件\n  values.yaml         # chart 默认的配置值\n  values.schema.json  # 可选: 一个使用JSON结构的values.yaml文件\n  charts/             # 包含chart依赖的其他chart\n  crds/               # 自定义资源的定义\n  templates/          # 模板目录， 当和values 结合时，可生成有效的Kubernetes manifest文件\n  templates/NOTES.txt # 可选: 包含简要使用说明的纯文本文件\n```\n\n**NOTE.txt**\n\n为用户提供说明。在`helm install` / `helm upgrade` 的最后，会打印出对用户有用的信息。\n\n虽然`NOTES.txt`是纯文本，但是会像模板一样处理，所有正常的模板函数和对象都是可用的\n\n\n\n### 1.2 Chart dependency\n\nHelm中，chart可以依赖其他任意个chart，所依赖的chart称为子chart。\n\n**依赖可以通过两种方式配置**：\n\n* 使用`Chart.yaml`文件中的`dependencies`字段动态链接\n\n  定义好依赖后，运行`helm dependency update`会使用依赖文件下载所指定的chart包到`chart/`目录\n\n* 带入到`chart/`目录手动配置\n\n\n\n## 2 Values\n\n### 2.1 Values对象\n\n作用：提供传递值到chart的方法。\n\n内容来源：\n\n* `values.yaml`文件\n\n* 子chart不可访问父chart的值，但是可以被覆盖\n\n* 使用`-f`参数传递到`helm install`/`helm upgrade`的values文件\n\n* 使用`--set`传递的单个参数\n\n  顺序：默认使用`values.yaml`，可以被父chart的`values.yaml`覆盖，继而被用户提供values文件覆盖， 最后会被`--set`参数覆盖，优先级为`values.yaml`最低，`--set`参数最高。\n\n\n\n即Helm相当于将`config value`与具体的资源的yaml解耦，即将具体的配置字段即其值提取出来成一个`values.yaml`文件。\n\n在资源具体的yaml文件中，字段值不直接配置，而是使用占位符代替。\n\n针对不同的运行环境，无需更改具体的yaml配置文件，而是更改`values.yaml`，类似于抽象出接口提供修改，而不是每次都到具体文件中修改。\n\n\n\n### 2.2全局值\n\n使用完全一样的名字在所有的chart及子chart中都能访问的值。全局变量需要显式声明。不能将现有的非全局值作为全局值使用。\n\n可以在`values.yaml`中设置`global`字段来设置全局值\n\n\n\n### 2.3 其他内置对象\n\n* Release\n* Chart\n* Files\n* Capabilities\n* Template\n\n\n\n## 3 模板Template\n\n### 3.1 模板函数和流水线\n\n#### 3.1.1 模板函数\n\n已知：通过占位key可以将value传入到模板中，但传入的信息无法修改，需转换所提供的数据格式该怎么办？\n\n用模板函数解决。\n\n````\nfunctionName arg1 arg2 ...\n````\n\n如：将传入的字符串用括号括起来放入模板中\n\n````\ndata:\n  testvalue: {{ quote .Values.test}}\n````\n\n即为调用`quote`函数并传递了一个参数为`.Values.test`\n\n[模板函数列表](https://helm.sh/zh/docs/chart_template_guide/function_list/)\n\n\n\n#### 3.1.2 管道符\n\n即为按顺序完成一系列任务的方式\n\n使用管道符重写上述模板函数：\n\n````\ndata:\n  testvalue: {{  .Values.test | quote}}\n````\n\n以上并不是调用`quote`函数，而是倒置命令，使用管道符( `|` )将参数发送给函数`quote`\n\n使用管道符可以链接多个函数，如：`testvalue: {{ .Values.test |upper |  quote}}`\n\n\n\n#### 3.1.3 default函数\n\n作用：设置默认值\n\n如：`testvalue: {{.Values.test | default \"my-test\" | quote }}`\n\n即设置`.Values.test`的默认值为`\"my-test\"`\n\n\n\n#### 3.1.4 空白控制\n\n错误的空白/空格会导致错误的YAML，缩进需正确。\n\n模板引擎运行时，会移除`{{`和`}}`里的内容，但是所留下的空白保持。\n\n`{{-`(包括添加的横杠和空格)表示向左删除空白， 而` -}}`表示右边的空格应该被去掉。\n\n要确保`-`和其他命令之间有一个空格。\n\n **一定注意空格就是换行**\n\n有时使用`indent`更好，如：`{{ indent 2 \"mug:true\" }}`\n\n\n\n### 3.2 流控制\n\n#### 3.2.1 if/else\n\n作用：创建条件语句\n\n````\n{{ if PIPELINE }}\n  # Do something\n{{ else if OTHER PIPELINE }}\n  # Do something else\n{{ else }}\n  # Default case\n{{ end }}\n````\n\n**注**：条件是`pipeline`而不是值，即控制结构可以执行整个管道而不仅仅是计算一个值\n\n管道`false`的情况：\n\n* false\n* 0\n* 空串\n* 空集合\n* nil（空或null）\n\n\n\n#### 3.2.2 with\n\n作用：指定范围\n\n````\n{{ with PIPELINE }}\n  # restricted scope\n{{ end }}\n````\n\n**注**：`with`后的块只有在`pipeline`不为空时才执行\n\n如：\n\n````\n{{- with .Values }}\ntestvalue: {{ test | default \"my-test\" | quote }}\n{{- end }}\n````\n\n**注**：在指定作用域中，无法使用`.`访问父作用域的对象。但是可以通过`$`到根作用域访问，即限定为`$.xxxx`\n\n\n\n#### 3.2.3 rang\n\n作用：提供类似`for each`类型的循环\n\n如：\n\n````\nlists: |-\n  {{- range .Values.lists }}\n  - {{ . | title | quote }}\n  {{- end }}    \n````\n\n使用`rang`后，类似于`with`的作用域，每次循环，`.`都会设置为当前的值，\n\n\n\n### 3.3 变量\n\n变量为对另一个对象的命名引用，遵循`$name`变量的格式且使用`:=`赋值\n\n如：\n\n````\nlists: |-\n  {{- range $index, $list := .Values.lists }}\n    {{ $index }}: {{ $list }}\n  {{- end }}    \n````\n\n以上会将整型索引（从0开始）赋值给`$index`并将`lists`每项值赋值给`$list`\n\n\n\n### 3.4 命名模板\n\n也叫部分/子模板。是仅仅在文件内部定义的模板，并使用了一个名字。\n\n**注**：模板名称是全局的，使用相同名称时，会使用最后出现那个\n\n常见命名惯例是用chart名称作为模板前缀\n\n\n\n#### 3.4.1 define\n\n作用：创建命名模板\n\n````\n{{- define \"chartname.subname\" }}\n  # body of template here\n{{- end }}\n````\n\n\n\n#### 3.4.2 template\n\n作用：导入命名模板\n\n````\n{{ template \"chartname.subname\" }}\n````\n\n当模板引擎读取包含`define`和`template`的文件时，它会存储`chartname.subname`的引用直到`template \"chartname.subname\"`被调用。 然后会按行渲染模板。\n\n**注**：使用的命名模板包含对象时，在`template`中需传入范围。\n\n如：`{{- template \"mychart.labels\" . }}`\n\n**使用`template`的问题**：`template`是一个行为而不是方法，数据只能简单地按行插入，解决空格缩进就很麻烦\n\n\n\n#### 3.4.3 include\n\n作用：可以将模板内容导入当前管道，然后传递给管道中的其他方法。\n\n如：`{{ include \"mychart.app\" | indent 4 }}`\n\n\n\n## 4 .helmignore文件\n\n指定不想包含在helm chart中的文件，如果文件存在，helm package命令在打包时会忽略所有在其中匹配的文件\n\n支持unix shell的全局匹配、相对路径匹配、反向匹配，每行只考虑一种模式\n\n\n\n## 5 Chart Hook\n\n作用：允许开发者在发布生命周期的某些点进行干预。\n\nHook的工作方式与常规模板类似，但是因为Helm对其不同的使用方式，会有一些特殊的注释。\n\n\n\n### 5.1 可用的Hook\n\n- `pre-install`：模板渲染之后，k8s资源创建之前执行\n- `post-install`：所有资源加载到k8s之后执行\n- `pre-delete`：在K8s删除之前，执行删除请求\n- `post-delete`：在所有的版本资源删除之后执行删除请求\n- `pre-upgrade`： 在模板渲染之后，资源更新之前执行一个升级请求\n- `post-upgrade`：所有资源升级之后执行一个升级请求\n- `pre-rollback`：在模板渲染之后，资源回滚之前，执行一个回滚请求\n- `post-rollback`： 在所有资源被修改之后执行一个回滚请求\n- `test`：调用`helm test`子命令执行\n\n![image-20240201172451016](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202402011724226.png)\n\n### 5.2 钩子和发布生命周期\n\n如为install定义的两个钩子：`pre-install`, `post-install`，在chart开发时两个钩子都执行，则整个`install`周期会变为：\n\n1. 用户执行 `helm install foo`\n2. Helm库调用安装API\n3. 在 `crds/`目录中的CRD会被安装\n4. 在一些验证之后，库会渲染`foo`模板\n\n>5. 库准备执行`pre-install`钩子(将hook资源加载到Kubernetes中)\n>6. 库按照权重对钩子排序(默认将权重指定为0)，然后在资源种类排序，最后按名称正序排列。\n>7. 库先加载最小权重的钩子(从负到正)\n>8. 库会等到钩子是 \"Ready\"状态(CRD除外)\n\n9. 库将生成的资源加载到Kubernetes中。注意如果设置了`--wait`参数，库会等所有资源是ready状态， 且所有资源准备就绪后才会执行`post-install`钩子。\n\n>10. 库执行`post-install`钩子(加载钩子资源)。\n>11. 库会等到钩子是\"Ready\"状态\n\n12. 库会返回发布对象(和其他数据)给客户端\n13. 客户端退出\n\n\n\n什么叫等到钩子是`Ready`状态？\n\n* 资源是`Job`或`Pod`类型，Helm会等到直到其成功运行完成。若钩子失败，发布就会失败。这是一个阻塞操作，所以Helm客户端会在这个任务执行时暂停\n* 其他种类资源，一旦k8s将资源标记为已加载，资源会被认为是`Ready`。\n\n当一个钩子中声明了很多资源时， 资源会串行执行。如果有钩子权重，会按照权重顺序执行。\n\n\n\n**钩子资源不使用对应版本管理**\n\n钩子创建的资源无法作为发布的一部分进行跟踪和管理。\n\n一旦Helm验证钩子达到`Ready`状态，将不再使用钩子资源。\n\n在钩子中创建了资源，不能依靠`helm uninstall`去删除资源。要删除这些资源，要么在钩子模板文件中 添加一个自定义的`helm.sh/hook-delete-policy` 注释，要么设置任务资源的生存时间（TTL）字段。\n\n`helm.sh/hook-delete-policy` 注释值：\n\n* `before-hook-creation`：新钩子启动前删除之前的资源（默认）\n* `hook-succeeded`：钩子成功执行后删除资源\n* `hook-failed`：如果钩子执行失败，删除资源\n\n\n\n### 5.3 编写一个hook\n\nhook是在`metadata`字段下指定了特殊的`annotations`的k8s清单文件\n\n如：\n\n````yaml\nmetadata:\n  annotations:\n    \"helm.sh/hook\": post-install #指定hook\n    \"helm.sh/hook-weight\": \"5\"\n    \"helm.sh/hook-delete-policy\": hook-succeeded\n````\n\n一个资源可以实现多个钩子","tags":["k8s","Helm Chart"],"categories":["Learning","K8S"]},{"title":"Redis","url":"/post/bae4ff13.html","content":"\n\n\n# Redis\n\n特点：高性能的`key-value`数据库，NoSQL\n\n与其他`key-value`数据库相比：\n\n* redis支持数据持久化，可以将内存中的数据保存在磁盘中，重启时再次加载使用。\n* 除简单数据外，还支持`list`, `set`, `zset`(有序set), `hash`等数据结构的存储\n* 支持数据备份，即master-slave模式的数据备份\n\n<!-- more -->\n\n优势：\n\n* 性能极高\n* 丰富的数据类型\n* 原子：所有操作都是原子性的\n* 丰富的特性：还支持publish/subscribe，通知，key过期等特性\n\n\n\n## 基本数据类型\n\n支持五种数据基础类型：\n\n* string\n* hash\n* list\n* set\n* zset(sorted set)\n\n\n\n### string\n\n是redis最基本的类型。值最大能存储`512MB`\n\n是二进制安全的，即redis的`string`可以包含任何数据。\n\n#### 常用命令\n\n````shell\n# 设置key-value类型的值\nSET test \"test\"\nGET test\n\"test\"\n# 批量设置/获取时可以用MSET / MGET\n\n# 判断某个key是否存在\nEXISTS test\n(integer) 1\n\n# 返回key对应的字符串的长度\nSTRLEN test\n(integer) 4\n\n# 删除key对应值\nDEL test\n````\n\n\n\n实现计数器：\n\n````shell\n# 当字符串内容为整数时可使用\nSET number 0\n\n# 增加\nINCR number\n(integer) 1\n\nINCRBY number 10\n(integer) 11\n\n# 减少\nDECR number\n(integer) 10\n\nDECRE number 10\n(integer) 0\n````\n\n过期（默认永不过期）：\n\n````shell\n# 设置key 60s后过期（已存在的key）\nEXPIRE test 60\n\n# 查看还有多久过期\nTTL test\n\n#设置 key-value 类型的值，并设置该key的过期时间为 60 秒\n> SET key  value EX 60\nOK\n> SETEX key  60 value\nOK\n# 不存在就插入（not exists）\n>SETNX key value\n(integer) 1\n````\n\n\n\n#### 内部实现\n\nstring底层的数据结构实现主要是`int`和`SDS`(简单动态字符串)\n\nSDS相比C语言字符串：\n\n* SDS不仅可以保存文本数据，还可以保存二进制数据。因为SDS使用`len`来判断字符串长度而不是空字符`\\0`\n* SDS获取字符串长度的时间复杂度是$O(1)$，因为其使用了`len`属性来记录长度\n* SDS是API安全的，拼接字符串不会造成缓冲区溢出，因为拼接之前会检查SDS空间是否满足要求，不够会扩容。\n\n\n\nSDS共有五种类型：sdshdr5实际并不会使用。redis会根据初始化长度决定使用哪种类型，从而减少内存使用。\n\n| 类型     | 字节 | 位   |\n| -------- | ---- | ---- |\n| sdshdr5  | < 1  | <8   |\n| sdshdr8  | 1    | 8    |\n| sdshdr16 | 2    | 16   |\n| sdshdr32 | 4    | 32   |\n| sdshdr64 | 8    | 64   |\n\n对于后四种实现都包含了下面这 4 个属性：\n\n- `len`：字符串的长度也就是已经使用的字节数\n- `alloc`：总共可用的字符空间大小，alloc-len 就是 SDS 剩余的空间大小\n- `buf[]`：实际存储字符串的数组\n- `flags`：低三位保存类型标志\n\n\n\n#### 应用场景\n\n##### 缓存对象\n\n有两种方式：\n\n* 直接缓存整个对象的json，如：\n\n  ````shell\n  SET user:1 '{\"name\": \"Jack\", \"age\": 11}'\n  ````\n\n  \n\n* 采用将key进行分离为对象字段，使用MSET存储，即为：\n\n  ````shell\n  MSET user:1:name \"Jack\" user:1:age 11\n  ````\n\n\n\n##### 常规计数\n\nredis命令都是原子的，所以string类型可以用于计数\n\n如可用于计算访问次数、点赞、转发数等\n\n使用`INCR`即可\n\n\n\n##### 分布式锁\n\n`SET`有个参数为`NX`，可以实现key不存在才插入，可用于实现分布式锁：\n\n* 若key不存在，则插入成功，可用于表示加锁成功\n* 若key存在，则插入失败，可用于表示加锁失败\n\n一般而言，还会对分布式锁加上过期时间(`PX`，单位为miliseconds)，分布式锁的命令如下：\n\n```shell\nSET lock_key unique_value NX PX 10000\n```\n\n解锁的过程即将`lock_key`删除，删除前需判断锁的`unique_value`是否为加锁客户端，是的时候才删除。\n\n即解锁有两个过程，需使用Lua脚本来保证解锁的原子性：\n\n````lua\n// 释放锁时，先比较 unique_value 是否相等，避免锁的误释放\nif redis.call(\"get\",KEYS[1]) == ARGV[1] then\n    return redis.call(\"del\",KEYS[1])\nelse\n    return 0\nend\n````\n\n\n\n##### 共享session信息\n\n例如用户登录的场景，其session信息被存储在server1，第二次访问时用户被分配到server2，就会出现重复登录的问题。问题在于分布式系统每次会把请求随机分配到不同的服务器。\n\n可以借助redis对session信息进行统一的存储和管理。\n\n![img](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202402011542828.png)\n\n\n\n### hash\n\n是一个键值对集合(key-value)。\n\nhash 是一个 string 类型的 `field` 和 `value` 的映射表，很适合用于存储对象。\n\n每个hash可以存储$2^{32}-1$个键值对\n\n\n\n#### 常用命令\n\n````shell\n# HSET / HMSET(deprecated)用于设置多个键值对\nHSET test field1 \"value1\" field2 \"value2\"\n\n# 返回对应key指定键值\nHGET test field1\n\"value1\"\n\n# 返回所有键值\nHGETALL test\n# 1) \"field1\"\n# 2) \"value1\"\n# 3) \"field2\"\n# 4) \"value2\"\n\n# 删除指定键值\nHDEL test field1\n\n# 返回field数量\nHLEN test\n\n# 为指定field值加上增量n(field为数字时)\nHINCREBY key field n\n````\n\n\n\n#### 内部实现\n\n底层数据结构为`压缩列表`或`哈希表`\n\n7.0后压缩列表废弃，使用`listpack(紧凑列表)`实现\n\n* 元素个数小于512，所有值小于64字节，使用压缩表\n* 否则使用哈希表   \n\n\n\n#### 应用场景\n\n##### 存储对象\n\n非常适合存储对象，如：\n\n````shell\nHSET user:1 name \"Tom\" age \"11\"\n````\n\n**string(json)还是hash来存储对象？**\n\n* string存放的为序列化后的对象数据，存放的为整个对象，hash对每个对象字段单独存储，可以获取部分字段的信息，也可以修改或者添加部分字段，节省网络流量。如果对象中*某些字段需要经常变动或者经常需要单独查询对象中的个别字段信息*，Hash 就非常适合。\n* string存储更节省内存，缓存相同数量的对象数据，string消耗内存约为hash的一半。且存储有多层嵌套的对象更方便。若*系统对性能和资源消耗很敏感*，string更合适\n* 一般情况用string存储即可\n\n\n\n##### 购物车\n\n购物车商品频繁修改变动，用hash更合适\n\n* 用户id为key\n* 商品id为field，数量为value\n\n\n\n### list\n\n是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）。\n\n最多存储元素数量为$2^{32} - 1$\n\n#### 常用命令\n\n````shell\n# LPUSH是在头部添加，key不存在时也可以\nLPUSH test \"value1\"\nLPUSH test \"value2\"\n\n# 在头部添加，只有key存在时才有效\nLPUSHX test \"value3\"\n\n# 尾部添加\nRPUSH test \"value4\"\n\n# 获取所有元素\nLRANGE test 0 -1\n\n# 头部移除\nLPOP test\n\n# 尾部移除\nRPOP test\n````\n\n**注**：下标：\n\n* 从左到右：0，1，2...\n* 从右到左：-1，-2，-3...\n\n\n\n#### 内部实现\n\n底层数据结构为`双向链表`或`压缩列表`\n\n3.2后只使用`quicklist`实现\n\nquicklist实际上为双向链表与压缩列表的混合体。\n\n将链表按段切分，每一段使用ziplist来紧凑存储，多个段之间使用双向指针串接起来。\n\n\n\n#### 应用场景\n\n##### 消息队列\n\n消息队列存取消息的三个需求：消息保序、处理重复的消息、保证消息可靠性\n\nlist与stream都可满足以上三个需求\n\n**1. 消息保序**\n\n即满足消息先进先出。\n\n可以使用`LPUSH + RPOP`或`RPUSH + LPOP`实现\n\n\n\n存在潜在的性能风险点。如使用`LPUSH + RPOP`：\n\n生产者向list中push数据时，其并不会主动通知消费者有新消息写入。消费者想要及时处理消息时，需要不断调用`RPOP`命令，有新消息时就返回结果，否则返回空值继续循环。\n\n故即使没新消息写入，消费者也需一直调用RPOP，即导致其CPU一直消耗在RPOP命令上，带来不必要的性能损失。\n\n为解决该问题，redis提供`BRPOP`命令，即阻塞式读取，未读到数据时，自动阻塞，直到有新消息加入队列，再开始读取新数据。\n\n\n\n**2. 重复消息处理**\n\n消费者实现重复消息处理，需实现两个方面的要求：\n\n1. 每个消息都要有一个全局的ID\n2. 消费者要记录已经处理过的消息的ID。收到新消息时，对比其ID与记录的已处理过的ID，若已处理则不再处理\n\n问题：list不会为每个消息生成ID，所以需要为每个消息自定义唯一的全局ID。生成之后，使用`LPUSH`将消息插入list时，需包含该全局ID。\n\n\n\n**3. 保证消息可靠性**\n\n消息一旦从list中读出，list中就不会留存该消息。在处理消息的过程中出现宕机或故障时，会导致消息未处理完成，想要再次处理时却无法再在list中读取该消息。\n\n为留存消息，list提供命令`BRPOPLPUSH`，其作用为：让消费者程序从一个 List 中读取消息，同时，Redis 会把这个消息再插入到另一个 List（可以叫作备份 List）留存\n\n如此，重启后消费者可以在备份list中再次读取到消息\n\n> list作为消息队列的缺陷？\n\nlist不支持多个消费者消费同一条消息，因为消息从list中读取后就被删除了，无法被再次消费。\n\nlist不支持消费者组的实现，所以无法多消费者消费同一条消息。不过stream支持消费者组的形式读取。\n\n\n\n### set\n\n是string类型的无序集合。\n\n集合是通过哈希表实现，所以增删改查的复杂度都是$O(1)$\n\n集合中最大的成员数为 $2^{32} - 1$\n\n#### 常用命令\n\n````shell\n# 添加元素，重复添加元素会被忽略\nSADD test \"value1\" \"value2\"\n\n# 查看集合元素\nSMEMBERS test\n\n# 删除元素\nSREM test \"value1\"\n\n# 获取元素个数\nSCARD test\n\n# 判断元素是否在集合中\nSISMEMBER test \"value3\"\n\n# 从集合中随机选出count个元素，元素不删除\nSRANDMEMBER test 2\n# 元素删除\nSPOP test 2\n````\n\n\n\n#### 运算操作\n\n````shell\n# 交集运算\nSINTER key [key ...]\n# 将交集结果存入新集合destination中\nSINTERSTORE destination key [key ...]\n\n# 并集运算\nSUNION key [key ...]\n# 将并集结果存入新集合destination中\nSUNIONSTORE destination key [key ...]\n\n# 差集运算\nSDIFF key [key ...]\n# 将差集结果存入新集合destination中\nSDIFFSTORE destination key [key ...]\n````\n\n注：交并差计算复杂度较高$O(n)$，数据量大时会导致redis实例阻塞\n\n\n\n#### 内部实现\n\n底层数据结构为`哈希表`或`整数集合`\n\n* 集合元素都为整数且个数小于512时，使用整数集合\n* 其余情况使用哈希表\n\n\n\n#### 应用场景\n\n集合的主要几个特性，无序、不可重复、支持并交差等操作。\n\n\n\n##### 点赞\n\n利用不可重复性\n\n保证一个用户只能点一个赞。\n\n如用户对某视频点赞：\n\n````shell\n# 点赞\nSADD video:1 uid:1\nSADD video:1 uid:2\n\n# 取消点赞\nSREM video:1 uid:1\n\n# 获取点赞总数\nSCARD video:1 \n\n# 判断用户是否点赞\nSISMEMBER video:1 uid:4\n````\n\n\n\n##### 共同关注\n\n利用交并差\n\nset支持交集运算，所以可用户计算共同相关量\n\n````shell\nSADD uid:1 1 2 3 4 5\nSADD uid:2 2 3 6 8 \n\n# 获取其共同关注\nSINTER uid:1 uid:2\n\n# 给uid:2 推荐uid:1的关注\nSDIFF uid1 uid:2\n````\n\n\n\n##### 抽奖活动\n\n利用唯一性，保证同一用户不会中奖两次，且保证随机数据源\n\nkey：活动名 value：参与者id\n\n````shell\nSADD lucky 1 2 3 4 6 7 8\n\n# 允许重复抽奖时，可使用SRANDMEMBER\nSRANDMEMBER lucky 1\n\n# 不允许重复时，使用SPOP\nSPOP lucky 2\n````\n\n\n\n### zset\n\n有序集合\n\n每个元素都会关联一个double类型的分数，通过分数来增序排列。\n\n成员唯一，但是分数score可重复。\n\n#### 常用命令\n\n````shell\n# 添加元素\nZADD key score value\n\n# 如\nZADD test 0 \"value1\"\nZADD test 1 \"value2\"\n\n# 返回元素分值\nZSCORE test \"value1\"\n\n# 返回元素个数\nZCARD test\n\n# 删除元素\nZREM test \"value1\"\n\n# 正序获取从start到stop的元素\nZRANGE test start stop [WITHSCORES]\n\n# 逆序获取\nZREVRANGE test start stop [WITHSCORES]\n\n# 获取指定分数区间元素，分数由高到低\nZRANGEBYSCORE test min max\n\n# 按字典序获取指定区间成员，分数必须相同。分数不同时返回结果不准。倒序使用ZREVRANGEBYLEX\n# min, max必须以[或(开头，可以使用-代替\nZRANGEBYLEX test min max\n\n# 获取指定元素排名（按分数从小到大）\nZRANK test \"value1\"\n\n# 从大到小\nZREVRANK test \"value1\"\n````\n\n#### 运算操作\n\n支持交并，不支持差\n\n````shell\n# 并集计算(相同元素分值相加)，numberkeys一共多少个key，WEIGHTS每个key对应的分值乘积\nZUNIONSTORE destkey numberkeys key [key...] \n# 交集计算(相同元素分值相加)，numberkeys一共多少个key，WEIGHTS每个key对应的分值乘积\nZINTERSTORE destkey numberkeys key [key...]\n````\n\n\n\n#### 内部实现\n\n底层数据结构使用`压缩列表`或`跳表`\n\n* 有序元素个数小于128，每个元素值小于64字节，使用压缩列表\n* 否则使用跳表\n\n7.0中，压缩列表废弃，使用`listpack`\n\n**为什么使用跳表而不是红黑树？**\n\n跳表复杂度和红黑树一样都是$O(\\log_{2}n)$，但是相对而言，跳表结构更简单，而且更适合zset的`ZRANGE`操作。\n\n\n\n#### 应用场景\n\nzset可以根据元素权重排序。\n\n适用于显示最新列表（插入时间为权重），排行榜等\n\n##### 排行榜\n\n以点赞数为例，某条博文下评论的点赞数\n\n````shell\nZADD blogcom:1 300 uid:1\nZADD blogcom:1 200 uid:2\n\n# 新增点赞\nZINCRBY blogcom:1 1 uid:1\n\n# 查看点赞数\nZSCORE blogcom:1 uid:1\n\n# 查看点赞数最多的三条\nZREVRANGE blogcom:1 0 2 WITHSCORES\n````\n\n\n\n## 特殊数据类型\n\n### BitMap\n\n即位图，是一串连续的二进制数组，可以通过偏移量(offset)定位元素。\n\nbitmap通过最小的单位bit来进行`0/1`的设置，表示某个元素的值或状态，时间复杂度为$O(1)$\n\n使用bit存储非常节省空间，适合大数量量且使用二值统计的场景。\n\n\n\n#### 常用命令\n\n````shell\n# 设置值，value只能为0, 1\nSETBIT key offset value\n\n# 获取值\nGETBIT key offset\n\n# 获取指定范围内1的个数，start和end以字节为单位，-1表示最后一个字节\nBITCOUNT key start end\n#如：\n# a: 0110 0001\t\n# b: 0110 0010\t\n# c: 0110 0011\n# mykey: 01100001 01100010 01100011\n127.0.0.1:6379> set mykey 'abc'\nOK\n\n# 统计整个字符串对应的bit=1的数量\n127.0.0.1:6379> bitcount mykey\n(integer) 10\n\n# a\n127.0.0.1:6379> bitcount mykey 0 0\n(integer) 3\n\n# ab\n127.0.0.1:6379> bitcount mykey 0 1\n(integer) 6\n````\n\n\n\n#### 运算操作\n\n````shell\n# BitMap间的运算\n# operations 位移操作符，枚举值\n  AND 与运算 &\n  OR 或运算 |\n  XOR 异或 ^\n  NOT 取反 ~\n# result 计算的结果，会存储在该key中\n# key1 … keyn 参与运算的key，可以有多个，空格分割，not运算只能一个key\n# 当 BITOP 处理不同长度的字符串时，较短的那个字符串所缺少的部分会被看作 0。返回值是保存到 destkey 的字符串的长度（以字节byte为单位），和输入 key 中最长的字符串长度相等。\nBITOP [operations] [result] [key1] [keyn…]\n\n# 返回指定key中第一次出现指定value(0/1)的位置\nBITPOS [key] [value]\n````\n\n\n\n\n\n#### 内部实现\n\n其底层数据结构为`string`，string是会保存为`二进制的字节数组`，所以，redis将字节数组的每个bit位都利用起来，用来表示一个元素的二值状态。可以将Bitmap看作一个`bit数组`。\n\n所以可以使用string值来set，其会自动转换为对应的ascii的二进制值。\n\n````shell\n# 可以直接使用string来set，会转换为其对应的ascii二进制，如可以：\nSET key 42\n# 42为：4为52，2为50 即为00110100 00110010\n# 然后可以通过GETBIT获取值\n````\n\n\n\n#### 应用场景\n\n适合二值(0/1)状态统计的场景\n\n##### 签到统计\n\n只记录签到(1)和未签到(0)\n\n每个用户每天的签到情况只需用一个bit为表示\n\n````shell\n# 记录6.3号签到\nSETBIT uid:1:202306 2 1\n\n# 查询是否已签到\nGETBIT uid:1:202306 2\n\n# 统计签到次数\nBITCOUNT uid:1:202306\n\n# 查询这个月第一次打卡的日期\n# 提供了：BITPOS key value [start] [end]范围第一次出现value的offset位置\nBITPOS uid:1:202306 1\n# 返回的值需+1\n````\n\n\n\n##### 判断用户登录状态\n\n基本同上\n\n\n\n##### 连续签到用户总数\n\n统计出连续7天签到用户总数\n\n1. 将每天的日期作为key，uid为offset，打卡值为1。则每个key表示某天用户的打卡记录\n2. 统计某7天，则对应有7个如此的bitmap，将这7天对应的Bit位做与运算，若全为1则说明连续打卡。\n3. 将结果保存至新的bitmap中，然后使用BITCOUNT计算总数\n\n使用`BITOP [operations] [result] [key1] [keyn…]`进行位操作\n\n````shell\n# 统计7天\nBITOP AND destmap bitmap:1 bitmap:2 bitmap:3 bitmap:4 bitmap:5 bitmap:6 bitmap:7\nBITCOUNT destmap\n````\n\n同时可以为每天的bitmap设置过期时间，节省内存\n\n\n\n### HyperLogLog\n\n是用于做基数（不同数据个数）统计的算法。【不精确】\n\n优点：在输入元素的数量或体积非常大时，计算基数所需空间总是固定的、很小的。\n\n只会根据输入元素来计算基数，不会储存元素本身，所以不能返回元素。\n\n#### 常用命令\n\n````shell\n# 添加元素\nredis> PFADD test 1 2 4 3 2 1\n(integer) 1\n# 返回基数估算值\nredis> PFCOUNT test\n(integer) 4\n\nredis> PFADD test2 2 4 5 6\n(integer) 1\nredis> PFCOUNT test2\n(integer) 4\n\n# 合并\nredis> PFMERGE testall test test2\n\"OK\"\nredis> PFCOUNT testall\n(integer) 6\n````\n\n使用场景：\n\n* 用于统计注册IP、访问IP数，在线用户数、搜索词条数量。即数据量比较大的，需要统计总数的场景。\n\n\n\n### GEO\n\n3.2版本新增，用于存储地理位置信息，并对存储的信息进行操作。\n\n\n\n#### 常用命令\n\n````shell\n# 存储指定的地理空间位置，可以将一个或多个经度(longitude)、纬度(latitude)、位置名称(member)添加到指定的 key 中。\nGEOADD key longitude latitude member [longitude latitude member ...]\n\n# 从给定的 key 里返回所有指定名称(member)的位置（经度和纬度），不存在的返回 nil。\nGEOPOS key member [member ...]\n\n# 返回两个给定位置之间的距离。\nGEODIST key member1 member2 [m|km|ft|mi]\n\n# 根据用户给定的经纬度坐标来获取指定范围内的地理位置集合。\nGEORADIUS key longitude latitude radius m|km|ft|mi [WITHCOORD] [WITHDIST] [WITHHASH] [COUNT count] [ASC|DESC] [STORE key] [STOREDIST key]\n# WITHDIST: 在返回位置元素的同时， 将位置元素与中心之间的距离也一并返回。\n# WITHCOORD: 将位置元素的经度和纬度也一并返回。\n# COUNT 限定返回的记录数。\n# ASC: 查找结果根据距离从近到远排序。\n# DESC: 查找结果根据从远到近排序。\n````\n\n\n\n#### 内部实现\n\n底层直接使用了`Sorted Set`\n\n使用GeoHash编码方法实现了经纬度到sorted set中元素权重分数的转换，这其中的两个关键机制就是「对二维地图做区间划分」和「对区间进行编码」。一组经纬度落在某个区间后，就用区间的编码值来表示，并把编码值作为 Sorted Set 元素的权重分数。\n\n这样一来，我们就可以把经纬度保存到 Sorted Set 中，利用 Sorted Set 提供的“按权重进行有序范围查找”的特性，实现 LBS(Location-Based Service) 服务中频繁使用的“搜索附近”的需求。\n\n\n\n##### 使用场景\n\n打车\n\n假设车辆 ID 是 33，经纬度位置是（116.034579，39.030452），我们可以用一个 GEO 集合保存所有车辆的经纬度，集合 key 是 cars:locations。\n\n````shell\nGEOADD cars:locations 116.034579 39.030452 33\n````\n\n当用户想要寻找自己附近的网约车时，LBS 应用就可以使用 GEORADIUS 命令。\n\n如以下，Redis 会根据输入的用户的经纬度信息（116.054579，39.030452 ），查找以这个经纬度为中心的 5 公里内的车辆信息，并返回给 LBS 应用。\n\n````shell\nGEORADIUS cars:locations 116.054579 39.030452 5 km ASC COUNT 10\n````\n\n\n\n## 发布订阅\n\npub/sub是一种消息通信模式\n\nredis客户端可以订阅任意数量的频道\n\n![img](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202402011544135.png)\n\n有新消息通过PUBLISH命令发送给频道channel1时，该消息会被发送给订阅它的三个客户端\n\n````shell\n# 订阅频道\nSUBSCRIBE testChannel\n\n# 发布消息\nPUBLISH testChannel \"this is a message\"\n\n# 订阅的客户端会受到\n1) \"message\"\n2) \"testChannel\"\n3) \"this is a message\"\n````\n\n注：pub/sub可以分发消息，但是无法记录历史消息\n\n**发布/订阅机制为什么不可做消息队列？**\n\n数据丢失\n\n* 不具备数据持久化能力，即其相关操作不会写入到RDB和AOF中，redis宕机后，其数据会全部丢失\n* 是“发后即忘”的工作模式，有订阅者离线重连后不能消费之前的历史消息。\n* 消费端有一定的消息积压时，若超过32M或60s内持续保持8M以上，消费端会被强行断开。该参数在配置文件中：`client-output-buffer-limit pubsub 32mb 8mb 60`\n\n故发布订阅机制只适合即时通讯的场景。如构建哨兵集群的场景就使用了发布订阅机制。\n\n\n\n## Stream\n\n5.0新增，主要用于消息队列（MQ，Message Queue）\n\n支持消息的持久化、支持自动生成全局唯一 ID、支持 ack 确认消息的模式、支持消费组模式等，让消息队列更加的稳定和可靠。\n\n提供了消息的持久化和主备复制功能，可以让任何客户端访问任何时刻的数据，并且能记住每一个客户端的访问位置，还能保证消息不丢失。\n\n其结构如下，有一个消息链表，将所有加入的消息都串起来，每个消息都有唯一的ID与对应的内容：\n\n![img](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202402011546127.png)\n\n每个 Stream 都有唯一的名称，它就是 Redis 的 key，在我们首次使用` xadd` 指令追加消息时自动创建。\n\n- Consumer Group ：消费组，使用 `XGROUP CREATE` 命令创建，一个消费组有多个消费者(Consumer)。\n- last_delivered_id ：游标，每个消费组会有个游标 last_delivered_id，任意一个消费者读取了消息都会使游标 last_delivered_id 往前移动。\n- pending_ids：消费者(Consumer)的状态变量，作用是维护消费者的未确认的 id。 pending_ids 记录了当前已经被客户端读取的消息，但是还没有 ack (Acknowledge character：确认字符）。\n\n\n\n### 消息队列相关命令：\n\n- `XADD` - 添加消息到末尾吗，队列不存在时自动创建队列\n\n  ````shell\n  XADD key ID field value [field value ...]\n  ````\n\n  * key：队列名称\n\n  * ID：消息ID，使用`*`表示redis自动生成。自定义时需保证递增性\n\n    自动生成的id如：`\"1654254953808-0\"`,其中前半部分为数据插入时，以毫秒为单位计算的当前服务器时间；后半部分为该毫秒内的第1条消息\n\n  * field value ：记录\n\n  \n\n- `XTRIM` - 对流进行修剪，限制长度\n\n  ````shell\n  XTRIM key MAXLEN [~] count\n  ````\n\n  * MAXLEN：长度\n  * count：数量\n  * `~`：并不是精确要求count条，但是绝不能少于count；可以提高效率\n\n  \n\n- `XDEL` - 删除消息\n\n  ````shell\n  XDEL key ID [ID ...]\n  ````\n\n  \n\n- `XLEN`- 获取流包含的元素数量，即消息长度\n\n  ````shell\n  XLEN key\n  ````\n\n  \n\n- `XRANGE` - 获取消息列表，会自动过滤已经删除的消息\n\n  ````shell\n  XRANGE key start end [COUNT count]\n  ````\n\n  * start：`-`表示最小值\n  * end：`+`表示最大值\n\n  \n\n- `XREVRANGE` - 反向获取消息列表，ID 从大到小\n\n  语法用XRANGE\n\n  \n\n- `XREAD`- 以阻塞或非阻塞方式获取消息列表\n\n  ````shell\n  XREAD [COUNT count] [BLOCK miliseconds] STREAMS key [key ...] id [id ...]\n  ````\n\n  * miliseconds：阻塞毫秒数，可选，无就是默认非阻塞模式\n  * 从指定id的消息开始读取\n\n\n\n以上操作使用list也可以实现，而消费者组是stream所特有的。\n\n\n\n### 消费组相关命令\n\n- `XGROUP CREATE` - 创建消费者组\n\n  ````shell\n  XGROUP [CREATE key groupname id-or-$] \n  ````\n\n  * `$`：表示从尾部开始消费，只接受新消息，当前stream的消息会被全部忽略\n  * id为0时表示从所有历史消息开始\n\n  \n\n- `XREADGROUP GROUP` - 读取消费者组中的消息\n\n  ````shell\n  XREADGROUP GROUP group consumer [COUNT count] [BLOCK milliseconds] [NOACK] STREAMS key [key ...] ID [ID ...]\n  ````\n\n  从指定ID的消息开始读取：使用`>`表示从第一条尚未被消费的消息开始读取\n\n  **注**：【消息队列中的消息一旦被消费者组中的一个消费者读取了，就不能再被该消费者组中其他消费者读取，即同一消费者组中的消费者不能消费同一条消息。】\n\n  【但是可以被不同消费者组中的消费者读取（但是有前提条件，创建消息组的时候，不同消费组指定了相同位置开始读取消息）。】\n\n  使用消费组的目的是让组内的多个消费者共同分担读取消息，所以，我们通常会让每个消费者读取部分消息，从而实现消息读取负载在多个消费者间是均衡分布的。\n\n- `XACK` - 将消息标记为\"已处理\"\n\n- `XGROUP DELCONSUMER` - 删除消费者\n\n- `XGROUP DESTROY` - 删除消费者组\n\n- `XPENDING` - 显示待处理消息的相关信息\n\n- `XINFO` - 查看流和消费者组的相关信息；\n\n- `XINFO GROUPS` - 打印消费者组的信息；\n\n- `XINFO STREAM` - 打印流信息\n\n\n\n**基于 Stream 实现的消息队列，如何保证消费者在发生故障或宕机再次重启后，仍然可以读取未处理完的消息？**\n\nStreams 会自动使用内部队列（也称为 PENDING List）留存消费组里每个消费者读取的消息，直到消费者使用` XACK `命令通知 Streams“消息已经处理完成”。\n\n消费确认增加了消息的可靠性，一般在业务处理完成之后，需要执行` XACK` 命令确认消息已经被消费完成\n\n![img](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202402011546172.png)\n\n如果消费者没有成功处理消息，它就不会给 Streams 发送 `XACK` 命令，消息仍然会留存。此时，消费者可以在重启后，用 `XPENDING `命令查看已读取、但尚未确认处理完成的消息。\n\n\n\n### 问题\n\n专业的消息队列需满足：\n\n* 消息不丢\n* 消息可堆积\n\n\n\n**1. redis消息会丢失吗？**\n\n消息队列三大块：\n\n* 生产者\n* 队列中间件\n* 消费者\n\n想要保证消息不丢失，即保证以上三个环节消息都不丢失\n\n![img](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202402011547779.png)\n\n* 生产者：生产者是否会丢失消息，取决于生产者对异常情况的处理是否合理。从消息生产到提交给MQ，只要能正常收到MQ中间件的ack确认响应，就表示发送成功，所以只需处理好返回值和异常，返回异常则进行消息重发，则此阶段不会出现消息丢失。\n* 消费者：不会丢失消息。因为stream(MQ中间件)会自动使用内部队列(pending list)留存消费组中每个消费者读取但未被确认的消息。消费者重启后，用`XPENDING`查看已被读取，但未确认处理完成的消息，等其执行完业务逻辑后，再发送消费确认`XACK`命令，消息不会丢失。\n* 消息中间件：会丢失消息。redis在以下两个场景，都会导致消息丢失：\n  * AOF持久化配置为每秒写盘，但该写过程是异步的，redis宕机时可能存在数据丢失的可能\n  * 主从复制也是异步的，主从切换时，也存在数据丢失的可能。\n\n类似kafka这样的专业队列中间件，使用时部署一个集群，其中一个节点挂了也不会导致数据丢失\n\n\n\n**2. redis消息可堆积吗？**\n\nRedis 的数据都存储在内存中，这就意味着一旦发生消息积压，则会导致 Redis 的内存持续增长，如果超过机器内存上限，就会面临被 OOM 的风险。\n\n所以 Redis 的 Stream 提供了可以指定队列最大长度的功能，就是为了避免这种情况发生。\n\n当指定队列最大长度时，队列长度超过上限后，旧消息会被删除，只保留固定长度的新消息。这么来看，Stream 在消息积压时，如果指定了最大长度，还是有可能丢失消息的。\n\n\n\n## 事务\n\n事务可以一次执行多条命令，并有以下保证：\n\n* 批量操作在发送 `EXEC` 命令前被放入队列缓存。\n* 收到 `EXEC` 命令后进入事务执行，事务中任意命令执行失败，其余的命令依然被执行。\n* 在事务执行过程，其他客户端提交的命令请求不会插入到事务执行命令序列中。\n\n一个事务从开始到执行的三个阶段：\n\n1. 开始事务\n2. 命令入队\n3. 执行事务\n\n````shell\n# 开启事务\nredis> MULTI\nOK\n\n# 命令入队\nredis> SET book-name \"Mastering C++ in 21 days\"\nQUEUED\n\nredis> GET book-name\nQUEUED\n\nredis> SADD tag \"C++\" \"Programming\" \"Mastering Series\"\nQUEUED\n\nredis> SMEMBERS tag\nQUEUED\n\n# 执行事务\nredis> EXEC\n1) OK\n2) \"Mastering C++ in 21 days\"\n3) (integer) 3\n4) 1) \"Mastering Series\"\n   2) \"C++\"\n   3) \"Programming\"\n````\n\n单个redis命令是原子性的，但是事务执行并不是原子性的。事务类似于批量执行的脚本，但中间命令失败不影响后面指令（无回滚和中断）。\n\n\n\n## 脚本\n\n使用Lua解释器执行脚本，执行常用命令为`EVAL`\n\n````shell\nredis> EVAL script numkeys key [key ...] arg [arg ...]\n````\n\n如：\n\n````shell\nredis> EVAL \"return {KEYS[1],KEYS[2],ARGV[1],ARGV[2]}\" 2 key1 key2 first second\n\n1) \"key1\"\n2) \"key2\"\n3) \"first\"\n4) \"second\"\n````\n\n\n\n## 数据备份与恢复\n\n备份：\n\n````shell\n# save时阻塞主进程，save完成后，主进程才开始工作\nSAVE\n\n# 也可以使用BGSAVE，区别是bgsave是在后台执行，fork了一个专门的save子进程，不会影响主进程\nBGSAVE\n````\n\n会在redis安装目录中创建`dump.rdb`文件\n\n\n\n数据恢复：\n\n只需将`dump.rdb`文件移动到redis安装目录并启动服务即可。\n\n````shell\n# 获取redis安装目录\nCONFIG GET dir\n````\n\n\n\n## 性能测试\n\n````shell\nredis-benchmark [option] [option value]\n````\n\n| 序号 | 选项               | 描述                                       | 默认值    |\n| :--- | :----------------- | :----------------------------------------- | :-------- |\n| 1    | -h                 | 指定服务器主机名                           | 127.0.0.1 |\n| 2    | -p                 | 指定服务器端口                             | 6379      |\n| 3    | -s                 | 指定服务器 socket                          |           |\n| 4    | -c                 | 指定并发连接数                             | 50        |\n| 5    | -n                 | 指定请求数                                 | 10000     |\n| 6    | -d                 | 以字节的形式指定 SET/GET 值的数据大小      | 2         |\n| 7    | -k                 | 1=keep alive 0=reconnect                   | 1         |\n| 8    | -r                 | SET/GET/INCR 使用随机 key, SADD 使用随机值 |           |\n| 9    | -P                 | 通过管道传输 <numreq> 请求                 | 1         |\n| 10   | -q                 | 强制退出 redis。仅显示 query/sec 值        |           |\n| 11   | --csv              | 以 CSV 格式输出                            |           |\n| 12   | -l（L 的小写字母） | 生成循环，永久执行测试                     |           |\n| 13   | -t                 | 仅运行以逗号分隔的测试命令列表。           |           |\n| 14   | -I（i 的大写字母） | Idle 模式。仅打开 N 个 idle 连接并等待。   |           |\n\n\n\n## 分区\n\n### 分区特点\n\n分区是分割数据到多个redis实例的处理过程，每个实例只保存key的一个子集。\n\n优点：\n\n* 利用多台计算机内存的和值，可以构造更大的数据库\n* 通过多核和多台计算机，可以扩展计算能力\n* 通过多台计算机和网络适配器，允许扩展网络带宽\n\n缺点：\n\n* 涉及多个key的操作不被支持\n* 涉及多个key的事务不能使用\n* 使用分区时，数据处理较复杂\n* 增加与删除容量也比较复杂\n\n\n\n### 分区类型\n\n假设有`n`个redis实例\n\n#### 范围分区\n\n即映射一定范围的对象到特定的redis实例\n\n不足：需要有区间范围到实例的映射表，该表需要被管理，同时需各种对象的映射表，通常不算好。\n\n\n\n#### 哈希分区\n\n1. 使用哈希函数转换key为一个数字\n2. 对该整数取模，将其转化为`0-(n-1)`之间的数字，将该整数映射到`n`个redis实例中的其中一个\n\n\n\n\n\n\n\n## Redis持久化\n\nredis不同于memcached的最重要的一点就是其支持持久化。有以下三种持久化方式：\n\n* 快照(snapshotting, RDB)\n* 只追加文件(append-only files, AOF)\n* RDB 和 AOF 的混合持久化(Redis 4.0 新增)\n\n\n\n### RDB\n\n通过创建快照（全量快照）来获得存储在内存里的数据在某个时间点上的副本。\n\n创建快照后，可以对快照进行备份，可以将其赋值到其他服务器从而创建具有相同数的服务器副本（Redis 主从结构，主要用来提高 Redis 性能）。还可以将快照留在原地以便重启服务器时使用。\n\n快照是redis默认采用的持久化方式。在redis.conf中：\n\n````\nsave 900 1           #在900秒(15分钟)之后，如果至少有1个key发生变化，Redis就会自动触发bgsave命令创建快照。\n\nsave 300 10          #在300秒(5分钟)之后，如果至少有10个key发生变化，Redis就会自动触发bgsave命令创建快照。\n\nsave 60 10000        #在60秒(1分钟)之后，如果至少有10000个key发生变化，Redis就会自动触发bgsave命令创建快照。\n````\n\n**RDB创建快照是会阻塞主线程吗？**\n\n提供了两个命令来生成快照文件：\n\n* `SAVE`：同步保存，会阻塞redis主线程\n* `BGSAVE`：fork出子进程，不阻塞主线程，默认选项。\n\n\n\n### AOF\n\n#### 工作流程\n\nredis默认不开启AOF（6.0后默认开启），未开启时可以通过`appendonly yes`开启\n\n总而体验，AOF的工作流程如下：\n\n1. **命令追加append**：所有`写命令`都会被追加到AOF缓冲区中\n\n2. **文件写入write**：将AOF缓冲区数据写入到AOF文件中，系统会调用`write`函数。`write`将数据写入到了系统内核缓冲区之后直接返回了（延迟写，即不会立马同步到硬盘）。注意！！！此时并没有同步到磁盘。\n\n3. **文件同步fsync**：根据持久化方式（`fsync`策略）向硬盘做同步操作，系统会调用`fsync`函数。`fsync`针对单个文件操作，对其进行强制硬盘同步。`fsync`将阻塞直到写入硬盘完成后返回，保证了数据持久化。\n\n4. **文件重写rewrite**：随着AOF文件越来越大，需对AOF文件进行重写，达到压缩的目的\n\n   >重写的新文件与原AOF文件所保存的数据库状态一样，但是体积更小。\n   >\n   >该功能是通过读取数据库中的键值对来实现的（即读取最新的键值对），程序无须对现有 AOF 文件进行任何读入、分析或者写入操作。\n   >\n   >大量写入操作，防止对正常处理命令造成影响，将其放入子进程中执行\n   >\n   >重写期间，Redis还会维护一个**AOF重写缓冲区**，该缓冲区会在子进程创建新 AOF 文件期间，记录服务器执行的所有写命令。当子进程完成创建新 AOF 文件的工作之后，服务器会将重写缓冲区中的所有内容追加到新 AOF 文件的末尾，使得新的 AOF 文件保存的数据库状态与现有的数据库状态一致。最后，服务器用新的 AOF 文件替换旧的 AOF 文件，以此来完成 AOF 文件重写操作。\n   >\n   >**重写开启**\n   >\n   >1. 调用`BGREWRITEAOF`手动执行\n   >2. 设置配置项，让程序自动决定触发时机：\n   >  * `auto-aof-rewrite-min-size`：如果 AOF 文件大小小于该值，则不会触发 AOF 重写。默认值为 64 MB;\n   >  * `auto-aof-rewrite-percentage`：执行 AOF 重写时，当前 AOF 大小（aof_current_size）和上一次重写时 AOF 大小（aof_base_size）的比值。如果当前 AOF 文件大小增加了这个百分比值，将触发 AOF 重写。将此值设置为 0 将禁用自动 AOF 重写。默认值为 100。\n\n5. **重启加载load**：redis重启时，可以加载AOF文件进行数据恢复\n\n只有同步到硬盘才算持久化保存了，否则依然有数据丢失的风险。如系统内核缓存区的数据还未同步，磁盘机器就宕机了。\n\nAOF文件的保存文件通RDB文件位置，都是通过`dir`设置的，默认文件名为`appendonly.aof`\n\n\n\n#### AOF为什么在执行完命令之后记录日志\n\n关系型数据库（如 MySQL）通常都是执行命令之前记录日志（方便故障恢复），而 Redis AOF 持久化机制是在执行完命令之后再记录日志。即先执行写命令，再记录到AOF文件中\n\nwhy?\n\n* 避免额外的检查开销，AOF记录日志不会对命令进行语法检查\n* 命令执行完后再记录，不会阻塞当前命令的执行\n\n问题：\n\n* 刚执行完命令redis就宕机，会导致数据丢失\n* 可能阻塞后续其他命令执行（AOF记录日志是在redis主线程中进行）\n\n\n\n#### 持久化方式（fsync策略）\n\n1. `appendfsync always`：主线程调用 `write` 执行写操作后，后台线程（ `aof_fsync` 线程）立即会调用 `fsync` 函数同步 AOF 文件（刷盘），`fsync` 完成后线程返回，这样会严重降低 Redis 的性能（`write` + `fsync`）。\n2. `appendfsync everysec`：主线程调用 `write` 执行写操作后立即返回，由后台线程（ `aof_fsync` 线程）每秒钟调用 `fsync` 函数（系统调用）同步一次 AOF 文件（`write`+`fsync`，`fsync`间隔为 1 秒）\n3. `appendfsync no`：主线程调用 `write` 执行写操作后立即返回，让操作系统决定何时进行同步，Linux 下一般为 30 秒一次（`write`但不`fsync`，`fsync` 的时机由操作系统决定）。\n\n可见，其差别主要在于`fsync`同步AOF文件的时机（刷盘）\n\n\n\n\n\n#### AOF校验机制\n\nAOF 校验机制是 Redis 在启动时对 AOF 文件进行检查，以判断文件是否完整，是否有损坏或者丢失的数据。\n\n这个机制的原理是通过使用一种叫做 **校验和（checksum）** 的数字来验证 AOF 文件。这个校验和是通过对整个 AOF 文件内容进行 CRC64 算法计算得出的数字。如果文件内容发生了变化，那么校验和也会随之改变。\n\n因此，Redis 在启动时会比较计算出的校验和与文件末尾保存的校验和（计算的时候会把最后一行保存校验和的内容给忽略掉），从而判断 AOF 文件是否完整。\n\n如果发现文件有问题，Redis 就会拒绝启动并提供相应的错误信息。AOF 校验机制十分简单有效，可以提高 Redis 数据的可靠性。\n\n类似地，RDB 文件也有类似的校验机制来保证 RDB 文件的正确性。\n\n\n\n### RDB 和 AOF 的混合持久化(Redis 4.0 新增)\n\nRedis 4.0 开始支持 RDB 和 AOF 的混合持久化（默认关闭，可以通过配置项 `aof-use-rdb-preamble` 开启）。\n\n如果把混合持久化打开，AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头。\n\n优点：可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据。\n\n缺点：AOF 里面的 RDB 部分是压缩格式不再是 AOF 格式，可读性较差。\n\n\n\n### RDB vs. AOF\n\n**RDB 比 AOF 优秀的地方**：\n\n- RDB 文件存储的内容是经过压缩的二进制数据， 保存着某个时间点的数据集，文件很小，适合做数据的备份，灾难恢复。AOF 文件存储的是每一次写命令，类似于 MySQL 的 binlog 日志，通常会比 RDB 文件大很多。当 AOF 变得太大时，Redis 能够在后台自动重写 AOF。新的 AOF 文件和原有的 AOF 文件所保存的数据库状态一样，但体积更小。不过， Redis 7.0 版本之前，如果在重写期间有写入命令，AOF 可能会使用大量内存，重写期间到达的所有写入命令都会写入磁盘两次。\n- 使用 RDB 文件恢复数据，直接解析还原数据即可，不需要一条一条地执行命令，速度非常快。而 AOF 则需要依次执行每个写命令，速度非常慢。也就是说，与 AOF 相比，恢复大数据集的时候，RDB 速度更快。\n\n**AOF 比 RDB 优秀的地方**：\n\n- RDB 的数据安全性不如 AOF，没有办法实时或者秒级持久化数据。生成 RDB 文件的过程是比较繁重的， 虽然 BGSAVE 子进程写入 RDB 文件的工作不会阻塞主线程，但会对机器的 CPU 资源和内存资源产生影响，严重的情况下甚至会直接把 Redis 服务干宕机。AOF 支持秒级数据丢失（取决 fsync 策略，如果是 everysec，最多丢失 1 秒的数据），仅仅是追加命令到 AOF 文件，操作轻量。\n- RDB 文件是以特定的二进制格式保存的，并且在 Redis 版本演进中有多个版本的 RDB，所以存在老版本的 Redis 服务不兼容新版本的 RDB 格式的问题。\n- AOF 以一种易于理解和解析的格式包含所有操作的日志。你可以轻松地导出 AOF 文件进行分析，你也可以直接操作 AOF 文件来解决一些问题。比如，如果执行`FLUSHALL`命令意外地刷新了所有内容后，只要 AOF 文件没有被重写，删除最新命令并重启即可恢复之前的状态.\n\n**综上**：\n\n- Redis 保存的数据丢失一些也没什么影响的话，可以选择使用 RDB。\n- 不建议单独使用 AOF，因为时不时地创建一个 RDB 快照可以进行数据库备份、更快的重启以及解决 AOF 引擎错误。\n- 如果保存的数据要求安全性比较高的话，建议同时开启 RDB 和 AOF 持久化或者开启 RDB 和 AOF 混合持久化。\n\n\n\n## 性能优化\n\n**1. 使用批量操作减少网络传输** \n\n一个 Redis 命令的执行可以简化为以下 4 步：\n\n1. 发送命令\n2. 命令排队\n3. 命令执行\n4. 返回结果\n\n1和4消耗的时间为RTT(往返时间)，即数据在网络上传输的时间\n\n可以使用批量操作减少网络传输次数，进而有效减少网络开销，大幅减少RTT。\n\n此外，发送一次命令的 socket I/O 成本也比较高（涉及上下文切换，存在`read()`和`write()`系统调用），批量操作还可以减少 socket I/O 成本。\n\n* 原生批量操作：如MSET, MGET, HSET, SADD【原子操作】\n* pipeline：不支持批量操作的命令，可以使用pipeline将一批命令封装成一组，这些命令会被一次性提交到redis服务器，只需一次网络传输。不过，需控制一次批量操作的元素个数，避免实际网络传输的数据量过大【非原子操作】\n\n都存在的问题：无法保证所有的 key 都在同一个 hash slot（哈希槽）上\n\n\n\n**2. 大量key集中过期问题**\n\n对过期key，redis采用：定期删除+惰性/懒汉式删除\n\n定期删除执行过程中，如果突然遇到大量过期 key 的话，客户端请求必须等待定期清理过期 key 任务线程执行完成，因为这个这个定期任务线程是在 Redis 主线程中执行的。这就导致客户端请求没办法被及时处理，响应速度会比较慢。\n\n解决方法：\n\n* 给key设置随机过期时间\n* 开启lazy-free（惰性删除/延迟释放），即让redis采用异步方法延迟释放key使用的内存，该操作交由单独的子线程处理，避免阻塞主线程。\n\n\n\n**3. bigkey(大key)**\n\nBigkey：key对应的value占用的内存较大。\n\n危害：除了会消耗更多的内存空间和带宽外，还会对性能造成较大影响\n\n如何发现bigkey?\n\n* 使用redis自带的`--bigkeys`参数来查找\n\n  > 会扫描所有key，对性能有一点影响。且只能找出每种数据结构的top 1 bigkey\n  >\n  > 为降低对redis影响，可以使用`-i`参数控制扫描频率，单位为s\n\n* 借助开源工具分析RDB文件\n\n  > 如果采用的是RDB持久化\n\n* 借助公有云的redis分析服务\n\n如何处理bigkey?\n\n* **分割 bigkey**：将一个 bigkey 分割为多个小 key。这种方式需要修改业务层的代码，一般不推荐这样做。\n\n* **手动清理**：Redis 4.0+ 可以使用 `UNLINK` 命令来异步删除一个或多个指定的 key。Redis 4.0 以下可以考虑使用 `SCAN` 命令结合 `DEL` 命令来分批次删除。\n\n* **采用合适的数据结构**：比如使用 HyperLogLog 统计页面 UV。\n\n* **开启 lazy-free（惰性删除/延迟释放）** ：lazy-free 特性是 Redis 4.0 开始引入的，指的是让 Redis 采用异步方式延迟释放 key 使用的内存，将该操作交给单独的子线程处理，避免阻塞主线程.\n\n  \n\n**4. hotkey(热key)**\n\nhotkey：一个key的访问次数明显多于其他key\n\n出现原因：某个热点数据访问量暴增\n\n**危害**\n\n* 处理hotkey会占用大量CPU与带宽，可能影响redis实例对其他请求的处理\n* 访问hotkey的请求超过了redis的处理能力，会造成redis直接宕机，然后大量请求将会落在数据库上，可能导致数据库崩溃\n\n故hotkey可能称为系统性能瓶颈点，需对其进行单独优化，保证系统高可用性和稳定性\n\n**如何发现hotkey?**\n\n* 使用redis自带的`--hotkeys`来查找\n\n  该参数能够返回所有 key 的被访问次数。会增加 Redis 实例的 CPU 和内存消耗（全局扫描），因此需要谨慎使用。\n\n  使用该方案的前提条件是 Redis Server 的 `maxmemory-policy` 参数设置为 LFU 算法，不然就会出现如下所示的错误。\n\n  >Redis 中有两种 LFU 算法：\n  >\n  >1. **volatile-lfu（least frequently used）**：从已设置过期时间的数据集（`server.db[i].expires`）中挑选最不经常使用的数据淘汰。\n  >2. **allkeys-lfu（least frequently used）**：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key。\n\n* 使用`MONITOR`命令\n\n  可以时查看 Redis 的所有操作，可以用于临时监控 Redis 实例的操作情况，包括读写、删除等操作。\n\n  该命令对 Redis 性能的影响比较大，因此禁止长时间开启 `MONITOR`（生产环境中建议谨慎使用该命令）。\n\n  紧急情况下可以在合适实际短暂使用该命令并输出至重定向文件，然后关闭命令、分析文件后找出hotkey\n\n* 借助开源项目\n\n* 根据业务情况提前预估\n\n* 业务代码中记录分析：会增加代码复杂度\n\n* 借助公有云的redis分析服务\n\n\n\n**如何解决hotkey?**\n\n**读写分离**：主节点处理写请求，从节点处理读请求。\n\n**使用 Redis Cluster**：将热点数据分散存储在多个 Redis 节点上。\n\n**二级缓存**：hotkey 采用二级缓存的方式进行处理，将 hotkey 存放一份到 JVM 本地内存中（可以用 Caffeine）。\n\n\n\n**5. 慢查询命令**\n\n慢查询统计的是`命令执行`这一步的耗时，慢查询命令即为命令执行时间较长的命令\n\nredis中大部分命令都是$O(1)$的时间复杂度，但也有少部分 $O(n)$的，如：LRANGE, HGETALL, SMEMBERS, SINTER, SUNION, SDIFF\n\n除了这些 $O(n)$时间复杂度的命令可能会导致慢查询之外， 还有一些时间复杂度可能在$ O(N) $以上的命令，如：`ZRANGE`为$O(log_{2}n+m)$，m为返回元素个数，m很大时，$O(n)$时间复杂度更低\n\n**如何找到慢查询命令？**\n\n在`redis.conf`中使用`slowlog-log-slower-than`参数设置耗时命令的阈值，并使用`slowlog-max-len`参数设置耗时命令的最大记录条数（也可以通过`CONF`命令直接设置）\n\n当 Redis 服务器检测到执行时间超过 `slowlog-log-slower-than`阈值的命令时，就会将该命令记录在慢查询日志(slow log) 中，这点和 MySQL 记录慢查询语句类似。当慢查询日志超过设定的最大记录条数之后，Redis 会把最早的执行命令依次舍弃。\n\n获取慢查询日志：`SLOWLOG GET`，默认返回最近 10 条的的慢查询命令，也可以指定返回的慢查询命令的数量 `SLOWLOG GET N`。\n\n\n\n**6. redis内存碎片**\n\n**为什么会有内存碎片？**\n\n1. 存储数据时向系统申请的内存空间大于数据实际需要的存储空间\n2. 频繁修改redis中的数据时产生\n\n查看内存碎片：`info memory`\n\n**如何清理内存碎片？**\n\nRedis4.0-RC3 版本以后自带了内存整理，可以避免内存碎片率过大的问题。\n\n直接通过 `config set` 命令将 `activedefrag` 配置项设置为 `yes` 即可。\n\n\n\n## 生产问题\n\n### 缓存穿透\n\n定义：大量请求的key是不合理的，其不存在于缓存中，也不存在于数据库中，导致请求在访问缓存时，发现缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据，没办法构建缓存数据，来服务后续的请求。那么当有大量这样的请求到来时，数据库的压力骤增，这就是**缓存穿透**的问题。\n\n发生情况：\n\n* 业务误操作\n* 恶意攻击\n\n应对方案：\n\n**1. 非法请求的限制**\n\n做好参数校验，判断出恶意请求就直接返回错误\n\n**2. 缓存空值或默认值**\n\n发现存在缓存穿透的现象，可以针对查询数据，在缓存中设置空值或无效值，后续查询可以直接返回该无效值。\n\n适用于key变化不频繁的场景，存在大量无效key时依然不能解决。\n\n**3. 使用布隆过滤器快速判断数据是否存在，避免查询数据库判断其是否存在**\n\n把所有可能存在的请求的值都存放在布隆过滤器中，当用户请求过来，先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会走下面的流程。\n\n即使发生了缓存穿透，大量请求只会查询 Redis 和布隆过滤器，而不会查询数据库，保证了数据库能正常运行，Redis 自身也是支持布隆过滤器的。\n\n**注**：布隆过滤器可能会存在误判的情况。总结来说就是：**布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在**。\n\n将一个元素加入布隆过滤器，会进行：\n\n1. 使用布隆过滤器中的哈希函数对元素值进行计算得到哈希值（几个哈希函数得几个哈希值）\n2. 根据得到的哈希值，在位数组中将其对应下标置1\n\n判断元素是否存在于布隆过滤器：\n\n1. 对元素再次进行相同的哈希计算【判断时可能存在哈希冲突，即不同元素的哈希值相同】\n2. 得到值后判断位数组中的每个元素是否都为1，都为1时，说明在布隆过滤器中，否则，则说明不在布隆过滤器中\n\n\n\n### 缓存击穿\n\n定义：请求的key对应的是热点数据，该数据存在于数据库中，但是不存在于缓存中（通常由于已过期），则会导致大量请求直接发送给数据库，造成数据库宕机。\n\n解决办法：\n\n* 设置热点数据永不过期或过期时间较长\n* 针对热点数据提前预热，将其存入缓存中并设置合理的过期时间\n* 请求数据库写数据到缓存之前，先获取互斥锁，保证只有一个请求会落到数据库上，减少数据库的压力\n\n\n\n\n\n### 缓存雪崩\n\n定义：缓存在同一时间大面积失效，导致大量请求都直接落在数据库上，对数据库造成了巨大压力，导致其宕机。\n\n缓存服务宕机也会导致请求直接落在数据库上，造成缓存雪崩。\n\n**解决办法**：\n\n1. 针对redis服务不可用：\n   * 采用redis集群，避免单机出问题导致整个缓存服务都无法使用\n   * 限流，避免同时处理大量请求\n2. 针对缓存失效问题：\n   * 设置不同的失效时间，如随机设置缓存的失效时间\n   * 缓存永不失效（实用性差）\n   * 设置二级缓存\n\n缓存击穿可以看作缓存雪崩的一种\n\n\n\n## 如何保证缓存和数据库数据一致性\n\n数据更新：无论是先更新数据库还是先更新缓存，都存在并发问题。当两个请求并发更新同一条数据时，可能出现缓存中和数据中的数据不一致的情况。\n\n**Cache Aside Pattern**旁路缓存策略：先更新数据库，再删除缓存\n\n其中又分为两个策略：读策略和写策略\n\n写策略：\n\n1. 更新数据库中的数据\n2. 删除缓存中的数据\n\n读策略：\n\n1. 读取的数据命中缓存则直接返回\n2. 未命中缓存，从数据库中读取数据，将数据写入缓存并返回\n\n如果更新数据库成功，而删除缓存这一步失败的情况的话，简单说两个解决方案：\n\n1. **缓存失效时间变短（不推荐，治标不治本）**：我们让缓存数据的过期时间变短，这样的话缓存就会从数据库中加载数据。另外，这种解决办法对于先操作缓存后操作数据库的场景不适用。\n2. **增加 cache 更新重试机制（常用）**：如果 cache 服务当前不可用导致缓存删除失败的话，我们就隔一段时间进行重试，重试次数可以自己定。如果多次重试还是失败的话，我们可以把当前更新失败的 key 存入队列中，等缓存服务可用之后，再将缓存中对应的 key 删除即可。\n\n\n\n参考：\n\n[小林Coding Redis](https://xiaolincoding.com/redis/data_struct/command.html#%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF-9)\n\n[菜鸟教程Redis](https://www.runoob.com/redis/redis-stream.html)","tags":["Redis"],"categories":["Learning","DataBase"]},{"title":"leetcode记录","url":"/post/f8355b15.html","content":"\n一些比较杂乱的刷题记录和总结\n\n<!-- more -->\n\n公共最长子序列\n\n````java\nint longestCommonSubsequence(String text1, String text2) {\n        if(text1.length() <= 0 || text2.length() <= 0){\n            return 0;\n        }\n        int [][] dp = new int[text1.length()][text2.length()];\n        dp[0][0] = text1.charAt(0) == text2.charAt(0) ? 1 : 0;\n        for(int i = 0; i < text1.length() ; i++){\n            for(int j = 0; j < text2.length() ; j++){\n                //特殊情况\n                if( i == 0 || j == 0){\n                    dp[i][j] = dp[0][0];\n                }\n                else if(text1.charAt(i) == text2.charAt(j)){\n                    dp[i][j] = dp[i-1][j-1] + 1;\n                }\n                else{\n                    dp[i][j] = Math.max(dp[i-1][j], dp[i][j-1]);\n                }\n            }\n        }\n        return dp[text1.length() - 1][text2.length() - 1];\n    }\n````\n\n\n\n322零钱兑换\n\n````java\npublic int coinChange(int[] coins, int amount) {\n        //dp[i]表示钱为i时所需硬币数\n        int[] dp = new int[amount + 1];\n        for(int i = 0; i <= amount; i++){\n            dp[i] = Integer.MAX_VALUE;\n        }\n        dp[0] = 0;\n        for(int i = 1; i <= amount ; i++){\n            for(int j = 0; j < coins.length ; j++){\n                if(i - coins[j] >= 0 && dp[i - coins[j]] != Integer.MAX_VALUE){\n                    dp[i] = Math.min( dp[i - coins[j]] + 1, dp[i]);\n                }\n            }\n        }\n        if(dp[amount] == Integer.MAX_VALUE){\n            return -1;\n        }\n        return dp[amount];\n    }\n````\n\n\n\n300最长递增子序列\n\n````java\npublic int lengthOfLIS(int[] nums) {\n        //dp[i]表示从头到nums[i]，且以nums[i]结尾的最长递增子序列\n        int[] dp = new int[nums.length];\n        dp[0] = 1;\n        int maxValue = 1;\n        for( int i = 1; i < nums.length; i++) {\n            dp[i] = 1;\n            for(int j = 0; j < i; j++){\n                if(nums[i] > nums[j]){\n                    dp[i] = Math.max(dp[i], dp[j] + 1);\n                }\n            }\n            maxValue = Math.max(dp[i] , maxValue);\n        }\n        return maxValue;\n    }\n````\n\n\n\n\n\n## 滑动窗口\n\n一般思路：\n\n一般用于：数组、字符串中求满足某条件的最大/小的连续子串【因为窗口是连续的】\n\n1. [left, right]为窗口，初始时left = right = 0\n2. right一直往右增加，直到不满足条件【也可能为直到条件满足】\n3. 缩小left直到条件再次满足【也可能为直到不满足条件】\n4. 重复2,3求最优\n\n常见题目：\n\n[3. 无重复字符的最长子串](https://leetcode.cn/problems/longest-substring-without-repeating-characters/)\n\n```\n输入: s = \"pwwkew\"\n输出: 3\n解释: 因为无重复字符的最长子串是 \"wke\"，所以其长度为 3。\n     请注意，你的答案必须是 子串 的长度，\"pwke\" 是一个子序列，不是子串。\n```\n\n由题目可提取：\n\n* 条件：无重复字符\n* 子串\n* 最优：最长\n\n由子串思考，一般用滑动窗口求解\n\n1. 窗口构造[left, right]，初始时都为0\n\n2. right增加，直到不满足条件，即出现重复字符X\n\n3. 缩小left直到再次满足条件，可知此时left应在X上一次出现的位置后方\n\n   > **怎么知道X上一次出现的位置呢？**\n   >\n   > Ans：使用数组或者map保存\n   >\n   > * 数组索引为字符X，值为出现位置，数组最大长度128即可\n   > * map key为字符X，值为位置\n\n4. 每次都保存子串的长度，有更长的则更新长度\n\n5. right到字符串尾则结束\n\n综上，其代码为：\n\n````java\npublic int lengthOfLongestSubstring(String s) {\n        Map<Character, Integer> map = new HashMap<>();\n        int left = 0;\n        int right = 0;\n        int count = 0;\n        while(right < s.length() && left <= right){\n            if(map.containsKey(s.charAt(right))){\n                left = Math.max(map.get(s.charAt(right)) + 1 , left);\n            }\n            count = Math.max(right - left + 1, count);\n            map.put(s.charAt(right), right);\n            right ++;\n        }\n        return count;\n    }\n````\n\n\n\n[438. 找到字符串中所有字母异位词](https://leetcode.cn/problems/find-all-anagrams-in-a-string/)\n\n**示例 1:**\n\n```\n输入: s = \"cbaebabacd\", p = \"abc\"\n输出: [0,6]\n解释:\n起始索引等于 0 的子串是 \"cba\", 它是 \"abc\" 的异位词。\n起始索引等于 6 的子串是 \"bac\", 它是 \"abc\" 的异位词。\n```\n\n **示例 2:**\n\n```\n输入: s = \"abab\", p = \"ab\"\n输出: [0,1,2]\n解释:\n起始索引等于 0 的子串是 \"ab\", 它是 \"ab\" 的异位词。\n起始索引等于 1 的子串是 \"ba\", 它是 \"ab\" 的异位词。\n起始索引等于 2 的子串是 \"ab\", 它是 \"ab\" 的异位词。\n```\n\n所有异位词：即为在s中找寻长度为p.length的子串，且其中的字符与p中的相等\n\n* 条件：异位词\n* s中找子串\n\n所以依然考虑用滑动窗口解决，但是此时窗口长度固定。\n\n1. 构建窗口：[left , right]，初始时left = 0 , right = p.len\n\n2. 整个窗口右移，看是否满足条件：窗口的字符串为p的异位词\n\n   > **怎么判断异位词**：由题目可知异位词为相同字符不同出现顺序，则可以：\n   >\n   > * 统计字符出现次数，若两个串出现各字符出现次数相同则为异位词\n   > * 将p按字符大小排序，然后将窗口内的字符串也按大小排序，排序后相同则为异位词\n\n3. 满足条件则将窗口left加入答案\n\n4. 重复2，3直到right到s末尾\n\n\n\n使用字符出现次数判断异位词：\n\n````java\nclass Solution {\n    public List<Integer> findAnagrams(String s, String p) {\n        int len1 = p.length();\n        int len2 = s.length();\n        if(len1 > len2){\n            return new ArrayList<Integer>();\n        }\n\n        int[] charCount1 = new int[26];//p\n        int[] charCount2 = new int[26];//s\n\n        List<Integer> re = new ArrayList<>();\n\n        for(int i = 0; i < len1; i++){\n            charCount1[p.charAt(i) - 'a'] ++;\n        }\n\n        for(int i = 0; i < len2 ; i++){\n            charCount2[s.charAt(i) - 'a'] ++;\n            if(i >= len1){\n                charCount2[s.charAt( i - len1) - 'a'] --;\n            }\n            if(Arrays.equals(charCount1 , charCount2  )){\n                re.add(i + 1 - len1);\n            }\n        }\n        return re;\n    }\n}\n````\n\n使用字符排序判断：\n\n````java\npublic List<Integer> findAnagrams(String s, String p) {\n        char[] array = p.toCharArray();\n        Arrays.sort(array);\n\n        List<Integer> re = new ArrayList<>();\n        int len1 = p.length();\n        int right = len1;\n        while(right <= s.length()){\n            String temp = s.substring(right - len1 , right);\n            char[] array2 = temp.toCharArray();\n            Arrays.sort(array2);\n\n            if (Arrays.equals(array, array2)){\n                re.add(right - len1);\n            }\n            right++;\n        }\n        return re;\n    }\n````\n\n\n\n## 双指针：\n\n一般分为两种：\n\n* 左右指针：两指针相向或者相背移动\n* 快慢指针：两指针朝同一方向移动，只是速度不同\n\n\n\n### 快慢指针\n\n一般思路为使用慢指针做有效值保存，使用快指针探测值是否有效\n\n如：[283. 移动零](https://leetcode.cn/problems/move-zeroes/)\n\n将所有0移到数组末尾，原地操作\n\n则使用慢指针保存非0值，然后快指针探测值是否为0，最后将慢指针之后的位置置0即可\n\n````java\nclass Solution {\n    public void moveZeroes(int[] nums) {\n        int pos=0;\n        // pos为慢指针，i为快指针\n        for(int i=0;i<nums.length;i++){\n            if(nums[i]!=0){\n                nums[pos++]=nums[i];\n            }\n        }\n        for(int i=pos;i<nums.length;i++){\n            nums[i]=0;\n        }\n    }\n}\n````\n\n\n\n### 左右指针\n\n两指针相向或者相背移动\n\n滑动窗口也为左右指针\n\n类似于**有序数组**求和之类问题【nSum】，都应该首先考虑双指针\n\n[15. 三数之和](https://leetcode.cn/problems/3sum/)\n\n1. 该题不为有序数组，但是可以先将数组排序。\n2. 然后固定一个值，则变为二值之和为target。\n3. 使用左右指针，左指针从固定位置后方开始，右指针从数组最右端开始\n4. 调整指针直到满足条件\n5. 不断调整固定的值（遍历），最后得出结果\n\n````java\nclass Solution {\n    public List<List<Integer>> threeSum(int[] nums) {\n        Arrays.sort(nums);\n        List<List<Integer>> re = new ArrayList<>();\n        List<Integer> temp = new ArrayList<>();\n        int left, right;\n\n        for (int i = 0; i < nums.length; i++) {\n            left = i + 1;\n            right = nums.length - 1;\n            if (nums[i] > 0) {\n                return re;\n            }\n            if (i > 0 && nums[i] == nums[i - 1]) {\n                continue;\n            }\n            while (left < right) {\n                if (nums[i] + nums[left] + nums[right] == 0) {\n                    temp.add(nums[i]);\n                    temp.add(nums[left]);\n                    temp.add(nums[right]);\n                    re.add(new ArrayList(temp));\n                    temp.clear();\n\n                    while (left < right && nums[left] == nums[left + 1]) {\n                        left++;\n                    }\n                    while (left < right && nums[right - 1] == nums[right]) {\n                        right--;\n                    }\n\n                    left++;\n                    right--;\n                } else if (nums[i] + nums[left] + nums[right] > 0) {\n                    right--;\n                } else {\n                    left++;\n                }\n            }\n        }\n        return re;\n    }\n}\n````\n\n\n\n**反转数组**\n\n即将数组原地反转\n\n1. 使用左右指针left, right相向而行\n2. 每次交换其值\n3. 到中点则结束\n\n````java\nvoid reverseString(char[] s) {\n    // 一左一右两个指针相向而行\n    int left = 0, right = s.length - 1;\n    while (left < right) {\n        // 交换 s[left] 和 s[right]\n        char temp = s[left];\n        s[left] = s[right];\n        s[right] = temp;\n        left++;\n        right--;\n    }\n}\n````\n\n\n\n**回文串判断**\n\n回文串则为反向和正向相同\n\n即类似于反转数组：\n\n1. 使用左右指针left, right相向而行\n2. 每次比较其值\n3. 到中点则结束\n\n扩展：[5. 最长回文子串](https://leetcode.cn/problems/longest-palindromic-substring/)\n\n判断最长回文子串\n\n1. 使用中间扩散法，每次从中间扩散\n\n   > 问题：子串为奇偶情况不同\n   >\n   > 奇：从中间开始\n   >\n   > 偶：从中间两个元素开始\n\n2. 找出每次以s[i]扩散后的回文串，长度变长则更新\n\n3. 字符串的每个字符都可为中心【遍历】\n\n````java\nclass Solution {\n    public String longestPalindrome(String s) {\n        String res = \"\";\n        for(int i = 0 ;i < s.length(); i++){\n            String s1 = palindrome(s, i, i);//以i为中心，长度为奇数的回文串\n            String s2 = palindrome(s, i, i + 1);//以i为中心，长度为偶数\n            res = s1.length() > res.length() ? s1 : res;\n            res = s2.length() > res.length() ? s2 : res;\n        }\n        return res;\n    }\n\n    public String palindrome(String s, int left, int right){\n        while(left >= 0 && right < s.length() && (s.charAt(left) == s.charAt(right))){\n                left --;\n                right ++;\n            }\n        return s.substring(left + 1, right);\n    }\n}\n````\n\n**接雨水**\n\n使用双指针来处理，使用相向而行的指针\n\n[42. 接雨水](https://leetcode.cn/problems/trapping-rain-water/)\n\n考虑每列能接到的雨水之和。\n\n1. 使用相向指针left right\n\n2. 雨水怎么才能被接到？\n\n   > 整体而言[left, right]中的雨水最高为其最小值【注意为整体而言】\n   >\n   > 保存最大的left与最大的right，则每次移动left时，如果其值小于maxLeft，则说明其这一列可以接满至left高，right同理【注：需判断maxLeft和maxRight大小，可以理解为最小值先接】\n   >\n   > 直到left与right移至中间则为结束\n\n\n\n## 链表\n\n### 链表排序\n\n快排：\n\n````java\nclass Solution {\n    public ListNode sortList(ListNode head) {\n        if(head == null || head.next == null){\n            return head;\n        }\n        ListNode newHead = new ListNode();\n        newHead.next = head;\n        return quickSort(newHead, null);\n    }\n    public ListNode quickSort(ListNode head , ListNode end){\n        if(head == end || head.next == end || head.next.next == null){\n            return head;\n        }\n        ListNode tempHead = new ListNode();\n        ListNode pivot = head.next;\n        ListNode p = pivot;\n        ListNode temp = tempHead;\n\n        while(p.next != end){\n            if(p.next.val < pivot.val){\n                //使用temp保存比pivot小的node\n                temp.next = p.next;\n                temp = temp.next;\n                //删除原链表中的p.next节点\n                p.next = p.next.next;\n            }\n            else{\n                p = p.next;\n            }\n        }\n        temp.next = head.next;\n        //将每次快排后的链表接回原头上\n        head.next = tempHead.next;\n        quickSort(head, pivot);\n        quickSort(pivot, end);\n        return head.next;\n    }\n}\n````\n\n归并排序：\n\n````java\nclass Solution {\n    public ListNode sortList(ListNode head) {\n        if(head == null || head.next == null){\n            return head;\n        }\n        return mergeSort(head, null);\n    }\n\n    public ListNode mergeSort(ListNode head, ListNode tail){\n        if (head == null) {\n            return head;\n        }\n        if (head.next == tail) {\n            head.next = null;\n            return head;\n        }\n        ListNode slow = head;\n        ListNode fast = head;\n        \n        //快慢指针找链表zhong'd'f\n        while(fast != tail){\n            slow = slow.next;\n            fast = fast.next;\n            if(fast != tail){\n                fast = fast.next;\n            }\n        }\n        ListNode mid = slow;\n        ListNode list1 = mergeSort(head, mid);\n        ListNode list2 = mergeSort(mid, tail);\n        return merge(list1, list2);\n    }\n\n    public ListNode merge(ListNode list1, ListNode list2){\n        ListNode tempHead = new ListNode();\n        ListNode temp = tempHead;\n\n        while(list1 != null && list2 != null){\n            if(list1.val < list2.val){\n                temp.next = list1;\n                list1 = list1.next;\n            }\n            else{\n                temp.next = list2;\n                list2 = list2.next;\n            }\n            temp = temp.next;\n        }\n        temp.next = list1 == null ? list2 : list1;\n        return tempHead.next;\n    }\n}\n````\n\n\n\n\n\n## 回溯\n\n解题思路：\n\n本质其实为探索所有解中的可行解的算法。即：会穷举出所有解，选择满足条件的可行解。\n\n本质其实相当于dsf  + 剪枝\n\n````java\ndef backtrack(已添加数据的集合, 可选的元素列表):\n    if 满足结束条件:\n        result.add(已添加数据的集合)\n        return\n    \n\nfor 元素 in 可选的元素列表:\n    选择元素\n    backtrack(已添加数据的集合, 可选的元素列表)\n    撤销选择元素\n\n````\n\n\n\n核心为`for`循环中的递归，在递归前选择元素，然后在递归调用之后撤销选择，即树形结构中回溯到上一层。\n\n两个中间字段使用：\n\n* isUsed：用于判断是否已被用过，一般用于有唯一性的场景，即排列场景（[1,2,3], [3,2,1]为不同列表）\n* begin：用于去重，即不考虑begin索引之前的字符了，组合问题下使用[1,2,3], [3,2,1]为同一列表）\n\n\n\n## 动态规划\n\n首先题目识别：一般有最xx，子序列类似题都是使用dp\n\n以及第`i`项结果需要用到前项结果之类的题目，基本都是用dp求解\n\ndp最重要的我认为应该是定义dp数组，即你的dp[i]表示的是什么，然后再根据题意列出转移方程。如果一维dp不能解决则使用二维\n\n\n\n## 背包\n\n题目识别：类似于将几个东西凑起来，使其值为`X`，即将所给物品装满所给背包\n\n注意01背包和其他\n\n\n\n## 贪心\n\n即先考虑怎么样才能使结果最优，最后得到最优解\n\n\n\n## 前缀和\n\n即使用额外的数组来保存给定数组的前n项和\n\n即pre[i] = nums[0] + ... + nums[i]；\n\npre[i + 1] =  pre[i] + nums[i + 1];\n\n\n\n\n\n数位dp\n\n一般用于统计某个范围的数，而这个范围一般都很大，难以直接暴力枚举求解，所以一般将其每位数拆分，一位一位地看。\n\n如：判断在`[0,x]`范围中，满足某条件地数的个数\n\n先做规约：\n\n* 0特殊判断，然后数位dp判断`[1,x]`\n* 不填前导0，即保证每个数的最高位为正数\n\n填数过程，遵循以下：\n\n* 从高位往低位枚举数位\n* 在第`i`位填上了数，则其后面的数位都需填上数，保证数据不重复\n* 保证填入的数组成的数据不大于x\n\n\n\n如：令`x = 324783729`，求`[1,x]`内有多少个数满足其数位上的数字之和为16\n\n1. 先看第一位：\n   * 不填\n   * 填：可以填1, 2, 3\n2. 再看第二位：\n   * 不填\n   * 填：\n     * 第一位没填数：可以填[1,9]任意一个数\n     * 第一位填数了：\n       * 第一位填的1或2：可以填[0,9]任意一个数\n       * 第一位填的3：可以填[0,2]任意一个数\n3. ...\n4. 如处理到第七位：\n   * 不填\n   * 填：\n     * 前面都没有填数：可以填[1,9]任意一个数\n     * 前面填了：\n       * 前面位数没满，即前面填的数没有六位：可以填[0,9]任意一位数\n       * 前面数位满了：\n         * 前面存在一位，其数字小于其对应的数字，即nums[i]：可以填[0,9]任意一位数\n         * 前面所有数字都与对应数字相同：可以填[0,7]任意一位\n\n**规律分析总结：**\n\n第`i`位填数：\n\n* 前面都没有填数：[1,9]\n* 前面没填满或填满了但存在一位所填的数小于x中对应位数的数值：[0,9]\n* 前面所有数字都与x中对应数字相同：[0, nums[i]]\n\n所以，可以引入变量`limit`来判断前面所填数字是否都与x中对应数字相同\n\n则在填入第一个数时，即情况1，前面都没有填数时，对`limit`进行初始化\n\n第二种情况下：limit = 0\n\n第三种情况下： limit = 1\n\n\n\n**limit转移：**\n\n填完第`i`个数字，`limit`怎么转移到第`i + 1`位：\n\n当前limit = 1且填入的数字为nums[i]，则下一位的limt = 1;\n\n否则下一位的limit = 0;\n\n\n\n**特殊情况处理：**\n\n即最高位，第0位的处理\n\n其填入的值的范围：[1, nums[0]]\n\n其limit = 填值 == nums[i] ? 1 : 0\n\n\n\n分析转移方程：使用`dp[i][limit][sum]`表示在前`i`位数字和为sum的数据个数\n\n* 前面都没有填数：[1,9]\n\n  ````java\n  //初始化\n  //填入数字为c,取值为1，9\n  dp[i][0][c] = 1;\n  ````\n\n* 前面没填满或填满了但存在一位所填的数小于x中对应位数的数值：[0,9]\n\n  ````java\n  dp[i][0][cur_sum + c] += dp[i - 1][0][cur_sum];\n  ````\n\n  \n\n* 前面所有数字都与x中对应数字相同：[0, nums[i]]\n\n  ````java\n  c != nums[i]\n  dp[i][0][cur_sum + c] += dp[i - 1][1][cur_sum];\n  else c == nums[i]\n  dp[i][1][cur_sum + c] += dp[i - 1][1][cur_sum];\n  ````\n\n* 最终答案为：\n\n  ````java\n  dp[n - 1][0][sum] + dp[n - 1][1][sum]\n  ````\n\n\n\n\n多线程\n\n1. 三个线程打印3的倍数，5的倍数和其他，不可重复\n\n````java\npublic class Test {\n\n    static class Pointer implements Runnable{\n        private  int mod;\n        private static int num = 1;//每次打印的数字\n        private static final Object lock = new Object();\n\n        Pointer(int mod ){\n            this.mod = mod;\n        }\n\n        @Override\n        public void run() {\n            synchronized (lock){\n                while(num < 101){\n                    if((mod==3 && num%mod!=0)\n                            || (mod==5 && num%mod!=0)\n                            || (mod== -1 && (num%3==0 || num%5==0) )){\n                        try {\n                            lock.wait();\n                        } catch (InterruptedException e) {\n                            throw new RuntimeException(e);\n                        }\n                    }\n                    else{\n                        System.out.println(Thread.currentThread().getName() +  \" and the value is : \" + num);\n                        num ++;\n                        lock.notifyAll();\n                    }\n                }\n            }\n        }\n    }\n\n\n    public static void main(String[] args){\n        new Thread(new Pointer(3),\"Thread0\").start();\n        new Thread(new Pointer(5),\"Thread1\").start();\n        new Thread(new Pointer(-1),\"Thread2\").start();\n    }\n}\n````\n\n\n\n2. 三个线程按序打印ABCABCABC，各打印十次\n   * 使用state和ReentrantLock\n\n````java\npublic class Test {\n    private static volatile int state = 0;\n    private static Lock lock = new ReentrantLock();\n\n    static class ThreadA extends Thread{\n        @Override\n        public void run(){\n            for(int i = 0 ; i < 10 ; ){\n                try {\n                    lock.lock();\n                    while (state % 3 == 0){\n                        System.out.print(\"A\");\n                        i ++;\n                        state ++;\n                    }\n                }\n                finally {\n                    lock.unlock();\n                }\n\n            }\n        }\n    }\n    static class ThreadB extends Thread{\n        @Override\n        public void run(){\n            for(int i = 0 ; i < 10 ; ){\n                try {\n                    lock.lock();\n                    while (state % 3 == 1) {\n                        System.out.print(\"B\");\n                        i ++;\n                        state ++;\n                    }\n                }\n                finally {\n                    lock.unlock();\n                }\n\n            }\n        }\n    }\n    static class ThreadC extends Thread{\n        @Override\n        public void run(){\n            for(int i = 0 ; i < 10 ; ){\n                try {\n                    lock.lock();\n                    while (state % 3 == 2) {\n                        System.out.print(\"C\");\n                        i ++;\n                        state++;\n                    }\n                }\n                finally {\n                    lock.unlock();\n                }\n\n            }\n        }\n    }\n\n\n    public static void main(String[] args){\n        new ThreadA().start();\n        new ThreadB().start();\n        new ThreadC().start();\n    }\n}\n````\n\n* 使用semaphor\n\n````java\npublic class Test {\n    private static Semaphore a = new Semaphore(1);\n    private static Semaphore b = new Semaphore(0);\n    private static Semaphore c = new Semaphore(0);\n\n    static class ThreadA extends Thread{\n        @Override\n        public void run(){\n            for(int i = 0 ; i < 10 ; i ++){\n                try {\n                    a.acquire();\n                    System.out.print(\"A\");\n                    b.release();\n                } catch (InterruptedException e) {\n                    throw new RuntimeException(e);\n                }\n\n            }\n        }\n    }\n    static class ThreadB extends Thread{\n        @Override\n        public void run(){\n            for(int i = 0 ; i < 10 ; i ++){\n                try {\n                    b.acquire();\n                    System.out.print(\"B\");\n                    c.release();\n                } catch (InterruptedException e) {\n                    throw new RuntimeException(e);\n                }\n\n            }\n        }\n    }\n    static class ThreadC extends Thread{\n        @Override\n        public void run(){\n            for(int i = 0 ; i < 10 ; i ++){\n                try {\n                    c.acquire();\n                    System.out.print(\"C\");\n                    a.release();\n                } catch (InterruptedException e) {\n                    throw new RuntimeException(e);\n                }\n\n            }\n        }\n    }\n\n\n    public static void main(String[] args){\n        new ThreadA().start();\n        new ThreadB().start();\n        new ThreadC().start();\n    }\n}\n````\n\n[其余可参考](https://blog.csdn.net/hefenglian/article/details/82596072)","tags":["Java","Leetcode","算法"],"categories":["Learning","Algorithm"]},{"title":"GC","url":"/post/1134db17.html","content":"\n\n\n# Garbage Collection(GC)\n\n回收无任何对象引用的对象占据的内容空间，即不会再被使用的对象的内容空间。\n\n引用：若Reference类型的数据中存储的数值代表另一块内容的起始地址，则称这块内存为一个引用\n\n垃圾：无任何对象引用的对象\n\n回收：清理垃圾占用的内存空间而非对象本身\n\n发生地点：一般在堆内存中，因为大部分对象都储存在堆内存中\n\n发生时间：程序空闲时不定时回收\n\n<!-- more -->\n\n\n\n## 引用类型\n\n### 强引用StrongReference\n\n默认即为强引用，任何一个对象的赋值操作就产生了对这个对象的强引用。\n\n如：\n\n````java\nObject obj = new Object();\n````\n\n特征：只要强引用存在，被引用的对象就永远不会被回收\n\n\n\n### 软引用SoftReference\n\n用于描述可能有用，但非必须的对象。\n\nJDK1.2之后提供了`SoftReference`类来实现软引用。\n\n````java\npublic class SoftReference<T> extends Reference<T>\n\n//构造函数\n    public SoftReference(T referent);\n\tpublic SoftReference(T referent, ReferenceQueue<? super T> q)\n````\n\n特征：只有在内存不足的情况下，被引用的对象才会被回收。\n\n\n\n### 弱引用WeakReference\n\n构造函数类似于软应用\n\n特征：只要垃圾回收执行，其引用的对象就会被回收。\n\n\n\n### 虚引用PhantomReference\n\n作用：跟踪垃圾回收器收集对象的活动。GC的过程中，如果发现有`PhantomReference`，GC则会将引用放到`ReferenceQueue`中，由程序员自己处理，当程序员调用`ReferenceQueue.pull()`方法，将引用出`ReferenceQueue`移除之后，Reference对象会变成`Inactive`状态，意味着被引用的对象可以被回收了。\n\n````java\npublic PhantomReference(T referent, ReferenceQueue<? super T> q)\n````\n\n\n\n## 判断“垃圾”\n\n垃圾回收算法的一般过程：\n\n1. 找到所有存活对象\n2. 回收被无用对象占用的内存空间，使其可被再次使用\n\n\n\n### 引用计数法Reference Counting Collector\n\n思路：堆中每个对象都有一个引用计数器。\n\n1. 对象被创建并初始化后，计数器设置为`1`\n2. 每当有一个地方引用它，计数器值`加1`\n3. 引用失效时（超过生命周期、设置为新值），计数器`减1`\n4. 计数器为`0`的对象可被垃圾回收\n5. 当一个对象被垃圾收集时，它引用的任何对象计数`减1`。\n\n优点：\n\n* 执行简单，判定效率高，交织在程序运行中。\n* 对程序不被长时间打断的实时环境比较有利（OC内存管理使用该算法）\n\n缺点：\n\n* 难以检测出对象之间的循环引用\n* 增加了程序开销\n\n\n\n### 根搜索算法Tracing Collector\n\n**根集Root Set**\n\n为正在执行的Java程序可以访问的**引用变量**（注：不是对象）集合，包括局部变量、参数、类变量。程序可以使用引用变量访问对象的属性和调用对象的方法。\n\n\n\nGC Roots对象包括：\n\n* 虚拟机栈中引用的对象（栈帧中的本地变量表）；\n* 方法区中的常量引用的对象；\n* 方法区中的类静态属性引用的对象；\n* 本地方法栈中JNI（Native方法）的引用对象。\n* 活跃线程。\n\n思路：\n\n1. 通过名为“GC Roots”的对象作为起始点，寻找对应的引用节点\n2. 从找到的引用节点开始继续向下寻找其引用节点[repeat]\n3. 搜索走过的路径称为引用链，当一个对象到GC Roots没有任何引用链相连时，表明该对象不可用\n\n目前使用此方法判断对象是否存活。\n\n\n\n标记可达对象：\n\n![image-20240201155116603](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202402011551789.png)\n\n标记注意事项：\n\n* 开始标记前需暂停应用线程，若对象图一直处于变化状态则无法真正遍历。暂停线程以便JVM操作的情况称为安全点（Safe Point），会触发一次`Stop The World(STW)`暂停。垃圾回收是最常见的触发安全点的原因。\n\n* 暂停的时间长短取决于存活对象的多少（非堆内对象与堆大小）\n\n* 根搜索算法中，宣布对象死亡，至少要经历**两次标记**：\n\n  1. 对象在根搜索后发现没有与GC Roots相连接的引用链，则会被**第一次标记**并进行一个筛选。\n\n     筛选条件：该对象是否有必要执行`finalize()`，当对象未覆盖`finalize()`或该方法已被虚拟机调用过，虚拟机将其视为没有必要执行。\n\n  2. 若该对象被判定为有必要执行`finalize()`，则该对象会被放置在`F-Queue`队列中，并在稍后由一条由虚拟机自动创建的、低优先级的`Finalizer`线程执行`finalize()`\n\n     稍后GC将对`F-Queue`中的对象进行**第二次小规模的标记**。\n\n     若想在`finalize()`方法中拯救自己，则需在该方法中让该对象重新引用链上的任一对象建立关联即可（最后一次机会，一个对象的`finalize()`最多被系统调用一次）\n\n     还未被关联到任何链的对象会被回收\n\n* GC判断对象是否可达看的是强引用\n\n\n\n## 回收算法\n\n### 标记-清除算法Mark-Sweep\n\n使用了根集的概念，分为“标记”和“清除”两个阶段：首先标记出所需回收的对象，在标记完成后统一回收掉所有被标记的对象，它的标记过程其实就是根搜索算法中判定垃圾对象的标记过程。\n\n优点：无需进行对象的移动，仅对不存活的对象进行处理，在存活对象较多情况下高效\n\n缺点：\n\n* 标记与清除过程的效率都不高：需使用空闲表记录所有空闲区域及其大小\n\n* 标记清除后会产生大量不连续的内存碎片\n\n\n\n### 标记-整理算法Mark-Compact\n\n标记过程与标记-清除算法一致。\n\n在对垃圾对象的处理中，不是直接清理，而是让所有存活对象都向一端移动，然后直接清理掉端边界以外的内存。\n\n优点：\n\n* 整理后，新对象分配只需通过指针碰撞便可完成，非常简单\n* 空闲区域位置可知，无碎片问题\n\n缺点：\n\nGC暂停时间增长，因为需要将所有对象拷贝到新的地方，还得更新其引用地址\n\n`mark-sweep`与`mark-compact`图示：\n\n![image-20240201155300115](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202402011553289.png)\n\n### 复制算法Copying\n\n将内存按容量分为大小相等的两块，每次只是用其中一块（对象面），当这块内存用完，将还存活的对象复制到另一块内存上（空闲面），然后将已使用过的内存空间一次性清理。\n\n![image-20240201155757290](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202402011557375.png)\n\n适用于：新生代（短生存期的对象），在老年代，即长生存期的对象中，其对象存活率较高，会执行较多的复制操作，效率会降低。所以老年代一般选用其他算法，如标记-整理算法\n\n一种典型的基于Coping算法的垃圾回收是`stop-and-copy`算法，它将堆分成对象区和空闲区，在对象区与空闲区的切换过程中，程序暂停执行\n\n优点：\n\n* 标记和复制阶段可同时进行\n* 每次只对一块内存回收，高效\n* 只需移动栈顶指针，按序分配内存即可，实现简单\n* 无需考虑内存碎片出现\n\n缺点：需一块能容纳下所有存活对象的额外的内存空间，因此，可一次性分配的最大内存缩小了一半\n\n\n\n### Adaptive算法\n\n在特定的情况下，一些垃圾收集算法会优于其它算法。基于Adaptive算法的垃圾收集器就是监控当前堆的使用情况，并将选择适当算法的垃圾收集器。\n\n\n\n## 堆内存\n\n基于Generation算法，划分为：\n\n* 新生代Young\n  * Eden\n  * Survivor\n    * FromSpace(Survivor0)\n    * ToSpace(Survivor1)\n* 老年代Old\n* 持久代Permanent\n\n![image-20240201155903481](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202402011559574.png)\n\n所有`new`创建的对象内存都在堆中分配，其大小可以通过`Xmx`和`-Xms`来控制\n\n\n\n### 堆内存分配区域\n\n#### 新生代Young Generation\n\n几乎所有新生成的对象都放于此。\n\n新生代按$8:1:1$分为`Eden`,`S0`,`S1`。大部分对象都在`Eden`区生成。\n\n新对象生成时：\n\n1. Eden Space申请失败（因空间不足等），则会发起一次GC(`Minor GC/Scavenge GC`)\n2. 回收时先将`Eden`区存活对象复制到`S0`区，然后清空`Eden`区\n3. `S0`也满了时，将`Eden`区和`S0`区存活对象复制到`S1`，然后清空`Eden`和`S0`\n4. 此时`S0`为空，然后将`S0`和`S1`交换，即保持`S1`为空\n5. 若`S1`不足以存放`Eden`和`S0`区存活对象时，将存活对象直接放入老年代\n\n>**Minor GC /  Scavenge GC**\n>\n>发生在新生代的GC。\n>\n>非常频繁，不一定等Eden区满才发生，一般回收速度也较快。\n>\n>新生代GC一般会有大量对象死去，只有少量存活，因此可以选择**复制算法**完成收集。\n\n对象在`Survivor`区躲过一次GC，则其年龄`加1`，默认年龄达到`15`时移动到老年代。\n\n若是老年代也满了就会触发一次`Full GC`，也就是新生代、老年代都进行回收。新生代大小可以由`-Xmn`来控制，也可以用`-XX:SurvivorRatio`来控制Eden和Survivor的比例。\n\n\n\n#### 老年代Old Generation\n\n 在新生代中经历了N次垃圾回收后仍然存活的对象，就会被放到年老代中。因此，可以认为年老代中存放的都是一些生命周期较长的对象。\n\n老年代内存大约为新生代的2倍。其内存满时会触发`Major GC/Full GC`\n\n一般大对象会被直接分配到老年代，大对象即为需要大量连续存储空间的对象，如大数组\n\n> **Major GC / Full GC**\n>\n> 发生在老年代的GC。经常伴随至少一次Minor GC\n>\n> 老年代对象声明周期长，所以Full GC不频繁，一般等老年代区满了才进行，速度比Minor GC慢10倍以上\n>\n> 若分配了Direct Memory，在老年代Full GC时，会清理掉Direct Memory中的废弃对象。\n>\n> 无额外空间进行分配担保，对象存活率高，必须使用**标记-清除**或**标记-整理**算法进行回收。\n>\n> 导致Full GC的原因可能有：\n>\n> * 老年代满\n> * 持久代满\n> * System.gc()被调用\n> * 上一次GC后堆的各域分配策略动态变化\n\n\n\n#### 持久代Persistence Generation\n\n用于存放静态文件（class, method）和常量\n\n回收主要由两部分内容：废弃常量和无用类\n\n永久代空间在Java SE8特性中已经被移除。取而代之的是元空间（`MetaSpace`）。因此不会再出现`java.lang.OutOfMemoryError: PermGen error`错误。\n\n\n\n## 垃圾回收器\n\n按执行机制分为四种垃圾回收器：\n\n![image-20240201172019392](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202402011720503.png)\n\n* 串行垃圾回收器（Serial Garbage Collector）\n* 并行垃圾回收器（Parallel Garbage Collector）\n* 并发标记扫描垃圾回收器（CMS Garbage Collector）\n* G1垃圾回收器（G1 Garbage Collector）\n\n### 串行垃圾回收器Serial\n\n通过持有应用程序所有的线程进行工作。为单线程环境设计，只是用一个单独的线程进行垃圾回收，通过冻结所有应用程序线程（STW）进行工作。\n\n简单高效，适合简单的命令行程序，是client级别默认的GC方式。\n\n通过JVM参数`-XX:+UseSerialGC`可以使用串行垃圾回收器。\n\n\n\n### 并行垃圾回收器Parallel\n\n也叫throughput collector。是JVM的默认垃圾回收器。\n\n使用多线程进行垃圾回收，与串行类似，执行垃圾回收的时候也会冻结所有的应用程序线程。\n\n适合多CPU、对暂停时间要求较短的应用，是server级别默认采用的GC方式。\n\n可用`-XX:+UseParallelGC`来强制指定，用`-XX:ParallelGCThreads=4`来指定线程数。\n\n\n\n### 并发标记扫描垃圾回收器CMS\n\n使用多线程扫描堆内存，标记需清理的实例并清理被标记过的实例。\n\n只有在以下两种情况下才持有应用程序所有线程：\n\n* 标记的引用对象在`Tenured`区域。\n* 进行垃圾回收的时候，堆内存的数据被并发地改变。\n\n相较于并行垃圾回收器，CMS使用更多的CPU来确保程序的吞吐量。\n\n若能分配更多的CPU以获得更好的性能，那么CMS是优于Parallel的首选。\n\n通过JVM参数`-XX:+USeParNewGC`打开并发标记扫描垃圾回收器。\n\n[更详细可见Hotspot部分](###6. CMS（标记—清除算法）)\n\n\n\n### G1垃圾回收器Garbage First\n\n用于大堆内存区域。将堆内存分隔为多个区域，并在这些区域并行进行收集。\n\n[G1](https://juejin.cn/post/7010034105165299725)\n\n\n\n## JVM配置参数\n\n运行的垃圾回收器类型：\n\n| Option                  | Description                              |\n| :---------------------- | :--------------------------------------- |\n| -XX:+UseSerialGC        | Serial Garbage Collector                 |\n| -XX:+UseParallelGC      | Parallel Garbage Collector               |\n| -XX:+UseConcMarkSweepGC | CMS Garbage Collector                    |\n| -XX:ParallelCMSThreads= | CMS Collector – number of threads to use |\n| -XX:+UseG1GC            | G1 Gargbage Collector                    |\n\n优化选项：\n\n| Option          | Description      |\n| :-------------- | :--------------- |\n| -Xms            | 初始化堆内存大小 |\n| -Xmx            | 堆内存最大值     |\n| -Xmn            | 新生代大小       |\n| -XX:PermSize    | 持久代大小       |\n| -XX:MaxPermSize | 持久代最大容量   |\n\n\n\n## Hotspot所提供的回收器\n\n![image-20240201172120200](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202402011721343.png)\n\n两个收集器之间存在连线，那说明它们可以搭配使用。虚拟机所处的区域说明它是属于新生代收集器还是老年代收集器。\n\n### 1. Serial（SerialMSC）（Copying算法）\n\nSerial收集器是最基本最古老的收集器，它是一个单线程收集器，并且在它进行垃圾收集时，必须暂停所有用户线程（STW）。\n\nSerial收集器是针对新生代的收集器，采用的是Copying算法。\n\n\n\n### 2. ParNew （Copying算法）\n\nParNew收集器是新生代收集器，Serial收集器的多线程版本。使用多个线程进行垃圾收集，在多核CPU环境下有着比Serial更好的表现。\n\n\n\n### 3. Parallel Scavenge （Copying算法）\n\nParallel Scavenge收集器是一个新生代的多线程收集器（并行收集器），它在回收期间**不需要暂停其他用户线程**。\n\n其采用的是Copying算法，该收集器与前两个收集器有所不同，它主要是为了达到一个**可控的吞吐量**。追求高吞吐量，高效利用CPU。吞吐量一般为99%。 也被称为“吞吐量优先收集器”。\n\n吞吐量= 用户线程时间/(用户线程时间+GC线程时间)。适合后台应用等对交互相应要求不高的场景。\n\n\n\n### 4. Serial Old （标记—整理算法）\n\nSerial Old收集器是针对老年代的收集器，采用的是Mark-Compact算法。它的优点是实现简单高效，但是缺点是会给用户带来停顿。\n\n\n\n### 5. Parallel Old（ParallelMSC）（标记—整理算法）\n\nParallel Old是Parallel Scavenge收集器的老年代版本（并行收集器），使用多线程和Mark-Compact算法。吞吐量优先。\n\n\n\n### 6. CMS（标记—清除算法）\n\nCMS（Current Mark Sweep）收集器是一种以**获取最短回收停顿时间**为目标的收集器，它是一种并发收集器，采用的是Mark-Sweep算法。\n\n收集过程：\n\n1. 初始标记，标记GCRoots能直接关联到的对象，时间很短。\n2. 并发标记，进行GCRoots Tracing（可达性分析）过程，时间很长。\n3. 重新标记，修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，时间较长。\n4. 并发清除，回收内存空间，时间很长。\n\n其中，并发标记与并发清除小号时间长，但是可以和用户线程并发执行。如下图：\n\n![image-20240201172154141](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202402011721271.png)\n\n高并发、低停顿，追求最短GC回收停顿时间，CPU占用比较高。响应时间快，停顿时间短，多核CPU 追求高响应时间的选择。\n\n缺点：\n\n* 对CPU资源非常敏感，可能会导致应用程序变慢，吞吐率下降。\n* 无法处理浮动垃圾。因为在并发清理阶段用户线程还在运行，自然就会产生新的垃圾，而在此次收集中无法收集他们，只能留到下次收集，这部分垃圾为浮动垃圾。\n* 同时，由于用户线程并发执行，所以需要预留一部分老年代空间提供并发收集时程序运行使用。\n* 由于采用的标记 - 清除算法，会产生大量的内存碎片，不利于大对象的分配，可能会提前触发一次Full GC。\n\n\n\n### 7. G1（标记-整理）\n\n  特点：\n\n* 并行和并发。使用多个CPU来缩短Stop The World停顿时间，与用户线程并发执行。\n\n* 分代收集。独立管理整个堆，但是能够采用不同的方式去处理新创建对象和已经存活了一段时间、熬过多次GC的旧对象，以获取更好的收集效果。\n\n* 空间整合。基于标记 - 整理算法，无内存碎片产生。\n\n* 可预测的停顿。能简历可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒。\n\n  G1垃圾回收器适用于堆内存很大的情况，他将堆内存分割成不同的区域，并且并发的对其进行垃圾回收。\n\n\n\n## 与垃圾回收相关的两个方法\n\n### System.gc()\n\n 命令行参数监视垃圾收集器的运行：\n\n不管JVM使用的是哪一种垃圾回收的算法，都可以请求Java的垃圾回收。在命令行中有一个参数`-verbosegc`可以查看Java使用的堆内存的情况，它的格式如下：\n\n`java -verbosegc classfile`\n\n**注**：调用System.gc()也仅仅是一个请求(建议)。JVM接受这个消息后，并不是立即做垃圾回收，而只是对几个垃圾回收算法做了加权，使垃圾回收操作容易发生，或提早发生，或回收较多而已。\n\n\n\n### finalize()\n\n在JVM垃圾回收器收集一个对象之前，一般要求程序调用适当的方法释放资源。但在没有明确释放资源的情况下，Java提供了缺省机制来终止该对象以释放资源，这个方法就是`finalize()`\n\n**why finalize()?**\n\n存在着垃圾回收器不能处理的特殊情况。如的对象（并非使用new方法）获得了一块“特殊”的内存区域（如类c空间分配、打开的文件资源），而垃圾回收器只知道那些显示地经由new分配的内存空间。\n\n\n\n一旦垃圾回收器准备好释放对象占用的存储空间，首先会去调用`finalize()`方法进行一些必要的清理工作。只有到下一次再进行垃圾回收动作的时候，才会真正释放这个对象所占用的内存空间。\n\n当 `finalize() `方法被调用时，JVM 会释放该线程上的所有同步锁。\n\n\n\n参考：\n\n[浅析JAVA的垃圾回收机制（GC）](https://www.jianshu.com/p/5261a62e4d29)\n\n[万字长文！深入详解Java垃圾回收（GC）机制](https://bbs.huaweicloud.com/blogs/296981)\n\n[Types of Java Garbage Collectors](https://javapapers.com/java/types-of-java-garbage-collectors/)\n\n","tags":["Java","GC垃圾回收"],"categories":["Learning","Java"]},{"title":"多线程与锁","url":"/post/4b1b8bf7.html","content":"\n# 1. 多线程编程\n\n## 1. 1 线程生命周期\n\n### 1.1.1 线程创建\n\n<!-- more -->\n\n#### 1. 继承Thread\n\n````java\npublic class MyThread extends Thread{\n    @Override\n    public void run() {\n        for(int i=0; i < 5; i++){\n            System.out.println(Thread.currentThread().getName() + \" run \" + i + \" times\");\n        }\n    }\n}\n\n//使用时为\nnew MyThread().start();\n````\n\n\n\n#### 2. 实现Runnable接口\n\n````java\npublic class MyRunnabel implements Runnable{\n\n    @Override\n    public void run() {\n        for(int i=0; i < 5; i++){\n            System.out.println(Thread.currentThread().getName() + \" run \" + i + \" times\");\n        }\n    }\n}\n\n//使用时为\nnew Thread(new Runnable()).start();\n\n//直接通过newRunnable().run()只会在main线程执行\n````\n\n\n\n#### 3. 实现Callable接口\n\n````java\npublic class MyCallable implements Callable<String> {\n    @Override\n    public String call() throws Exception {\n        Thread.sleep(5000);\n        return \"This is Callable\";\n    }\n}\n\n//需配合Future使用\n\t\tFutureTask futureTask = new FutureTask(new MyCallable());\n        new Thread(futureTask).start();\n        System.out.println(futureTask.get().toString());\n````\n\n`Future` 类是异步思想的典型运用\n\n`FutureTask`相当于对`Callable` 进行了封装，管理着任务执行的情况，存储了 `Callable` 的 `call` 方法的任务执行结果。\n\n\n\n### 1.1.2 使用线程池创建线程\n\n优点：可以减少在创建和销毁线程上所花时间以及系统资源的开销，解决资源不足问题。\n\n#### 1.1.2.1 使用Executors创建线程池\n\n常见的创建线程池的方式：\n\n````java\n//无限\nExecutors.newCachedThreadPool();\n\n//创建固定大小的线程池。\nExecutors.newFixedThreadPool( int nThreads);\n\n//创建单个线程的线程池\nExecutors.newSingleThreadExecutors();\n````\n\n一般为：\n\n````java \nExecutorService executorService = Executors.newCachedThreadPool();\nexecutorService.execute(new Runnable());\n\n//线程池不会自动终止，需调用shutdown方法\nexecutorService.shutdown();\n````\n\n\n\n#### 1.1.2.2 使用ThreadPoolExecutor创建线程池\n\n````java\npublic ThreadPoolExecutor(int corePoolSize,//线程池的核心线程数量\n                              int maximumPoolSize,//线程池的最大线程数\n                              long keepAliveTime,//当线程数大于核心线程数时，多余的空闲线程存活的最长时间\n                              TimeUnit unit,//时间单位\n                              BlockingQueue<Runnable> workQueue,//任务队列，用来储存等待执行任务的队列\n                              ThreadFactory threadFactory,//线程工厂，用来创建线程，一般默认即可\n                              RejectedExecutionHandler handler//拒绝策略，当提交的任务过多而不能及时处理时，我们可以定制策略来处理任务\n                               ) \n````\n\n**3个最重要的参数**\n\n**`corePoolSize` :** 任务队列未达到队列容量时，最大可以同时运行的线程数量。\n\n**`maximumPoolSize` :** 任务队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。\n\n**`workQueue`:** 新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。\n\n即任务处理流程为：\n\n![image-20240107115802834](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202401071158109.png)\n\n\n\n##### 饱和策略handler\n\n**`ThreadPoolExecutor.AbortPolicy`：** 抛出 `RejectedExecutionException`来拒绝新任务的处理。\n\n**`ThreadPoolExecutor.CallerRunsPolicy`：** 调用执行自己的线程运行任务，也就是直接在调用`execute`方法的线程中运行(`run`)被拒绝的任务，如果执行程序已关闭，则会丢弃该任务（即将任务回退给调用者）。因此这种策略会降低对于新任务提交速度，影响程序的整体性能。如果您的应用程序可以承受此延迟并且你要求任何一个任务请求都要被执行的话，你可以选择这个策略。\n\n**`ThreadPoolExecutor.DiscardPolicy`：** 不处理新任务，直接丢弃掉。\n\n**`ThreadPoolExecutor.DiscardOldestPolicy`：** 此策略将丢弃最早的未处理的任务请求。\n\n\n\n# 2. 乐观锁与悲观锁\n\n## 2.1 乐观锁\n\n总是假设最好的情况，认为共享资源每次被访问的时候不会出现问题，线程可以不停地执行，无需加锁与等待，只是在提交修改的时候去验证对应的资源是否被其他线程修改了（可以使用版本号机制或CAS算法验证）。\n\n`java.util.concurrent.atomic`包下的原子变量类就是使用了乐观锁的一种实现方式CAS实现的。\n\n````java\n// LongAdder 在高并发场景下会比 AtomicInteger 和 AtomicLong 的性能更好\n// 代价就是会消耗更多的内存空间（空间换时间）\nLongAdder longAdder = new LongAdder();\n// 自增\nlongAdder.increment();\n// 获取结果\nlongAdder.sum();\n````\n\n优点：\n\n* 高并发场景下，相比悲观锁，不存在锁竞争造成线程阻塞\n* 不会有死锁问题，性能更好\n\n缺点：\n\n* 冲突频繁发生时（写操作占比多），会频繁失败与重试，导致CPU飙升，影响性能。\n\n频繁失败重试可以解决，如原子类中的`LongAddr`就是空间换时间解决该问题。\n\n\n\n### 2.1.1 乐观锁实现\n\n一般可以使用版本号机制和CAS算法实现。\n\n\n\n#### 2.1.1.1 版本号机制\n\n一般是在数据表中加上一个数据版本号`version`字段，表示其被修改的次数。\n\n数据被修改时，`version  += 1`\n\n线程更新数据值时，读取数据的同时也会读取`version`值；提交更新时，若读取到的`version`值与当前数据库中的`version`值等时才更新，否则重试更新操作，直到更新成功。\n\n\n\n#### 2.1.1.2 CAS算法\n\nCAS(Compare And Swap)\n\n其思想为：将预期值与要更新的变量值比较，两值相等时才进行更新。\n\nCAS为一个**原子操作**，底层依赖于一条CPU的原子指令。\n\nCAS涉及的三个操作数：\n\n* V：要更新的变量值Var\n* E：预期值Expected\n* N：拟写入的新值New\n\n当且仅当 V 的值等于 E 时，CAS 通过原子方式用新值 N 来更新 V 的值。如果不等，说明已经有其它线程更新了 V，则当前线程放弃更新。\n\n\n\n### 2.1.2 乐观锁存在的问题\n\n#### 2.1.2.1 ABA问题\n\n最常见的为ABA问题。\n\n即变量V初始读取时值为A，准备赋值时仍未A，但是不能说明其在这个过程中未被其他线程操作修改过。即其经历的过程可能为A-B-A。\n\n\n\nABA问题解决：\n\n在变量前加上版本号或时间戳，JDK1.5后的`AtomicStampedReference`就是用于解决ABA问题的。\n\n````java\npublic boolean compareAndSet(V   expectedReference,\n                             V   newReference,\n                             int expectedStamp,\n                             int newStamp) {\n    Pair<V> current = pair;\n    return\n        expectedReference == current.reference &&\n        expectedStamp == current.stamp &&\n        ((newReference == current.reference &&\n          newStamp == current.stamp) ||\n         casPair(current, Pair.of(newReference, newStamp)));\n}\n````\n\n其中`compareAndSet`首先检查当前引用是否等于预期引用，且当前标志是否等于预期标志，若全部相等，则以原子方式将该引用和标志的值设置为给定的更新值。\n\n\n\n#### 2.1.2.2 循环时间长开销大\n\nCAS经常用到自旋操作来进行重试，即不成功会一直循环直到成功。\n\n若长时间不成功，会给CPU带来很大的执行开销。\n\n\n\n#### 2.1.2.3 只能保证一个共享变量的原子操作\n\nCAS只对单个变量有效。\n\n但是从 JDK 1.5 开始，提供了`AtomicReference`类来保证引用对象之间的原子性，可以把多个变量放在一个对象里来进行 CAS 操作。所以可以使用锁或者利用`AtomicReference`类把多个共享变量合并成一个共享变量来操作。\n\n\n\n## 2.2 悲观锁\n\n总是假设最坏的情况，认为共享资源每次被访问的时候都会出现问题，所以每次在获取资源操作的时候就会上锁，其他线程访问资源需等锁释放。\n\n即为：共享资源每次只给一个线程使用，其他线程阻塞，用完后再把资源转给其他线程。\n\n`synchronized`与`ReentrantLock`等独占锁就是悲观锁思想的具体实现。\n\n一般开销是固定的。\n\n缺点：\n\n* 高并发的场景下，激烈的锁竞争会造成线程阻塞，大量阻塞线程会导致系统的上下文切换，增加系统的性能开销。\n* 并且，悲观锁还可能会存在死锁问题，影响代码的正常运行。\n\n\n\n### 2.2.1 synchronized\n\n功能：保证其修饰的方法或代码块在任意时刻只有一个线程执行，主要解决多线程访问资源的同步性。\n\n使用方式：\n\n1. 修饰实例方法(锁当前对象实例)\n\n   ````java\n   //给当前对象实例加锁，进入同步代码前要获得 当前对象实例的锁 \n   synchronized void method() {\n       //业务代码\n   }\n   ````\n\n2. 修饰静态方法(锁当前类)\n\n   ````java\n   //静态方法为类的所有实例共享，进入同步代码前要先获得 当前class的锁\n   synchronized static void method() {\n       //业务代码\n   }\n   ````\n\n3. 修饰代码块(锁指定对象/类)\n\n   ````java\n   /**\n   * synchronized(object) 表示进入同步代码库前要获得 给定对象的锁。\n   * synchronized(类.class) 表示进入同步代码前要获得 给定 Class 的锁\n   **/\n   synchronized(this) {\n       //业务代码\n   }\n   ````\n\n\n\n#### 底层原理\n\n`synchronized` **同步语句块**的实现使用的是 `monitorenter` 和 `monitorexit` 指令，其中 `monitorenter` 指令指向同步代码块的开始位置，`monitorexit` 指令则指明同步代码块的结束位置。\n\n`synchronized` 修饰的**方法**并没有 `monitorenter` 指令和 `monitorexit` 指令，取得代之的确实是 `ACC_SYNCHRONIZED` 标识，该标识指明了该方法是一个同步方法。JVM 通过该 `ACC_SYNCHRONIZED` 访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。\n\n如果是实例方法，JVM 会尝试获取实例对象的锁。如果是静态方法，JVM 会尝试获取当前 class 的锁。\n\n\n\n### 2.2.2 ReentrantLock\n\n````java\npublic class ReentrantLock implements Lock, java.io.Serializable {}\n````\n\n是一个可重入且独占式的锁，和 `synchronized` 关键字类似。不过，`ReentrantLock` 更灵活、更强大，增加了轮询、超时、中断、公平锁和非公平锁等高级功能。\n\n`ReentrantLock` 里面有一个内部类 `Sync`，`Sync` 继承 AQS（`AbstractQueuedSynchronizer`），添加锁和释放锁的大部分操作实际上都是在 `Sync` 中实现的。`Sync` 有公平锁 `FairSync` 和非公平锁 `NonfairSync` 两个子类。\n\n````java\n// 传入一个 boolean 值，true 时为公平锁，false 时为非公平锁\npublic ReentrantLock(boolean fair) {\n    sync = fair ? new FairSync() : new NonfairSync();\n}\n````\n\n即`ReentrantLock` 的底层就是由 AQS 来实现的。\n\n\n\n### 2.2.3 synchronized vs. ReentrantLock\n\n共同点：\n\n* 两者都是可重入锁。\n\n>可重入锁：也叫递归锁，指的是线程可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果是不可重入锁的话，就会造成死锁。\n\nJDK 提供的所有现成的 `Lock` 实现类，包括 `synchronized` 关键字锁都是可重入的。\n\n\n\n不同点：\n\n* synchronized依赖JVM，ReentrantLock依赖于API\n\n* ReentrantLock增加了一些高级功能\n\n  * 等待可中断：通过 `lock.lockInterruptibly()` 来实现这个机制。也就是说正在等待的线程可以选择放弃等待，改为处理其他事情。\n\n  * 可实现公平锁\n\n  * 可实现选择性通知：`synchronized`关键字与`wait()`和`notify()`/`notifyAll()`方法相结合可以实现等待/通知机制。`ReentrantLock`类当然也可以实现，但是需要借助于`Condition`接口与`newCondition()`方法。\n\n    >`Condition`是 JDK1.5 之后才有的，它具有很好的灵活性，比如可以实现多路通知功能也就是在一个`Lock`对象中可以创建多个`Condition`实例（即对象监视器），**线程对象可以注册在指定的`Condition`中，从而可以有选择性的进行线程通知，在调度线程上更加灵活。 在使用`notify()/notifyAll()`方法进行通知时，被通知的线程是由 JVM 选择的，用`ReentrantLock`类结合`Condition`实例可以实现“选择性通知”** ，这个功能非常重要，而且是 `Condition` 接口默认提供的。而`synchronized`关键字就相当于整个 `Lock` 对象中只有一个`Condition`实例，所有的线程都注册在它一个身上。如果执行`notifyAll()`方法的话就会通知所有处于等待状态的线程，这样会造成很大的效率问题。而`Condition`实例的`signalAll()`方法，只会唤醒注册在该`Condition`实例中的所有等待线程\n\n  ![image-20240107121000049](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202401071210166.png)\n  \n  \n\n## 2.3 适用场景\n\n|          | 乐观锁   | 悲观锁 |\n| -------- | -------- | ------ |\n| 适用场景 | 多读少写 | 多写   |","tags":["Java","多线程","乐观锁","悲观锁"],"categories":["Learning","Java"]},{"title":"论文阅读学习","url":"/post/4b1b8bf7.html","content":"**结构化数据 vs. 非结构化数据**\n\n* 结构化数据：也称行数据。由二维表结构来逻辑表达和实现，严格遵循数据格式与长度规范，主要通过关系型数据库进行存储管理\n* 非结构化数据：数据结构不规则或不完整，没有预定义的数据模型，不方便用数据库二维表来表现的数据。例如办公文档、文本、图片、HTML、音视频等等。\n\n<!-- more -->\n\n**Relation Extraction(RE)**\n\n关系提取。\n\n作用：从非结构化文本中提取结构化知识。\n\n\n\n**prompt-tuning**\n\n提示调整？\n\n通过完成掐词任务，直接采用预训练的 LM 作为预测器，以弥补预训练和微调之间的差距。\n\nprompt-tuning将原始输入与提示模板结合在一起来预测[MASK]，然后将预测的标签词映射到相应的类集，使得PLMs(Pre-trained Language Models)在少量任务上有更好的表现。\n","tags":["LLM","RE","fine-tuning"],"categories":["Learning","LLM"]},{"title":"Java内存区域","url":"/post/a7eb5674.html","content":"\n\n\n## 运行时数据区域\n\n<!-- more -->\n\nJDK1.7\n\n![Java 运行时数据区域（JDK1.7）](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202402011722151.png)\n\nJDK1.8\n\n![Java 运行时数据区域（JDK1.8 ）](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202402011722847.png)\n\n区别即为1.7中的方法区被1.8中的元空间替代了\n\n\n\n以上数据区域中：\n\n**线程共享**：\n\n* 堆\n* 方法区\n* 直接内存\n\n**线程私有**：\n\n* 程序计数器\n* 虚拟机栈\n* 本地方法栈\n\n\n\n### 程序计数器\n\n为一块较小的内存空间，可看作为当前线程所执行的字节码的`行号指示器`。\n\n字节码解释器工作时通过改变其取值来选取下一条需执行的字节码指令。\n\n分支、循环、跳转、异常处理、线程恢复都依赖程序计数器完成。\n\n所以，为了线程切换后能恢复到正确的位置，每个线程都需要有一个独立的程序计数器。\n\n**注**：程序计数器是唯一一个不会出现OOM的内存区域(因为其只保存下一条指令，内存小而固定)，其生命周期与线程保持一致。\n\n\n\n### 虚拟机栈\n\n其也为线程私有，生命周期与线程一致。\n\n除一些Native方法是通过本地方法栈实现，其他所有Java方法都是通过虚拟机栈来实现，为JVM运行时数据区域的一个核心。\n\n方法调用的数据由栈进行传递，每次方法调用都会有一个对应的栈帧被压入栈中，每次调用结束后都会有栈帧被弹出。\n\n> 栈由一个个栈帧组成，其中每个栈帧都包含：\n>\n> * 局部变量表\n> * 操作数栈\n> * 动态链接\n> * 方法返回地址\n\n**局部变量表**\n\n存放编译器可知的各种数据类型(8种基本数据类型)、对象引用(与对象本身不同，其可能是指向对象起始地址的引用指针，也可能是代表对象的句柄，总体而言为可以定位对象的数据)\n\n**操作数栈**\n\n作为方法调用的中转站使用，用于存放方法执行过程中的中间计算结果，以及计算过程中产生的临时变量。\n\n**动态链接**\n\n服务于一个方法需调用另一个方法的场景。\n\n当一个方法要调用其他方法，需要将常量池(Class文件中)中指向方法的符号引用转化为其在内存地址中的直接引用。\n\n动态链接的作用就是为了将符号引用转换为调用方法的直接引用，这个过程也被称为 动态连接 。\n\n\n\nJava返回方式：\n\n1. return正常返回\n2. 抛出异常\n\n无论哪种方式返回，都会导致栈帧被弹出，即无论正常还是异常都是方法结束。\n\n栈空间虽有限，但正常调用一般无问题。但当函数调用陷入无限循环，就会导致栈中被压入太多栈帧而占用太多空间，导致栈空间过深。当线程请求栈的深度超过Java虚拟机栈的最大深度时，就会出现`StackOverFlowError`（栈不允许动态扩展时）\n\n除以上错误外，当栈内存大小可以动态扩展，虚拟机在动态扩展栈时无法申请到足够的空间，则会抛出`OutOfMemory`异常。\n\n\n\n### 本地方法栈\n\n类似于虚拟机栈，但是本地方法栈为虚拟机使用到的Native方法服务。在hotspot中与虚拟机栈二合一。\n\n> **本地(Native)方法**\n>\n> 使用`native`声明，不提供函数体。是使用其他语言在另外的文件中编写，编写规则遵循java本地接口规范(JNI)\n\n本地方法被执行的时候，在本地方法栈也会创建一个栈帧，用于存放该本地方法的局部变量表、操作数栈、动态链接、出口信息。\n\n方法执行完毕后相应的栈帧也会出栈并释放内存空间，也会出现 `StackOverFlowError` 和 `OutOfMemoryError` 两种错误。\n\n\n\n### 堆\n\n是JVM管理的内存中最大的一块，是所有线程共享的一块内存区域，在虚拟机启动时创建。\n\n作用：存放对象实例，几乎所有的对象实例以及数组都在此处分配内存。\n\n> “几乎”所有对象。随JIT(Just In Time)编译器发展与逃逸计数逐渐成熟，对象分配到堆不绝对了。\n>\n> 从1.7开始已经默认开启逃逸分析，若某些方法中的对象引用未被返回或未被使用(即未逃逸出去)，则对象可以直接在栈上分配内存。\n\n堆是垃圾收集器的主要区域，因此也被称为GC堆。\n\n从垃圾回收角度，由于收集器基本都采用分代收集算法，所以Java堆还可以细分为：\n\n* 新生代\n  * Eden\n  * S0\n  * S1\n* 老年代\n\nJDK7中还有永久代PermGen，在后面被MetaSpace替代。\n\n堆中最容易出现`OutOfMemoryError`，且其表现形式会有多种，如：\n\n* `java.lang.OutOfMemoryError: GC Overhead Limit Exceeded`：当 JVM 花太多时间执行垃圾回收并且只能回收很少的堆空间时，就会发生此错误。\n* **`java.lang.OutOfMemoryError: Java heap space`** :假如在创建新的对象时, 堆内存中的空间不足以存放新创建的对象, 就会引发此错误。(和配置的最大堆内存有关，且受制于物理内存大小。最大堆内存可通过`-Xmx`参数配置，若没有特别配置，将会使用默认。\n\n\n\n#### 字符串常量池\n\n是 JVM 为了提升性能和减少内存消耗针对字符串（String 类）专门开辟的一块区域，主要目的是为了避免字符串的重复创建。\n\n````java\n// 在堆中创建字符串对象”ab“\n// 将字符串对象”ab“的引用保存在字符串常量池中\nString aa = \"ab\";\n// 直接返回字符串常量池中字符串对象”ab“的引用\nString bb = \"ab\";\nSystem.out.println(aa==bb);// true\n````\n\nJDK1.7之前，存放在PermGen，之后移动到堆中。\n\n**为什么移动到堆中？**\n\n永久代GC回收效率太低，只有在整堆收集Full GC时\n\n才会执行GC。\n\n而程序中通常有大量被创建的字符串等待回收，将其放入堆中，能够更高效回收字符串内存。\n\n\n\n`StringTable` 可以简单理解为一个固定大小的`HashTable` ，容量为 `StringTableSize`（可以通过 `-XX:StringTableSize` 参数来设置），保存的是字符串（key）和 字符串对象的引用（value）的映射关系，字符串对象的引用指向堆中的字符串对象。\n\n\n\n**StringTable中存的是引用还是对象？**\n\n[参考](https://www.zhihu.com/question/57109429/answer/151717241)\n\n？若堆中已有对象，则在StringTable中存其引用，若无，则存对象。\n\n````java\n//会创建两个对象，一个在堆中的字符串对象，一个为字符串常量池中的\"1\"\n// s1引用指向的为java heap中的对象\nString s1 = new String(\"1\");\n// 查看常量池，发现\"1\"已在常量池中\ns1.intern();\n// s2指向常量池中的\"1\"\nString s2 = \"1\";\n// s1 == s2 为false\n\n// new String分别创建两个对象，此时java heap中有对象\"a\",\"b\"，常量池中有对象\"a\",\"b\"\n// +后在java heap中生成新对象\"ab\"\n// s3引用指向java heap中的\"ab\",此时\"ab\"不在常量池中\nString s3 = new String(\"a\") + new String(\"b\");\n// 由于常量池也在堆区，常量池存储s3引用的\"ab\"对象的引用\ns3.intern();\n// 在常量池中寻找\"ab\"，其指向s3引用对象的一个引用，即s4引用与s3指向一致\nString s4 = \"ab\";\n// s3 == s4 为true\n````\n\n\n\n### 方法区\n\n不同的虚拟机实现上，方法区的实现是不同的。\n\n虚拟机使用类时，需读取并解析Class文件获取相关信息，再将信息存入方法区。\n\n方法区存储已被虚拟机加载的类信息、字段信息、方法信息、常量、静态变量、即时编译器编译后的代码等数据。\n\n**PermGen vs. MetaSpace**\n\n是方法区的不同实现方式。\n\n**为什么在1.8及以后将PermGen替换为MetaSpace?**\n\n1. 永久代有JVM设置的固定大小上限，无法调整，元空间使用本地内存，溢出可能性大大减小\n\n   ````java\n   -XX:MetaspaceSize=N //设置 Metaspace 的初始（和最小大小）\n   -XX:MaxMetaspaceSize=N //设置 Metaspace 的最大大小，默认unlimit\n   ````\n\n2. 元空间存放类的元数据，加载类的数量不由`MaxPermSize`控制了，而是根据系统实际可用空间控制，可以加载更多类\n\n3. 移除 PermGen 可以促进 HotSpot JVM 与 JRockit VM 的融合，因为 JRockit 没有永久代。\n\n\n\n#### 运行时常量池\n\nClass 文件中除了有类的版本、字段、方法、接口等描述信息外，还有用于存放编译期生成的各种字面量（Literal）和符号引用（Symbolic Reference）的 **常量池表(Constant Pool Table)** 。\n\n常量池表会在类加载后存放到方法区的运行时常量池中。\n\n运行时常量池的功能类似于传统编程语言的符号表，尽管它包含了比典型符号表更广泛的数据。\n\n既然运行时常量池是方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存时会抛出 `OutOfMemoryError` 错误。\n\n\n\n### 直接内存\n\n是一种特殊的内存缓冲区，是通过JNI的方式在本地内存上分配。\n\n在 JDK 1.4 中新加入了 NIO（New Input/Output）类，引入了一种基于通道（Channel）与缓冲区（Buffer）的 I/O 方式，它可以使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆里面的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在 Java 堆和 Native 堆中来回复制数据。\n\n直接内存并不是虚拟机运行时数据区的一部分，也不是虚拟机规范中定义的内存区域，但是这部分内存也被频繁地使用。而且也可能导致 `OutOfMemoryError` 错误出现。\n\n\n\n## HotSpot虚拟机对象\n\n### 对象创建\n\n**1. 类加载检查**\n\n虚拟机遇到`new`指令后，先检查这个指令的参数是否能在常量池中定位到该类的符号引用，并且检查这个符号引用代表的类是否已被加载、解析和初始化过，若没有，则需执行相应的类加载过程。\n\n**2. 分配内存**\n\n类加载检查通过后，虚拟机将为新生对象分配内存，对象所需内存大小在类加载完成后便可以确定。\n\n为对象分配空间的任务等同于将一块确定大小的内存从Java堆中划分出来。\n\n分配方式：\n\n* 指针碰撞\n\n  > * 适用场景：堆内存规整，即无内存碎片的情况\n  > * 原理：用过的内存与没用过的中间有一个分界指针，只需向着没用过的内存方向将该指针移动对象大小位置即可\n  > * 使用该分配方式的GC收集器：Serial, ParNew\n\n* 空闲列表\n\n  > * 适用场景：堆内存不规整\n  > * 原理：虚拟机会维护一个列表，该列表会记录哪些内存块是可用的，在分配时，找一块足够大的内存块来划分给对象实例，然后更新列表。\n  > * 使用该分配方式的GC收集器：CMS\n\n选着哪种方式由Java堆是否规整决定，而Java堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。\n\n> 内存分配并发问题\n>\n> 在创建对象的时候有一个很重要的问题，就是线程安全，因为在实际开发过程中，创建对象是很频繁的事情，作为虚拟机来说，必须要保证线程是安全的，通常来讲，虚拟机采用两种方式来保证线程安全：\n>\n> - **CAS+失败重试：** CAS 是乐观锁的一种实现方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。**虚拟机采用 CAS 配上失败重试的方式保证更新操作的原子性。**\n> - **TLAB：** 为每一个线程预先在 Eden 区分配一块儿内存，JVM 在给线程中的对象分配内存时，首先在 TLAB 分配，当对象大于 TLAB 中的剩余内存或 TLAB 的内存已用尽时，再采用上述的 CAS 进行内存分配\n\n**3. 初始化零值**\n\n内存分配完成后，虚拟机将分配到的内存空间都初始化为零值（不包括对象头）。\n\n该步保证了对象的实例字段在Java代码中可以不赋初值就直接使用，程序能够访问到这些字段的数据类型所对应的零值。\n\n**4. 设置对象值头**\n\n初始化零值完成之后，*虚拟机要对对象进行必要的设置*，例如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的 GC 分代年龄等信息。 这些信息存放在*对象头*中。另外，根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。\n\n**5. 执行init方法**\n\n以上步骤完成后，从虚拟机角度而言，新的对象已经产生了。但是从Java程序角度来看，对象创建刚开始，`<init>`方法还未执行，所有字段都还为零。\n\n所以一般而言，执行`new`之后会接着执行`<init>`方法，将对象按意愿初始化，这样一个完全真正可用的对象才产生出来。","tags":["Java","JVM","内存管理"],"categories":["Learning","Java"]},{"title":"Lambda与Stream","url":"/post/e6f6ebb1.html","content":"\n\n\n# Lambda表达式\n\n也称闭包，允许将函数作为一个方法的参数，即把函数作为参数传递进方法中。\n\n<!-- more -->\n\n语法：\n\n````java\n(parameter) -> expression\n    或\n(parameter) -> {statements;}\n````\n\n特征：\n\n* 可选类型声明：不需声明参数类型，编译器可以统一识别参数值\n* 可选的参数圆括号：一个参数无需定义圆括号，多个参数需要\n* 可选的大括号：只有一条语句，可以不使用大括号\n* 可选的返回关键字：只有一个表达式返回值则编译器会自动返回值，大括号需指定表达式返回了一个数值\n\n如：\n\n````java\nx -> 2 * x//接受一个数字类型的参数，并返回其2倍的值\n````\n\n注：\n\n* Lambda表达式主要用来定义行内执行的方法类型接口\n* Lambda表达式免去了使用匿名方法的麻烦，简单但强大的函数化编程能力\n\n\n\n## 变量作用域\n\n只能引用标记了`final`的外层局部变量/隐性的具有final语义，即不能在Lambda内部修改定义在域外的局部变量，否则会编译错误\n\nLambda表达式中不允许声明与局部变量同名的参数或局部变量。\n\n\n\n## 双冒号:: 方法引用\n\n`::`在Java8中被称作方法引用，提供了一种不执行方法的方法\n\n一般使用lambda表达式会创建匿名方法，但有时只需调用已存在的方法，此时就可以用到方法引用。\n\n使用场景：\n\n1. 静态方法引用（static method）语法：`classname::methodname` 例如：Person::getAge\n2. 对象的实例方法引用语法：`instancename::methodname` 例如：System.out::println\n3. 对象的超类方法引用语法： `super::methodname`\n4. 类构造器引用语法： `classname::new` 例如：ArrayList::new\n5. 数组构造器引用语法： `typename[]::new` 例如： String[]::new\n\n\n\n\n\n# Stream流\n\n使用的是函数式编程模式，可以用来对集合进行链状流式操作。\n\nStream流不存储数据，但是可以检索和逻辑处理集合数据，包括筛选、排序、统计、计数，类似于SQL语句。\n\n\n\n## 工作方式\n\n1. 创建流`Object.stream()`\n2. 对流进行中间操作：不加分号`;`，会再次返回一个流\n3. 对流进行终端操作：结束动作，一般返回`void`或非流结果\n\n源数据：Collection、Array.\n\n其方法参数都是函数式接口类型，所以一般和Lambda配合使用。\n\n\n\n## 不同类型的Stream流\n\n可以从各种数据类型中创建Stream流，其中Collection集合最为常见。\n\n\n\n### 常规对象流\n\n创建Stream流：\n\n````java\n// 1. 对象.stream()\nArrays.asList(\"a\",\"b\",\"c\").stream();\n\n// 2. 通过Stream.of()直接创建\nStream.of(\"a\",\"b\",\"c\");\n````\n\n\n\n### 原始类型流\n\n特殊的处理基本数据类型的流：`int`, `long`, `double`\n\n````java\n//处理int\nIntStream\n    \nIntStreams.range()；//用于取代常规的for循环\nIntStreams.range(1,4)\n    .forEach(System.out::println)\n//相当于：\nfor(int i=1;i<4;i++){\n    System.out.println(i);\n}\n\n// 处理long\nLongStream\n  \n// 处理double\nDoubleStream\n````\n\n* 原始类型流使用其独特的函数式接口，如`IntFunction`\n* 原始类型流支持额外的终端聚合操作，如`sum()`和`average()`\n\n\n\n### 类型转换\n\n常规对象流和原始类型流之间的转换：\n\n* 将常规对象流转换为原始类型流：中间操作`mapToInt()`, `mapToLong()`, `mapToDouble()`\n* 原始类型流转换为常规对象流：`mapToObj()`\n\n\n\n## Stream流的处理顺序\n\n中间操作特征：**延时性**\n\n当且仅当存在终端操作时，中间操作才会被执行。\n\n\n\n处理顺序：（垂直执行）随着链表垂直移动的，即完整执行一个元素的所有中间操作和终端操作后再执行下一个元素。\n\n* 垂直执行：先执行完某个元素的所有操作\n* 水平执行：先执行完所有元素的某个操作\n\n**注**：`sorted`是水平执行的\n\n原因：性能考虑，可以减少对每个元素的实际操作数。\n\n            比如执行到某个元素整个流就停止执行了，则其后方元素就可以不被处理，即减少了其后方元素的中间操作执行过程。\n\n如：共有5个元素，中间操作有3个，终端操作1个，为匹配到指定字符则返回true结束循环（`anyMatch()`）。假设第3个元素能成功匹配。\n\n* 处理顺序为所有元素执行完中间操作后再执行终端操作时：会执行$5 * 3$次中间操作，$3$次终端操作\n* 执行完一个元素所有操作再执行下一个元素：会执行$3*3$次中间操作，$3$次终端操作\n\n\n\n通过适当调整中间操作的顺序，如先过滤再执行其他，可以有效提升性能。\n\n\n\n## 数据流复用问题\n\n**Stream流是不能复用的，一旦调用终端操作，流就会关闭。如果此时再调用会抛出异常。**\n\n即一个Stream只能操作一次，不能断开，否则会报错。\n\n克服以上限制：为每个终端操作创建新的流链。\n\n如：可以通过`Supplier`来包装流，通过get方法来构建新的Stream流：\n\n````java\nSupplier<Stream<String>> streamSupplier =\n    () -> Stream.of(\"d2\", \"a2\", \"b1\", \"b3\", \"c\")\n            .filter(s -> s.startsWith(\"a\"));\n\nstreamSupplier.get().anyMatch(s -> true);   // ok\nstreamSupplier.get().noneMatch(s -> true);  // ok\n````\n\n\n\n## 常用方法\n\n![Java-stream(1) Stream基本概念& Stream接口-CSDN博客](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202402011723475.png)\n\n- 无状态：指元素的处理不受之前元素的影响。\n- 有状态：指该操作只有拿到所有元素之后才能继续下去。\n- 非短路操作：指必须处理所有元素才能得到最终结果。\n- 短路操作：指遇到某些符合条件的元素就可以得到最终结果，如 A || B，只要A为true，则无需判断B的结果。\n\n其中：\n\n* 遍历/匹配：forEach / find / match\n* 筛选：filter\n* 聚合：max / min / count\n* 映射：map / flatMap\n* 归约：reduce 把一个流缩减成一个值，能实现对集合求和、求乘积和求最值操作。\n* 收集：collect \n  * 归集：toList / toSet / toMap\n  * 统计：count / averaging\n  * 分组：partitioningBy / groupingBy\n  * 接合：joining\n  * 归约：reducing\n* 排序：sorted\n\n\n\n\n\n### forEach\n\n功能：迭代流中的每个数据\n\n````java\n//一般使用如下\nstream.forEach(System.out::println);\n````\n\n\n\n### map\n\n功能：用于映射每个元素到对应的结果\n\n````java\nList<Integer> numbers = Arrays.asList(3, 2, 2, 3, 7, 3, 5);\n// 获取对应的平方数\nList<Integer> squaresList = \n    numbers\n    .stream()\n    .map( i -> i*i)\n    .distinct()\n    .collect(Collectors.toList());\n````\n\n\n\n### filter\n\n功能：设置条件过滤出元素\n\n````java\nList<String>strings = Arrays.asList(\"abc\", \"\", \"bc\", \"efg\", \"abcd\",\"\", \"jkl\");\n// 获取空字符串的数量\nlong count = \n    strings\n    .stream()\n    .filter(string -> string.isEmpty())\n    .count();\n````\n\n\n\n### limit\n\n作用：获取指定数量的流\n\n如`.limit(5)`就为只获取5条\n\n\n\n### collect\n\n终端操作，将流中元素转变为另一个不同的对象，如`List`, `Set`等。\n\n参数：Collector(收集器)，一般直接使用内置的收集器即可\n\n创建新的收集器：Collector.of()\n\n主要使用`java.util.stream.Collectors`提供的静态方法。\n\n如`map`部分的示例中的`.collect(Collectors.toList());`即为将流转为`List`\n\n\n\n除了将流转化为集合元素外，还可以在流上执行聚合操作。\n\n如计算平均数：`.colllect(Collectors.averagingInt())`\n\n合并字符串：`.colllect(Collectors.joining([前缀], 分隔符，[后缀]))`，其中前缀与后缀可选\n\n\n\n\n\n## 并行流\n\n````java\n// 1. 集合通过parallelStream()创建并行流\nArrays.asList(\"a\",\"b\",\"c\")\n    .parallelStream()\n    \n// 2.在数据流上调用中间方法parallel()，将串行流转化为并行流\nStream.of(\"a\",\"b\",\"c\").parallel();\n````\n\n注：并行流中的`sorted`在底层使用了Java8中的新方法`Arrays.parallelSort()`。这个方法会按照数据长度来决定以串行方式，或者以并行的方式来执行。\n\n>如果指定数据的长度小于最小数值，它则使用相应的`Arrays.sort`方法来进行排序。","tags":["Java","Lambda表达式","Stream"],"categories":["Learning","Java"]},{"title":"SseEmmitter","url":"/post/e6f6ebb1.html","content":"## SseEmmitter\n\n作用：推送消息\n\n<!-- more -->\n\n### 介绍\n\n服务端常用推送消息的技术有：\n\n* 客户端轮询：ajax定时拉取\n\n* 服务端主动推送：WebSocket。\n\n  * 是**双全工**的(full deplex)，即可以同时进行信号的双向传输。\n  * 本质上是一个额外的tcp连接，建立与关闭时握手使用http协议，其他数据传输不使用http协议，而是更复杂一些，适用于需要进行复杂**双向**数据通讯的场景。\n  * 优点：强大灵活\n\n* 服务端主动推送：SSE(Server Send Event)。\n\n  * 基于单工通信模式，HTML5新标准，用来从服务端实时推送数据到浏览器端。\n\n  * 直接建立在当前http连接上，本质是保持一个http长连接。\n\n    注：http协议无法做到服务器主动推送消息。但是，可以变通为服务器向客户端声明，接下来发送的是流信息(streaming)，即发送的为数据流，会源源不断发送，如此，客户端不会关闭连接，会一直等着服务器发过来的新的数据流。（流信息本质为用时很长的下载）\n\nSSE优点：\n\n* 使用HTTP协议，现有服务器软件都支持。WebSocket是一个独立协议。\n\n* 轻量级，使用简单。\n\n* 默认支持断线重连，WebSocket需要自己实现。\n\n* 一般只用于传送文本，二进制数据需要编码后传送。WebSocket默认支持传送二进制数据。\n\n* 支持自定义发送的消息类型。\n\n\n\n### 使用\n\n大致使用步骤为：\n\n1. 客户端创建SseEmitter，即`EventSource`对象，向服务器发起连接\n2. 服务端存储客户端创建的SseEmitter\n\n\n\n#### 客户端API\n\n**1. EventSource对象**\n\nSSE客户端API部署在EventSource对象中，查看浏览器是否支持SSE：\n\n````javascript\nif ('EventSource' in window) {\n  // ...\n}\n````\n\n使用SSE：\n\n1. 浏览器生成EventSource实例，向服务器发起连接：\n\n   ````javascript\n   var source = new EventSource(url);\n   ````\n\n   其中，以上url可以与当前网址同域，也可以跨域。\n\n   跨域时：可以指定第二个参数，打开`withCredentials`属性，表示是否一起发送Cookie.即为：\n\n   ````javascript\n   var source = new EventSource(url, { withCredentials: true });\n   ````\n\n   EventSource实例的`readyState`属性，表示连接的当前状态，该属性**只读**，可取值如下：\n\n   - 0：相当于常量`EventSource.CONNECTING`，表示连接还未建立，或者断线正在重连。\n   - 1：相当于常量`EventSource.OPEN`，表示连接已经建立，可以接受数据。\n   - 2：相当于常量`EventSource.CLOSED`，表示连接已断，且不会重连。\n\n2. 连接一旦建立，就会触发`open`事件，可以在`onopen`属性定义回调函数。\n\n   ````javascript\n   source.onopen =  function (event){\n       // ...\n   };\n   \n   // 或者\n   source.addEventListener('open', function (event) {\n       // ...\n   }, false);\n   ````\n\n3. 客户端收到服务器发来的数据，会触发`message`事件，可以在`onmessage`属性定义回调函数，类似于onopen.\n\n   ````javascript\n   source.onmessage =  function (event){\n       var data = event.data;\n       // ...\n   };\n   \n   // 或者\n   source.addEventListener('message', function (event) {\n       var data = event.data;\n       // ...\n   }, false);\n   ````\n\n   其中，data即为服务器传回的数据（文本格式）\n\n4. 发生通信错误时，会触发`error`事件，可以在`onerror`属性中定义回调函数。\n\n5. 使用`close`方法关闭SSE连接\n\n   ````javascript\n   source.close();\n   ````\n\n6. 自定义事件的处理：\n\n   服务器发来的数据默认总是触发浏览器EventSource的message事件，也可以自定义SSE事件，如此，发送来的数据不会触发message事件。\n\n   ````javascript\n   source.addEventListener('event_name', function(event){\n       var data = event.data;\n       // ...\n   }, false);\n   ````\n\n   以上，浏览器对SSE的'event_name'事件监听，而服务器如何发送'event_name'事件呢？如下：\n\n\n\n#### 服务器实现\n\n**数据格式**：\n\n1. 必须是UTF8编码的文本\n\n2. 有如下HTTP头信息：\n\n   ````\n   Content-Type: text/event-stream\n   Cache-Control: no-cache\n   Connection: keep-alive\n   ````\n\n   Content-Type`必须指定 MIME 类型为`event-steam\n\n* 每次发送的信息，由若干个`message`组成，每个之间使用`\\n\\n`分隔。每个message内部都由若干行组成，每行格式如下：\n\n  ````javascript\n  [field]: value\\n\n  ````\n\n\n* field取值可以有四个：\n  * **data**：表示数据内容，可以分行，每行以`\\n`结尾，最后一行使用`\\n\\n`结尾\n  \n  * **event**：表示自定义的事件类型，默认是`message`事件。\n  \n  * **id**：表示数据标识符，相当于每条数据的编号。\n  \n    * 在浏览器中，使用`lastEventId`属性读取这个值。\n    * 断连时，浏览器会发送一个HTTP头，其中包含一个特殊的`Last-Event-ID`头信息，将该值发送回来，用于帮助服务器端重新建立连接。\n    * 因此，该头信息可被视为一种同步机制。\n  \n  * **retry**：表示浏览器重新发起连接的时间间隔。\n  \n    浏览器重新发起连接的两种情况：\n  \n    * 时间间隔到期\n    * 网络错误等原因导致连接出错\n  \n  示例：\n  \n  ````\n  id: msg1\\n\n  event: foo\\n\n  retry: 10000\\n\n  data: a foo event\\n\\n\n  ````\n  \n  \n  \n* 此外，还可以有冒号开头的行，表示注释。通常，服务器每隔一段时间就会向浏览器发送一个注释，**保持连接不中断**。\n\n  ````javascript\n  : This is a comment\n  ````\n\n\n\n参考：\n\n[Server-Sent Events 教程](https://www.ruanyifeng.com/blog/2017/05/server-sent_events.html)\n\n[springboot学习(五十八) springboot中使用SseEmitter推送消息](https://blog.csdn.net/u011943534/article/details/120251614)","tags":["Java","SpringBoot","SseEmmitter"],"categories":["Learning","Java"]},{"title":"反射","url":"/post/7af799fd.html","content":"\n# 反射机制\n\n在程序运行时期，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意方法和属性；这种动态获取信息以及动态调用方法的功能成为反射机制。\n\n<!-- more -->\n\n\n\n## Class类\n\n`java.lang.Class`\n\n所有普通类都是`Class`类的对象\n\n类代码经编译器编译后，会为每个类生成`.class`文件。\n\n运行期间，需要实例化一个类时，如String类，JVM会首先尝试查看内存中是否已经有这个类，如果有，则直接创建实例；若无该类，则会根据类名加载该类。\n\n加载一个类时，加载器(class loader)的`defineClass()`会被JVM调用，然后会为该类产生一个`Class`对象，该对象唯一，此类的所有实例都共同拥有这个`Class`对象。即为：\n\n````java\nClass cls = new Class(String);\n````\n\n该Class实例为JVM内部创建，在JDK源码中，其构造方法为`private`。即只能由JVM创建Class实例。\n\n所以，JVM持有的每一个Class实例都指向一个数据类型（class或interface）\n\n一个Class实例包含了该class的所有完整信息，如：\n\n```ascii\n┌───────────────────────────┐\n│      Class Instance       │──────> String\n├───────────────────────────┤\n│name = \"java.lang.String\"  │\n├───────────────────────────┤\n│package = \"java.lang\"      │\n├───────────────────────────┤\n│super = \"java.lang.Object\" │\n├───────────────────────────┤\n│interface = CharSequence...│\n├───────────────────────────┤\n│field = value[],hash,...   │\n├───────────────────────────┤\n│method = indexOf()...      │\n└───────────────────────────┘\n```\n\n由于JVM为每个加载的`class`创建了对应的`Class`实例，并在实例中保存了该`class`的所有信息，包括类名、包名、父类、实现的接口、所有方法、字段等。\n\n因此，如果获取了某个`Class`实例，我们就可以通过这个`Class`实例获取到该实例对应的`class`的所有信息。\n\n以上这种通过`Class`实例获取`class`信息的方法称为反射。\n\n\n\n### 如何获取类的Class实例\n\n1. 直接通过一个类的静态变量`class`获取\n\n   ````java\n   Class cls = String.class\n   ````\n\n2. 通过实例变量的`getClass()`方法获取\n\n   ````java\n   String s = \"hello\";\n   Class cls = s.getClass();\n   ````\n\n3. 知道完整类名时，可以通过静态方法`Class.forName()`获取\n\n   ````java\n   Class cls = Class.forName(\"java.lang.String\");\n   ````\n\n以上三种方法获取的Class实例都是同一实例。\n\n获取到Class实例后，可以通过该实例来创建对应类型的实例，如：\n\n````java\nClass cls = String.class;\nString s = (String) cls.newInstance();\n//相当于new String()\n//注：只能调用无参的构造方法\n````\n\n**Q**: 为什么要使用反射创建实例？\n\n**A**: 反射可以动态获取类信息，若静态创建，类名或其相关操作发生变化则需修改源码，而反射无需做修改，相比静态而言修改变少，高效很多。\n\n\n\n### Class实例 vs. instanceof\n\n````java\nInteger n = new Integer(123);\n\nboolean b1 = n instanceof Integer; // true，因为n是Integer类型\nboolean b2 = n instanceof Number; // true，因为n是Number类型的子类\n\nboolean b3 = n.getClass() == Integer.class; // true，因为n.getClass()返回Integer.class\nboolean b4 = n.getClass() == Number.class; // false，因为Integer.class!=Number.class\n````\n\n`instanceof`不但匹配指定类型，还会匹配指定类型的父类\n\n\n\n## 访问字段\n\n### 获取字段\n\n`import java.lang.reflect.Field;`\n\n通过Class实例获取字段：\n\n* `Field getField(name)`：根据字段名获取某个`public`的field（包括父类）\n* `Field getDeclaredField(name)`：根据字段名获取当前类的某个field（不包括父类）\n* `Field[] getFields()`：获取所有`public`的field（包括父类）\n* `Field[] getDeclaredFields()`：获取当前类的所有field（不包括父类）\n\n一个`Field`对象包含了一个字段的所有信息：\n\n- `getName()`：返回字段名称，例如，`\"name\"`；\n- `getType()`：返回字段类型，也是一个`Class`实例，例如，`String.class`；\n- `getModifiers()`：返回字段的修饰符，它是一个`int`，不同的bit表示不同的含义。\n\n\n\n### 获取、设置字段值\n\n````java\nString s = \"abc\";\nClass cls = s.getClass();\nField f = cls.getDeclaredField(\"value\");\n\n//获取value的值\nf.get(s);\n\n/* 由于value是private，会报IllegalAccessException\n * 可以在get前增加\n * f.setAccessible(true)\n * 意为字段不管是不是public都允许访问，但是不一定百分百成功。\n */\n\n//设置字段值\nf.set(s,\"newValue\");\n//同样，非public字段需要设置setAccessible(true)\n````\n\n\n\n\n\n## 调用方法\n\n### 获取方法\n\n- `Method getMethod(name, Class...)`：获取某个`public`的`Method`（包括父类）\n- `Method getDeclaredMethod(name, Class...)`：获取当前类的某个`Method`（不包括父类）\n- `Method[] getMethods()`：获取所有`public`的`Method`（包括父类）\n- `Method[] getDeclaredMethods()`：获取当前类的所有`Method`（不包括父类）\n\n一个`Method`对象包含一个方法的所有信息：\n\n- `getName()`：返回方法名称，例如：`\"getScore\"`；\n- `getReturnType()`：返回方法返回值类型，也是一个Class实例，例如：`String.class`；\n- `getParameterTypes()`：返回方法的参数类型，是一个Class数组，例如：`{String.class, int.class}`；\n- `getModifiers()`：返回方法的修饰符，它是一个`int`，不同的bit表示不同的含义。\n\n\n\n### 调用方法\n\n````java\nString s = \"abc\";\n\n//获取String substring(i)方法，参数为int\nMethod m = String.class.getMethod(\"substring\",int.class);\n\n//利用反射调用method方法：invoke(params)\nString r = (String) method.invoke(s,1);\n//结果为：bc\n````\n\n调用非`public`方法时，同样需要`setAccessible(true)`\n\n\n\n### 获取静态方法\n\n调用静态方法时，无需指定实例对象，所以调用`invoke()`方法时，第一个参数为`null`\n\n````java\n//parseInt为Integer的静态方法\nMethod method = Integer.class.getMethod(\"parseInt\",String.class);\n\n//利用反射调用parseInt方法\nInteger i = (Integer) method.invoke(null, \"123456\");\n//i的值为：123456\n````\n\n\n\n### 调用构造方法\n\n使用`newInstance()`来创建新实例。\n\n````java\nString s = String.class.newInstance();\n// s为空\n````\n\n注：只能调用类的public无参构造方法，其余构造方法无法通过`Class.newInstance()`调用。\n\n**怎么调用任意构造方法？**\n\n使用`Constructor`对象。\n\n通过Class实例获取Constructor的方法如下：\n\n- `getConstructor(Class...)`：获取某个`public`的`Constructor`；\n- `getDeclaredConstructor(Class...)`：获取某个`Constructor`；\n- `getConstructors()`：获取所有`public`的`Constructor`；\n- `getDeclaredConstructors()`：获取所有`Constructor`。\n\n````java\n// 获取构造方法\nConstructor cons = String.class.getConstructor(String.class);\n\n//调用构造方法\nString s = (String) cons.newInstance(\"test\");\n//s为：test\n````\n\n\n\n### 多态\n\n使用反射机制调用方法时，仍然遵循多态原则。即总是调用实际类型所覆写的方法（若存在）\n\n\n\n## 获取继承关系的Class\n\n### 获取父类Class实例\n\n````java\nClass i = Integer.class;\n\n//获取Integr父类的Class实例\nClass n = i.getSuperClass();\n````\n\n除`Object`外，其他任何非`interface`的`Class`都必定存在一个父类类型。\n\n\n\n### 获取interface的Class实例\n\n一个类可实现多个接口，可以查询所有其实现的接口类型。\n\n````java\nClass i = Integer.class;\nClass[] is = i.getInterfaces();\n````\n\n注：`getInterfaces()`只返回当前类直接实现的接口类型，并不包括其父类实现的接口类型\n\n获取接口的父接口应使用`getInterfaces()`而不是`getSuperClass()`\n\n\n\n### 继承关系判断\n\n判断一个实例是否为某类型时，可以使用`instanceof`进行判断。\n\n若为两个`Class`实例，需判断一个向上转型是否成立，可以使用`isAssignableFrom()`\n\n````java\n// Integer i = ?\nInteger.class.isAssignableFrom(Integer.class); // true，因为Integer可以赋值给Integer\n// Number n = ?\nNumber.class.isAssignableFrom(Integer.class); // true，因为Integer可以赋值给Number\n// Object o = ?\nObject.class.isAssignableFrom(Integer.class); // true，因为Integer可以赋值给Object\n// Integer i = ?\nInteger.class.isAssignableFrom(Number.class); // false，因为Number不能赋值给Integer\n````\n\n\n\n## 动态代理\n\n所有`interface`类型的变量总是通过某个实例向上转型并赋值给接口类型变量的，如：\n\n````java\nList<String> list = new ArrayList<>();\n````\n\n那有没有可能不编写实现类，直接在运行期创建某个`interface`的实例呢？\n\n这是可能的，因为Java标准库提供了一种动态代理（Dynamic Proxy）的机制：可以在运行期动态创建某个`interface`的实例。\n\n大致流程：定义接口后，不编写实现类，而是通过JDK提供的`Proxy.newProxyInstance()`创建所定义的接口对象。\n\n这种无实现类但是在运行期动态创建一个接口对象的方式称为动态代码。JDK提供的动态创建接口对象的方式就叫动态代理。\n\n具体过程：\n\n1. 定义一个`InvocationHandler`实例，负责实现接口的方法调用\n2. 通过`Proxy.newProxyInstance()`创建interface实例，其需要三个参数：\n   * 使用的ClassLoader，通常为接口类的ClassLoader\n   * 需要实现的接口数组，通常需要传入一个接口\n   * 用来处理接口方法调用的`InvocationHandler`实例\n3. 将返回的Object强制转型为接口\n\n如下，定义了一个`Hello`接口，其中有一个`morning()`方法\n\n````java\npublic class Main {\n    public static void main(String[] args) {\n        InvocationHandler handler = new InvocationHandler() {\n            @Override\n            public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n                System.out.println(method);\n                if (method.getName().equals(\"morning\")) {\n                    System.out.println(\"Good morning, \" + args[0]);\n                }\n                return null;\n            }\n        };\n        Hello hello = (Hello) Proxy.newProxyInstance(\n            Hello.class.getClassLoader(), // 传入ClassLoader\n            new Class[] { Hello.class }, // 传入要实现的接口\n            handler); // 传入处理调用方法的InvocationHandler\n        hello.morning(\"Bob\");\n    }\n}\n\ninterface Hello {\n    void morning(String name);\n}\n````\n\n\n\n## 反射特点\n\n### 优点\n\n灵活、自由度高，不受类的访问权限控制\n\n\n\n### 缺点\n\n* 性能问题：通过反射访问、修改类的属性和方法时会远慢于直接操作\n* 安全问题：破坏了类的封装性\n\n\n\n### 如何提高反射性能\n\n* `setAccessible(true)`，可以防止安全检查\n* 缓存，将经常访问的元数据放入内存中，`class.forName`很耗时\n* `getMethod()`少用，尽量指定方法名称`getMethod(name)`，减少遍历次数","tags":["Java","反射"],"categories":["Learning","Java"]},{"title":"容器与集合","url":"/post/5d4053e7.html","content":"\n# 容器与集合\n\n<!-- more -->\n\n## Collection体系\n\n![image-20231211195144263](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202312111951493.png)\n\n### 常见方法\n\n````java\n// 增加元素\nboolean add(Object obj)\nboolean addAll(Collection c)\n\n// 删除元素\nvoid clear()\nboolean remove(Object obj)\n\nboolean contains(Object obj)\n\nboolean equals(Object obj)\n\nboolean isEmpty()\n\nint size()\n\nObject[] toArray()\n    \n//排序，需Object对象实现Comparable接口\nCollection sort(Object c)\n//使用方式\nCollections.sort(Collection c)\n````\n\n**注**：\n\n* `length`属性：针对数组，即数组长度\n* `length()`：针对字符串，即字符串长度\n* `size()`：针对泛型集合，即泛型元素个数\n\n\n\n### 集合遍历\n\n#### 1. for-each\n\n````java\nfor(Object obj : Collection c){\n    //action\n}\n````\n\n\n\n#### 2. Iterator\n\n````java\n/* 常用方法\nboolean hasNext()\nE next()\nvoid remove()\n*/\nCollection collection;\nIterator<E> it = collection.iterator();\nwhile(it.hasNext()){\n    E obj = it.next();\n    //可以使用it.remove()删除当前元素\n    //不能使用collection.remove()删除，会报并发修改异常\n}\n````\n\n\n\n\n\n\n\n## List\n\n ### List接口\n\n#### 创建对象\n\n````java\nList<E> list1 =  new ArrayList<>();\nList<E> list2 =  new LinkedList<>();\n````\n\n\n\n#### 常用方法\n\n````java\n//添加元素，会对基本类型自动装箱\nlist.add();\n\n//删除元素，可以使用索引删除，也可以删除某个元素（多次出现时删除第一个）\nlist.remove(0);//返回删除的元素\nlist.remove(\"value\")；//返回true/fasle\n//注：当删除数字与索引冲突时，将数字变为引用类型\n    \n//访问元素，使用索引访问\nlist.get(0);\n\n//修改元素，指定索引与修改后的值\nlist.set(2,\"value\")\n    \n//获取索引/位置\nlist.indexOf(\"value\");\n\n//获取子集合，左闭右开\nlist.subList(1,3);//获取的是索引为1，2\n````\n\n\n\n#### 遍历\n\n除集合的`for-each`，`iterator`外还可使用：\n\n1. 直接使用`for循环`遍历\n\n2. 使用`列表迭代器`\n\n   ````java\n   ListIterator li = list.ListIterator();\n   \n   //从前往后遍历\n   while(li.hasNext()){\n       li.nextIndex();\n       li.next();\n   }\n   \n   //从后往前遍历\n   while(li.hasPrevious()){\n       li.previousIndex();\n       li.previous();\n   }\n   ````\n\n   \n\n\n\n### List实现类对比(ArrayList, LinkdedList, Vector)\n\n|                  | ArrayList                                                 | LinkedList                                                   | Vector         |\n| ---------------- | --------------------------------------------------------- | ------------------------------------------------------------ | -------------- |\n| 实现方式         | Object数组                                                | 双向链表                                                     | Object数组     |\n| 是否需要连续空间 | 是                                                        | 否                                                           | 是             |\n| 速度             | 查询快（$O(1)$）<br />增删慢（$O(n)$,尾插不扩容为$O(1)$） | 查询慢（$O(n)$）<br />增删快（头尾插$O(1)$,指定位置插$O(n)$） | 查询快、增删慢 |\n| 是否线程安全     | 否                                                        | 否                                                           | 是             |\n| 是否支持随机访问 | 是                                                        | 否（故不能实现RandomAccess接口）                             | 是             |\n\n**RandomAccess接口**\n\n源码：\n\n````java\npublic interface RandomAccess {\n}\n````\n\n什么都没有定义，相当于只是一个**标识**实现此接口的类具有随机访问的功能。\n\n**注：ArrayList不是实现了RandomAccess接口才有的随机访问能力，而是底层数据结构使其天然有随机访问能力，RandomAccess只是表明其有此能力，只有标识的功能。**\n\n\n\n### ArrayList源码分析\n\n底层数据结构：数组队列，即相当于动态数组。\n\n````java\npublic class ArrayList<E> extends AbstractList<E>\n        implements List<E>, RandomAccess, Cloneable, java.io.Serializable{\n\n  }\n````\n\n实现的接口：\n\n* List：表明其是一个列表，支持List的基本操作\n\n* RandomAccess：标识其支持快速随机访问\n\n* Cloneable：表明其具有拷贝能力，可以进行深拷贝或浅拷贝\n\n  > * 浅拷贝：新创建一个对象，该对象有着原始对象属性值的一份精确拷贝。即原始对象属性为基本类型，则拷贝基本属性的值，若其为引用类型，拷贝其内存空间地址（即不会新创建这个引用类型）\n  > * 深拷贝：将对象从内存中完整拷贝出来，即会在堆中创建新对象，若原始对象属性为引用类型，则会重新创建这个引用类型。（即不与原始对象共享内存）\n\n* Serializable：表明可以进行序列化操作。即将对象转化为字节流进行持久化存储或网络传输。\n\n\n\n源码分析\n\n````java\nDEFAULT_CAPACITY = 10; //默认容量\n//注意：未指定初始容量时，如果没有向集合中添加任何元素时，容量0，添加一个后，容量为10\n//每次扩容是原来的1.5倍\nelementData存放元素的数组\nsize 实际元素个数\n````\n\n\n\n#### 扩容机制\n\n**ArrayList的构造函数（共三种）**\n\n````java\n   /**\n     * 默认初始容量大小\n     */\n    private static final int DEFAULT_CAPACITY = 10;\n\n\n    /**\n     * 空数组（用于空实例）。用于指定了容量为0的空数组\n     */\n    private static final Object[] EMPTY_ELEMENTDATA = {};\n\n     //用于默认大小空实例的共享空数组实例。\n     //我们把它从EMPTY_ELEMENTDATA数组中区分出来，以知道在添加第一个元素时容量需要增加多少。\n    private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {};\n\n    /**\n     * 1. 默认构造函数，使用初始容量10构造一个空列表(无参数构造)\n     */\n    public ArrayList() {\n        this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;\n    }\n\n    /**\n     * 2. 带初始容量参数的构造函数。（用户自己指定容量）\n     */\n    public ArrayList(int initialCapacity) {\n        if (initialCapacity > 0) {//初始容量大于0\n            //创建initialCapacity大小的数组\n            this.elementData = new Object[initialCapacity];\n        } else if (initialCapacity == 0) {//初始容量等于0\n            //创建空数组\n            this.elementData = EMPTY_ELEMENTDATA;\n        } else {//初始容量小于0，抛出异常\n            throw new IllegalArgumentException(\"Illegal Capacity: \"+\n                                               initialCapacity);\n        }\n    }\n\n\n   /**\n    * 3. 构造包含指定collection元素的列表，这些元素利用该集合的迭代器按顺序返回\n    *    如果指定的集合为null，throws NullPointerException。\n    */\n     public ArrayList(Collection<? extends E> c) {\n        elementData = c.toArray();\n        if ((size = elementData.length) != 0) {\n            // c.toArray might (incorrectly) not return Object[] (see 6260652)\n            if (elementData.getClass() != Object[].class)\n                elementData = Arrays.copyOf(elementData, size, Object[].class);\n        } else {\n            // replace with empty array.\n            this.elementData = EMPTY_ELEMENTDATA;\n        }\n    }\n````\n\n无参构造创建ArrayList时，初始化赋值的为一个空数组。真正添加元素时才会分配容量，即添加第一个元素时，容量初始化为10.\n\n\n\n以无参构造函数分析扩容机制：\n\n`add`方法：\n\n````java\n    /**\n     * 将指定的元素追加到此列表的末尾。\n     */\n    public boolean add(E e) {\n   //添加元素之前，先调用ensureCapacityInternal方法\n        ensureCapacityInternal(size + 1);  // Increments modCount!!\n        //这里看到ArrayList添加元素的实质就相当于为数组赋值\n        elementData[size++] = e;\n        return true;\n    }\n````\n\n可以看到首先调用了`ensureCapacityInternal(size + 1)`\n\n````java\n   //得到最小扩容量\n    private void ensureCapacityInternal(int minCapacity) {\n        if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) {\n              // 获取默认的容量和传入参数的较大值\n            minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity);\n        }\n\n        ensureExplicitCapacity(minCapacity);\n    }\n````\n\n当 要 add 进第 1 个元素时，minCapacity 为 1，在 Math.max()方法比较后，minCapacity 为 10。\n\n然后其又调用了`ensureExplicitCapacity(minCapacity)`\n\n````java\n  //判断是否需要扩容\n    private void ensureExplicitCapacity(int minCapacity) {\n        modCount++;\n\n        // overflow-conscious code\n        if (minCapacity - elementData.length > 0)\n            //调用grow方法进行扩容，调用此方法代表已经开始扩容了\n            grow(minCapacity);\n    }\n````\n\n即为：\n\n* add第1个元素时，`elementData.length=0`执行`ensureCapacityInternal`方法，`minCapacity`变为`10`。此时`minCapacity - elementData.length > 0`成立，调用`grow(minCapacity)`\n* add第2个元素时，`elementData.length=10`，`minCapability=2`，所以`minCapacity - elementData.length > 0`不成立，不会调用`grow(minCapacity);`\n* 直到add第11个元素，此时`elementData.length=10`，`minCapability=11`，调用`grow(minCapacity)`进行**扩容**\n\n`grow()`\n\n````java\n    /**\n     * 要分配的最大数组大小\n     */\n    private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;\n\n    /**\n     * ArrayList扩容的核心方法。\n     */\n    private void grow(int minCapacity) {\n        // oldCapacity为旧容量，newCapacity为新容量\n        int oldCapacity = elementData.length;\n        //将oldCapacity 右移一位，其效果相当于oldCapacity /2，\n        //我们知道位运算的速度远远快于整除运算，整句运算式的结果就是将新容量更新为旧容量的1.5倍(偶数为1.5倍，奇数为1.5倍左右)\n        int newCapacity = oldCapacity + (oldCapacity >> 1);\n        //然后检查新容量是否大于最小需要容量，若还是小于最小需要容量，那么就把最小需要容量当作数组的新容量，\n        if (newCapacity - minCapacity < 0)\n            newCapacity = minCapacity;\n       // 如果新容量大于 MAX_ARRAY_SIZE,进入(执行) `hugeCapacity()` 方法来比较 minCapacity 和 MAX_ARRAY_SIZE，\n       //如果minCapacity大于最大容量，则新容量则为`Integer.MAX_VALUE`，否则，新容量大小则为 MAX_ARRAY_SIZE 即为 `Integer.MAX_VALUE - 8`。\n        if (newCapacity - MAX_ARRAY_SIZE > 0)\n            newCapacity = hugeCapacity(minCapacity);\n        // minCapacity is usually close to size, so this is a win:\n        elementData = Arrays.copyOf(elementData, newCapacity);\n    }\n\n````\n\n如果新容量大于 MAX_ARRAY_SIZE,进入(执行) `hugeCapacity()` 方法来比较 minCapacity 和 MAX_ARRAY_SIZE\n\n````java\n    private static int hugeCapacity(int minCapacity) {\n        if (minCapacity < 0) // overflow\n            throw new OutOfMemoryError();\n        //对minCapacity和MAX_ARRAY_SIZE进行比较\n        //若minCapacity大，将Integer.MAX_VALUE作为新数组的大小\n        //若MAX_ARRAY_SIZE大，将MAX_ARRAY_SIZE作为新数组的大小\n        //MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;\n        return (minCapacity > MAX_ARRAY_SIZE) ?\n            Integer.MAX_VALUE :\n            MAX_ARRAY_SIZE;\n    }\n````\n\n\n\n#### System.arraycopy() vs.  Arrays.copyOf()\n\n`System.arraycopy()`\n\n````java\n    // arraycopy 是一个 native 方法,接下来我们解释一下各个参数的具体意义\n    /**\n    *   复制数组\n    * @param src 源数组\n    * @param srcPos 源数组中的起始位置\n    * @param dest 目标数组\n    * @param destPos 目标数组中的起始位置\n    * @param length 要复制的数组元素的数量\n    */\n    public static native void arraycopy(Object src,  int  srcPos,\n                                        Object dest, int destPos,\n                                        int length);\n````\n\n`Arrays.copyOf()`\n\n```java\npublic static int[] copyOf(int[] original, int newLength) {\n\t// 申请一个新的数组\n    int[] copy = new int[newLength];\n// 调用System.arraycopy,将源数组中的数据进行拷贝,并返回新的数组\n    System.arraycopy(original, 0, copy, 0,\n                     Math.min(original.length, newLength));\n    return copy;\n}\n```\n\n* 联系：Arrays.copyOf()内部调用了System.arraycopy()\n\n* 区别：arraycopy()需要目标数组，可以选择拷贝的起点、放入目标数组的起点；\n\n              copyOf()是在内部新建一个数组然后返回。\n\n\n\n\n\n## Set\n\n特点：\n\n* 无序：不等于随机性，无序指存储的数据在底层数组中并非按照数组索引的顺序添加，而是根据数据的哈希值决定。\n* 无下标\n* 不可重复性：元素按`equals()`判断时，返回`false`，需同时重写`equal()`和`hashCode()`方法。\n\n方法：全部继承自Collection方法\n\n\n\n### Comparable vs. Comparator\n\n|                | Comparable                                                   | Comparator                                                   |\n| -------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| 作用           | 排序接口，相当于内部比较器                                   | 比较接口，相当于外部比较器                                   |\n| 所来自的包     | java.lang                                                    | java.util                                                    |\n| 用于排序的方法 | compareTo(Object obj)                                        | compare(Object obj1, Object obj2)                            |\n| 排序规则       | 正序：当前对象this减去传入的比较对象obj的值<br />倒序：比较对象obj减去当前对象this的值 | 正序：obj1减去obj2的值<br />倒序：obj2减去obj1的值           |\n| 实现           | 需排序的类实现接口后重写`compareTo()`                        | 新建一个类ObjComparator实现该接口，即构造一个“比较器”（也可以直接在`sort`方法中`new Comparator<Object>`然后重写方法[使用匿名内部类]） |\n| 支持           | Collections.sort()<br />Arrays.sort()                        | Collections.sort(Object obj, new ObjComparator)<br />Arrays.sort(Object obj, new ObjComparator()) |\n| 优缺点         | 简单，但是需修改类内部源代码                                 | 不用修改源代码，在实现的比较器中传入需比较对象即可。可以实现可复用的通用逻辑。 |\n\n\n\n### HashSet、LinkedHashSet、TreeSet比较\n\n|              | HashSet                      | LinkedHashSet            | TreeSet                  |\n| ------------ | ---------------------------- | ------------------------ | ------------------------ |\n| 底层数据结构 | 哈希表（基于HashMap实现）    | 哈希表+链表              | 红黑树                   |\n| 应用场景     | 不需要保证元素插入和取出顺序 | 保证插入取出顺序满足FIFO | 支持对元素自定义排序规则 |\n| 是否线程安全 | 否                           | 否                       | 否                       |\n\n**HashSet存储过程**：\n\n1. 根据`hashCode()`计算保存的位置，如果位置为空，直接保存，不为空进入下一步\n   * 利用质数`31`减少散列冲突\n     * 31提高执行效率 `31 * i = (i << 5) - i` 转为移位操作【可以被JVM优化】\n2. 执行`equals()`方法，为`true`则认为重复，拒绝存入，否则形成链表\n\n \n\n## Map\n\n特点：\n\n* 存储任意键值对（`key-value`）\n* `key`：无序、无下标、唯一\n* `value`：无序、无下标，可重复\n\n\n\n常用方法：\n\n````java\n//存储对象\nObject put(Object key, Object value)\n\n//根据key获取value\nObject get(Object Key);\n\n//根据key删除key-value(若存在)\nObject remove(Object key);\n    \n//获取所有key\nSet keySet();\n\n//获取所有映射关系,Set实例化为Set<Map.Entry<String, String>>，然后可以调用每个entry对象的getKey和getValue获取键值对\nSet entrySet();\n````\n\n\n\n### HashMap\n\n可以存储`null`的`key`和`value`，但是`key`最多有一个为`null`.\n\n\n\n#### JDK 1.8之前底层数据结构分析\n\n此时底层数据结构为：**数组和链表**结合使用，即链表散列\n\n数据存储流程：\n\n1. HashMap通过`key`的`hashCode`经过**扰动函数**处理后得到`hash值`\n\n2. 然后通过`(n - 1) & hash`判断当前元素存放的位置（n为数组长度）\n\n   >`(n - 1) & hash`即为`hash % (n)`（当n为$2^x$时）\n\n3. 若当前位置存在元素，则判断该元素与要存入元素的`hash值`以及`key`是否相同\n\n4. 相同直接覆盖；不同则通过**拉链法**解决冲突\n\n\n\n**拉链法**\n\n数组与链表结合，即创建一个链表数组。遇到哈希冲突时，将冲突值加入链表即可。\n\n![image-20231211195341444](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202312111953674.png)\n\n#### JDK1.8之后底层数据结构分析\n\n在解决哈希冲突时有了较大变化\n\n在拉链法的基础上：\n\n1. 当链表长度大于阈值（默认为`8`），会首先调用`treeifyBin()`决定是否转换为红黑树\n\n2. 当hashMap`数组长度>=64`时，转换为红黑树以减少搜索时间\n\n   > 红黑树节点数小于6时又会调整为链表\n\n3. 数组长度未达到`64`时，执行`resize()`方法对数组扩容。\n\n![image-20231211195531634](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202312111955729.png)\n\n\n\n#### 源码分析\n\n##### 属性列表\n\n````java\npublic class HashMap<K,V> extends AbstractMap<K,V> implements Map<K,V>, Cloneable, Serializable {\n    // 序列号\n    private static final long serialVersionUID = 362498820763181265L;\n    // 默认的初始容量是16\n    static final int DEFAULT_INITIAL_CAPACITY = 1 << 4;\n    // 最大容量\n    static final int MAXIMUM_CAPACITY = 1 << 30;\n    // 默认的负载因子\n    static final float DEFAULT_LOAD_FACTOR = 0.75f;\n    // 当桶(bucket)上的结点数大于等于这个值时会转成红黑树\n    static final int TREEIFY_THRESHOLD = 8;\n    // 当桶(bucket)上的结点数小于等于这个值时树转链表\n    static final int UNTREEIFY_THRESHOLD = 6;\n    // 桶中结构转化为红黑树对应的table的最小容量\n    static final int MIN_TREEIFY_CAPACITY = 64;\n    // 存储元素的数组，总是2的幂次倍\n    transient Node<k,v>[] table;\n    // 存放具体元素的集\n    transient Set<map.entry<k,v>> entrySet;\n    // 存放元素的个数，注意这个不等于数组的长度。\n    transient int size;\n    // 每次扩容和更改map结构的计数器\n    transient int modCount;\n    // 阈值(容量*负载因子) 当实际大小超过阈值时，会进行扩容\n    int threshold;\n    // 负载因子\n    final float loadFactor;\n}\n````\n\n* `loadFactor`负载因子\n\n  控制数组存放数据的疏密程度。\n\n  * 越趋近于`1`，数组中存放的数据(entry)越多，也就越密，也就是会让链表长度增加（即扩容在满了才会发生）；\n\n  * 越趋近于`0`，数组中存放的数据越少，也就越稀疏。\n\n  大小控制：loadFactor 太大导致查找元素效率低，太小导致数组的利用率低，存放的数据会很分散。loadFactor 的默认值为` 0.75f `是官方给出的一个比较好的临界值。\n\n  * **why 0.75**\n\n    $阈值(threshold) = 负载因子(loadFactor) * 容量(capacity)$\n\n    > 元素个数超过threshold就会进行扩容\n\n    由hashMap的机制，容量一直为2的幂。所以为了保证$负载因子(loadFactor) * 容量(capacity)$的结果为整数，loadFactor为0.75比较合理，因为其与2的幂的乘积都为整数。\n\n\n\n##### 构造方法\n\n总共有四个构造方法：\n\n```java\n// 1. 默认构造函数。\npublic HashMap() {\n    this.loadFactor = DEFAULT_LOAD_FACTOR; // all   other fields defaulted\n }\n\n // 2. 包含另一个“Map”的构造函数\n public HashMap(Map<? extends K, ? extends V> m) {\n     this.loadFactor = DEFAULT_LOAD_FACTOR;\n     putMapEntries(m, false);//下面会分析到这个方法\n }\n\n // 3. 指定“容量大小”的构造函数\n public HashMap(int initialCapacity) {\n     this(initialCapacity, DEFAULT_LOAD_FACTOR);\n }\n\n // 4. 指定“容量大小”和“负载因子”的构造函数\n public HashMap(int initialCapacity, float loadFactor) {\n     if (initialCapacity < 0)\n         throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity);\n     if (initialCapacity > MAXIMUM_CAPACITY)\n         initialCapacity = MAXIMUM_CAPACITY;\n     if (loadFactor <= 0 || Float.isNaN(loadFactor))\n         throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor);\n     this.loadFactor = loadFactor;\n     // 初始容量暂时存放到 threshold ，在resize中再赋值给 newCap 进行table初始化\n     this.threshold = tableSizeFor(initialCapacity);\n }\n```\n\n以上4个构造方法中，都初始化了`loadFactor`。\n\n由于HashMap中无capacity字段，所以即使指定了初始容量大小`initialCapacity`，其也只是通过`tableSizeFor`将其扩容到与其**最接近的2的幂**的大小，然后赋值给`threshold`。后续通过`resize()`方法将`threshold`赋值给`newCap`进行table的初始化。\n\n**tableSizeFor()**\n\n````java\n    /**\n     * Returns a power of two size for the given target capacity.\n     */\n    static final int tableSizeFor(int cap) {\n        int n = cap - 1;\n        n |= n >>> 1;\n        n |= n >>> 2;\n        n |= n >>> 4;\n        n |= n >>> 8;\n        n |= n >>> 16;\n        return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;\n    }\n````\n\n\n\n\n\n##### putMapEntities方法\n\n即包含另一个“Map”的构造函数中会调用。\n\n````java\nfinal void putMapEntries(Map<? extends K, ? extends V> m, boolean evict) {\n    int s = m.size();\n    if (s > 0) {\n        // 判断table是否已经初始化\n        if (table == null) { // pre-size\n            /*\n             * 未初始化，s为m的实际元素个数，ft=s/loadFactor => s=ft*loadFactor, 跟我们前面提到的\n             * 阈值=容量*负载因子 是不是很像，是的，ft指的是要添加s个元素所需的最小的容量\n             */\n            float ft = ((float)s / loadFactor) + 1.0F;\n            int t = ((ft < (float)MAXIMUM_CAPACITY) ?\n                    (int)ft : MAXIMUM_CAPACITY);\n            /*\n             * 根据构造函数可知，table未初始化，threshold实际上是存放的初始化容量\n             * 如果添加s个元素所需的最小容量大于初始化容量，则将最小容量扩容为最接近的2的幂次方大小作为初始化。\n             * 注意这里不是初始化阈值\n             */\n            if (t > threshold)\n                threshold = tableSizeFor(t);\n        }\n        // 已初始化，并且m元素个数大于阈值，进行扩容处理\n        else if (s > threshold)\n            resize();\n        // 将m中的所有元素添加至HashMap中，如果table未初始化，putVal中会调用resize初始化或扩容\n        for (Map.Entry<? extends K, ? extends V> e : m.entrySet()) {\n            K key = e.getKey();\n            V value = e.getValue();\n            putVal(hash(key), key, value, false, evict);\n        }\n    }\n}\n\n````\n\n\n\n##### put方法\n\n添加元素时调用，会调用`putVal()`方法\n\n添加元素的过程：\n\n1. 定位到的数组位置无元素，直接插入\n2. 有元素时，比较其与插入的`key`\n3. `key`相同时直接覆盖；`key`不同时判断 p 是否是一个树节点，如果是就调用`e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value)`将元素添加进入。如果不是就遍历链表插入(插入的是链表尾部)。\n\n![image-20231211195415696](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202312111954803.png)\n\n````java\npublic V put(K key, V value) {\n    return putVal(hash(key), key, value, false, true);\n}\n\nfinal V putVal(int hash, K key, V value, boolean onlyIfAbsent,\n                   boolean evict) {\n    Node<K,V>[] tab; Node<K,V> p; int n, i;\n    // table未初始化或者长度为0，进行扩容\n    if ((tab = table) == null || (n = tab.length) == 0)\n        n = (tab = resize()).length;\n    // (n - 1) & hash 确定元素存放在哪个桶中，桶为空，新生成结点放入桶中(此时，这个结点是放在数组中)\n    if ((p = tab[i = (n - 1) & hash]) == null)\n        tab[i] = newNode(hash, key, value, null);\n    // 桶中已经存在元素（处理hash冲突）\n    else {\n        Node<K,V> e; K k;\n        //快速判断第一个节点table[i]的key是否与插入的key一样，若相同就直接使用插入的值p替换掉旧的值e。\n        if (p.hash == hash &&\n            ((k = p.key) == key || (key != null && key.equals(k))))\n                e = p;\n        // 判断插入的是否是红黑树节点\n        else if (p instanceof TreeNode)\n            // 放入树中\n            e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);\n        // 不是红黑树节点则说明为链表结点\n        else {\n            // 在链表最末插入结点\n            for (int binCount = 0; ; ++binCount) {\n                // 到达链表的尾部\n                if ((e = p.next) == null) {\n                    // 在尾部插入新结点\n                    p.next = newNode(hash, key, value, null);\n                    // 结点数量达到阈值(默认为 8 )，执行 treeifyBin 方法\n                    // 这个方法会根据 HashMap 数组来决定是否转换为红黑树。\n                    // 只有当数组长度大于或者等于 64 的情况下，才会执行转换红黑树操作，以减少搜索时间。否则，就是只是对数组扩容。\n                    if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st\n                        treeifyBin(tab, hash);\n                    // 跳出循环\n                    break;\n                }\n                // 判断链表中结点的key值与插入的元素的key值是否相等\n                if (e.hash == hash &&\n                    ((k = e.key) == key || (key != null && key.equals(k))))\n                    // 相等，跳出循环\n                    break;\n                // 用于遍历桶中的链表，与前面的e = p.next组合，可以遍历链表\n                p = e;\n            }\n        }\n        // 表示在桶中找到key值、hash值与插入元素相等的结点\n        if (e != null) {\n            // 记录e的value\n            V oldValue = e.value;\n            // onlyIfAbsent为false或者旧值为null\n            if (!onlyIfAbsent || oldValue == null)\n                //用新值替换旧值\n                e.value = value;\n            // 访问后回调\n            afterNodeAccess(e);\n            // 返回旧值\n            return oldValue;\n        }\n    }\n    // 结构性修改\n    ++modCount;\n    // 实际大小大于阈值则扩容\n    if (++size > threshold)\n        resize();\n    // 插入后回调\n    afterNodeInsertion(evict);\n    return null;\n}\n````\n\n\n\n##### resize()扩容\n\n进行扩容，会伴随一次重新hash分配，并会遍历hash表中的所有元素，非常耗时。\n\n实际上是将table初始化和table扩容进行了整合，底层行为都是给table赋值一个新的数组。\n\n**每次扩容都是扩大为原始大小的2倍。**\n\n````java\nfinal Node<K,V>[] resize() {\n    Node<K,V>[] oldTab = table;\n    int oldCap = (oldTab == null) ? 0 : oldTab.length;\n    int oldThr = threshold;\n    int newCap, newThr = 0;\n    if (oldCap > 0) {\n        // 超过最大值就不再扩充了，就只好随你碰撞去吧\n        if (oldCap >= MAXIMUM_CAPACITY) {\n            threshold = Integer.MAX_VALUE;\n            return oldTab;\n        }\n        // 没超过最大值，就扩充为原来的2倍\n        else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY && oldCap >= DEFAULT_INITIAL_CAPACITY)\n            newThr = oldThr << 1; // double threshold\n    }\n    else if (oldThr > 0) // initial capacity was placed in threshold\n        // 创建对象时初始化容量大小放在threshold中，此时只需要将其作为新的数组容量\n        newCap = oldThr;\n    else {\n        // signifies using defaults 无参构造函数创建的对象在这里计算容量和阈值\n        newCap = DEFAULT_INITIAL_CAPACITY;\n        newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);\n    }\n    if (newThr == 0) {\n        // 创建时指定了初始化容量或者负载因子，在这里进行阈值初始化，\n    \t// 或者扩容前的旧容量小于16，在这里计算新的resize上限\n        float ft = (float)newCap * loadFactor;\n        newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE);\n    }\n    threshold = newThr;\n    @SuppressWarnings({\"rawtypes\",\"unchecked\"})\n        Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];\n    table = newTab;\n    if (oldTab != null) {\n        // 把每个bucket都移动到新的buckets中\n        for (int j = 0; j < oldCap; ++j) {\n            Node<K,V> e;\n            if ((e = oldTab[j]) != null) {\n                oldTab[j] = null;\n                if (e.next == null)\n                    // 只有一个节点，直接计算元素新的位置即可\n                    newTab[e.hash & (newCap - 1)] = e;\n                else if (e instanceof TreeNode)\n                    // 将红黑树拆分成2棵子树，如果子树节点数小于等于 UNTREEIFY_THRESHOLD（默认为 6），则将子树转换为链表。\n                    // 如果子树节点数大于 UNTREEIFY_THRESHOLD，则保持子树的树结构。\n                    ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);\n                else {\n                    Node<K,V> loHead = null, loTail = null;\n                    Node<K,V> hiHead = null, hiTail = null;\n                    Node<K,V> next;\n                    do {\n                        next = e.next;\n                        // 原索引\n                        if ((e.hash & oldCap) == 0) {\n                            if (loTail == null)\n                                loHead = e;\n                            else\n                                loTail.next = e;\n                            loTail = e;\n                        }\n                        // 原索引+oldCap\n                        else {\n                            if (hiTail == null)\n                                hiHead = e;\n                            else\n                                hiTail.next = e;\n                            hiTail = e;\n                        }\n                    } while ((e = next) != null);\n                    // 原索引放到bucket里\n                    if (loTail != null) {\n                        loTail.next = null;\n                        newTab[j] = loHead;\n                    }\n                    // 原索引+oldCap放到bucket里\n                    if (hiTail != null) {\n                        hiTail.next = null;\n                        newTab[j + oldCap] = hiHead;\n                    }\n                }\n            }\n        }\n    }\n    return newTab;\n}\n````\n\n\n\n#### 为什么HashMap长度为2的幂\n\n为存取高效、减少碰撞，需将数据尽量分配均匀。\n\nHash 值的范围值-2147483648 到 2147483647，前后加起来大概 40 亿的映射空间，只要哈希函数映射得比较均匀松散，一般应用是很难出现碰撞的。但问题是一个 40 亿长度的数组，内存是放不下的。所以这个散列值是不能直接拿来用的。\n\n用之前还要先做对数组的长度取模运算，得到的余数才能用来要存放的位置也就是对应的数组下标。\n\n我们首先可能会想到采用`%`取余的操作来实现。但是，重点来了：**“ 取余(%)操作中如果除数是 2 的幂次则等价于与其除数减一的与(&)操作（也就是说 hash%length==hash&(length-1)的前提是 length 是 2 的 n 次方；）。”** 并且**采用二进制位操作 &，相对于%能够提高运算效率**，这就解释了 HashMap 的长度为什么是 2 的幂次方。\n\n#### 为什么不直接使用hashCode，而要增加使用扰动函数\n\n扰动函数：即为HashMap的`hash()`方法，可以减少碰撞\n\n为什么可以减少碰撞？数组位置计算：$(n-1) \\& hash$\n\n直接使用hashCode时，由于一般`n`比较小，所以`hash`一般只有`低位`参与计算，`高位无效`。这样就导致hash的高位未发挥作用。\n\nhashCode产生的hash是`int`类型，`32`位，所以将其`前16位`与其`后16位`数据进行`异或`运算，变相地让高位参与到计算中，增加了随机性，从而可以减少哈希碰撞。\n\n`hash()`\n\nJDK1.8：\n\n````java\n    static final int hash(Object key) {\n      int h;\n      // key.hashCode()：返回散列值也就是hashcode\n      // ^：按位异或\n      // >>>:无符号右移，忽略符号位，空位都以0补齐\n      //hashCode为一个int大小，总共32位，以下即为将hashCode的前16位与后16位按位异或，增大随机性\n      return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);\n  }\n````\n\nJDK1.7：性能稍差一点，扰动了四次\n\n````JAVA\nstatic int hash(int h) {\n    // This function ensures that hashCodes that differ only by\n    // constant multiples at each bit position have a bounded\n    // number of collisions (approximately 8 at default load factor).\n\n    h ^= (h >>> 20) ^ (h >>> 12);\n    return h ^ (h >>> 7) ^ (h >>> 4);\n}\n````\n\n\n\n\n\n#### HashMap vs. HashTable\n\n|                      | HashMap                              | HashTable                                         |\n| -------------------- | ------------------------------------ | ------------------------------------------------- |\n| 是否线程安全         | 否                                   | 是（内部方法基本都经过sychronized修饰，同一把锁） |\n| 效率                 | 高一点                               | （基本已被淘汰，不要使用）                        |\n| null key, null value | 至多一个null key<br />可以null value | 不允许                                            |\n| 默认初始容量         | 16                                   | 11                                                |\n| 指定初始容量         | 扩充为2的幂                          | 使用指定的                                        |\n| 扩容                 | 2倍                                  | 2n+1                                              |\n| 底层数据结构         | JDK1.8后解决哈希冲突的变化           |                                                   |\n\n\n\n#### HashMap多线程操作导致死循环问题\n\nJDK1.7及之前版本的HashMap在多线程环境下扩容可能存在死循环问题。\n\n因为当一个桶位中有多个元素需要进行扩容时，多个线程同时对链表进行操作，头插法可能导致链表中的节点指向错误的位置从而形成一个环形链表。\n\n[为什么头插法会导致环形链表的形成。](https://juejin.cn/post/7096754757716410382)\n\n为解决以上问题，JDK1.8的HashMap采用尾插法而不是头插法来避免链表倒置，使得插入节点永远放在链表末尾，避免了环形链表的形成。\n\n但是多线程环境下使用HashMap依然存在数据覆盖问题。\n\n并发环境下推荐使用`ConcurrentHashMap`。\n\n\n\n#### 为什么HashMap线程不安全\n\nJDK1.7 及之前版本，在多线程环境下，`HashMap` 扩容时会造成死循环和数据丢失的问题。\n\n数据丢失这个在 JDK1.7 和 JDK 1.8 中都存在。\n\n**并发put导致数据丢失**\n\n`putVal()`方法中的这一段：\n\n````java\n// (n - 1) & hash 确定元素存放在哪个桶中，桶为空，新生成结点放入桶中(此时，这个结点是放在数组中)\n#1    if ((p = tab[i = (n - 1) & hash]) == null)\n#2        tab[i] = newNode(hash, key, value, null);\n````\n\n假设两个线程`T1`, `T2`同时执行`put()`，其`(n - 1) & hash`字段相同，且此时该位置无元素。\n\n首先，两个进程都执行了`#1`处语句\n\n然后，假设`T1`先执行`#2`处语句，即`tab[i] = newNode(hash, key, value, null)`;\n\n此时键值对`(key1-value1)`应该已经被存储\n\n紧接着`T2`执行`#2`处语句，即`tab[i] = newNode(hash, key, value, null)`;\n\n此时在相同位置在`(key2-value2)`被存储，即`(key1-value1)`被覆盖丢失。\n\n\n\n**put与get并发可能导致get为null**\n\n`put()`时若发生扩容操作，刚好在创建新hash表（此时为空表）后即`get()`，则会get到`null`;\n\n\n\n### ConcurrentHashMap\n\n底层数据结构：\n\n* JDK1.7：分段数组+链表\n* JDK1.8：数组+链表/红黑树\n\n\n\n####实现线程安全的方式\n\nJDK1.7：对整个桶数组分割分段（`Segment`，分段锁），每把锁只锁容器其中一部分数据，多线程访问容器里不同段数据时，不会存在锁竞争，提高并发访问率\n\n![image-20240107114935643](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202401071149113.png)\n\n\n\nJDK1.8：直接用Node数组+链表+红黑树数据结构，并发控制使用`sychronized`和`CAS`操作。整个看起来像是优化过且线程安全的HashMap。\n\n![image-20240107115157281](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202401071151621.png)\n\n\n\n### TreeMap\n\n`TreeMap` 和`HashMap` 都继承自`AbstractMap` ，但是需要注意的是`TreeMap`它还实现了`NavigableMap`接口和`SortedMap` 接口。\n\n* 实现 `NavigableMap` 接口让 `TreeMap` 有了**对集合内元素的搜索的能力**。\n\n* 实现`SortedMap`接口让 `TreeMap` 有了对集合中的**元素根据键排序的能力**。默认是按 key 的升序排序，不过也可以指定排序的比较器。\n\n\n\n\n\n\n\n# 泛型\n\n## 泛型标识符\n\n- **E** - Element (在集合中使用，因为集合中存放的是元素)\n- **T** - Type（Java 类）\n- **K** - Key（键）\n- **V** - Value（值）\n- **N** - Number（数值类型）\n- **？** - 表示不确定的 java 类型\n\n`<? extends T>`：是指 “上界通配符（Upper Bounds Wildcards）”\n\n `<? super T>`：是指 “下界通配符（Lower Bounds Wildcards）”","tags":["Java","集合","HashMap","ArrayList","Set"],"categories":["Learning","Java"]},{"title":"MySQL索引","url":"/post/43a71ae4.html","content":"\n# 存储引擎\n\n常见存储引擎有3种：MyISAM, MEMORY, InnoDB\n\n<!-- more -->\n\n|                      | MyISAM                                                       | InnoDB                                                       | MEMORY                                                       |\n| -------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| 存储结构             | 每张表被存放在三个文件：<br />1. frm - 定义数据 <br />2. MYD (MYData)- 数据文件 <br />3.  MYI (MYIndex)- 索引文件 | 所有的表都保存在同一个数据文件中（也可能是多个文件，或者是独立的表空间文件），InnoDB 表的大小只受限于操作系统文件的大小，一般为 2GB | 将数据存在内存，为了提高数据的访问速度，每一个表实际上和一个磁盘文件关联。文件是frm。 |\n| 存储限制             | 256TB                                                        | 64TB                                                         | RAM                                                          |\n| 支持事务             | No                                                           | Yes                                                          | No                                                           |\n| 事务安全             | 不支持 每次查询具有原子性                                    | 支持。是具有事务 (commit)、回滚 (rollback) 和崩溃修复能力 (crash recovery capabilities) 的事务安全 (transaction-safe (ACID compliant)) 型表 |                                                              |\n| 支持全文索引         | Yes                                                          | No（5.6.4 以上支持英文全文索引） 可以通过使用 Sphinx 从 InnoDB 中获得全文索引，会慢一点 | No                                                           |\n| 支持B树索引          | Yes                                                          | Yes                                                          | Yes                                                          |\n| 支持哈希索引         | No                                                           | No                                                           | Yes                                                          |\n| 支持集群索引         | No                                                           | Yes                                                          | No                                                           |\n| 支持数据压缩         | Yes                                                          | No                                                           | No                                                           |\n| 支持外键             | No                                                           | Yes                                                          | No                                                           |\n| SELECT               | MyISAM更优                                                   |                                                              |                                                              |\n| INSERT               |                                                              | InnoDB更优                                                   |                                                              |\n| UPDATE               |                                                              | InnoDB更优                                                   |                                                              |\n| DELETE               |                                                              | InnoDB 更优 它不会重新建立表，而是一行一行的删除             |                                                              |\n| COUNT  without WHERE | MyISAM 更优。因为 MyISAM 保存了表的具体行数                  | InnoDB 没有保存表的具体行数，需要逐行扫描统计，就很慢了      |                                                              |\n| COUNT with WHERE     | 一样                                                         | 一样，无WHERE的情况InnoDB也会锁表                            |                                                              |\n| 锁                   | 只支持表锁                                                   | 支持表锁、行锁。行锁大幅度提高了多用户并发操作的性能。但是 **InnoDB 的行锁，只是在 WHERE 的主键是有效的，非主键的 WHERE 都会锁全表的。** | 表锁                                                         |\n|                      |                                                              |                                                              |                                                              |\n\n\n\n# 索引\n\n## 索引判断\n\n判断一条SQL是否使用索引，需通过执行计划进行判断：\n\n实现执行计划：在SQL前加上关键字`explain`，如：\n\n````SQL\nexplain select * from student where name = 'Mark'\n````\n\n则SQL执行结束后，会输出多个字段，其中某些关键字段为：\n\n| id   | select_type | table   | partitions | type | possible_keys | key    | key_len | ref    | rows | filtered | Extra  |\n| ---- | ----------- | ------- | ---------- | ---- | ------------- | ------ | ------- | ------ | ---- | -------- | ------ |\n| 1    | SIMPLE      | student | (Null)     | ALL  | (Null)        | (Null) | (Null)  | (Null) | 12   | 100.00   | (Null) |\n\n其中：\n\n* `type`：即为查询类型，即在表中找到所需行的方式。有以下几种类型（从上到下，性能越来越好）：\n\n  * ALL：全表扫描，即遍历全表以找到匹配的行。即直接遍历整个聚簇索引。\n\n  * index：全索引扫描，通过遍历所有索引来查找匹配的行.\n\n    > 直接在某个索引树上做条件判断，不需要回表。\n\n  * range：索引范围扫描，常见于`<`, `<=`, `>`,`>=` `between`等操作符.\n\n  * ref：普通的二级索引等值查询。\n\n    > 可能会查到多个匹配值，性能比const差一点。\n    >\n    > 由于null不能用const，所以不管是唯一索引还是二级索引值为null，都最多用到ref.\n\n  * eq_ref：多表连接查询时，被驱动表通过主键或唯一索引键进行等值查询\n\n  * const：使用主键或唯一索引等值查询来定位一条数据。因为索引的B+树都是矮胖的，定位一条唯一索引的记录，速度非常快，所以将该种查询定义为常数级，即为const.\n\n    > 唯一索引中允许多个null存在，所以对其进行null值查询，无法使用const\n\n  * system：是 const 类型的特例, 当查询的表只有一条数据的情况下使用 system.\n\n  * NULL：不用访问表或索引就直接能得到结果\n\n* `key`：执行本条SQL时，是否用到索引。\n\n* `Extra`：额外的可选信息。可以通过其判断当前SQL的执行效率。主要有：\n\n  * Using index：使用索引覆盖\n  * Using index condition：使用索引下推\n  * Using filesort：使用临时空间排序。\n\n\n\n索引种类\n\n目前MySQL提供了以下四种索引：\n\n1. B-Tree索引：最常见，大部分存储引擎都支持\n2. Hash索引：只有MEMORY引擎支持，使用场景简单\n3. R-Tree索引：又称空间索引，是MyISAM引擎的一个特殊索引类型，主要用于地理空间数据类型，通常使用较少。\n4. Full-text索引：又称全文索引，也是MyISAM引擎的一个特殊索引类型，主要用于全文检索，innoDB从mysql5.6开始支持全文索引。\n\n\n\n## 索引结构\n\n### 问题\n\n**Q1：索引过大无法加载到内存中怎么解决？**\n\nA1：分块读取。\n\n同时需要提高IO效率，在软件层面可以使用辅助手段提高。\n\n> 操作系统相关：\n>\n> 1. 局部性原理：\n>\n>    * 时间局部性：之前访问过的数据很可能再次被访问，至少比陌生数据概率大很多\n>    * 空间局部性：数据与程序都有聚集成群的倾向\n>\n> 2. 磁盘预读：\n>\n>    内存与磁盘交互的最小逻辑单位：页\n>\n>    其大小一般为4KB或8KB，由操作系统决定。在内存进行数据读取时，一般会读取页的整数倍。\n>\n> InnoDB引擎在进行数据加载时读取的就是**16KB**的数据，即为分块读取的集中体现。\n\n**Q2：why B+树？**\n\n索引存储的数据格式：key-value形式。\n\n能够存储key-value格式的数据结构有很多，如：hashmap，树，为什么最终选用B+树做索引？\n\n**首先，why not hashmap？**\n\n1. 利用hash存储需要将所有数据添加到内存，耗费内存空间\n2. 不合适的hash算法会导致hash冲突，以及会导致数据散列不均匀，空间浪费\n3. 哈希表存的key-value是无序的，进行范围查找时，需要遍历其中存储的所有数据，代价大。\n\nInnoDB自适应Hash。\n\n> **什么是自适应Hash？**\n>\n> InnoDB引擎会监控对表上二级索引的查找，如果发现某二级索引被频繁访问，二级索引成为热点数据，建立hash索引可以带来速度上的提升，则：\n>\n> 1. 自适应hash索引功能被打开\n> 2. 经常访问的二级索引数据会被自动生成到hash索引中去（最近连续被访问三次的数据）。\n>\n> 自适应hash索引通过缓冲池的b+树来构造，所以建立速度很快。\n>\n> **特点**\n>\n> 1. 无序，没有树高\n> 2. 降低对二级索引树的频繁资源访问\n> 3. 自适应\n>\n> **缺点**\n>\n> 1. 会占用innodb buffer pool\n> 2. 只适合搜索等值的查询，范围查找无法使用\n> 3. **MYSQL自动管理，无法人为干预**\n\n\n\n**其次，why not 二叉树、平衡二叉搜索树、AVL树、红黑树？**\n\n以上四种数据结构的共同点为：都为二叉树。即其每个分支上最多两个节点。\n\n当向其中插入大量数据时，无论其是否有序是否平衡，其树高度都会很大，导致在查找时，依然会存在多次比较操作，每次比较都相当于一次磁盘IO操作，会增加IO次数，影响效率\n\n> 为什么每次比较都相当于一次磁盘IO?\n>\n> 因为每个节点占用一个磁盘块，在比较时会将其中数据读取到内存中。\n\n则为了解决以上问题，可以从两个维度思考：\n\n1. 增加单个节点的范围：即单个节点的存值个数增加\n2. 增加节点的孩子个数\n\n因此，B树与B+树应运而生。\n\n\n\n### B树\n\n其为一棵平衡搜索多叉树。多叉，即为其孩子节点个数，也叫阶数，当我们描述一棵B或B+树时，需要指定其阶数，一般用`m`表示。\n\n定义：\n\n* 每个节点都有key-value\n  * 根节点至少有`1`对\n  * 非根节点至少有$\\lceil m/2 \\rceil$对\n  * 每个节点最多有`m-1`对\n* 所有叶子节点位于同一层\n* 除叶子节点外，所有节点的孩子数量为其当前的key-value对数 + 1\n* 每个节点中的key都按照排序规则从小到大排列，该节点左子树中所有key都小于它，右子树都大于它【开区间】\n\n\n\n查询过程为：如需查询key = 28的数据\n\n1. 由根节点找到磁盘块1，读入到内存中\n2. 比较得出28在区间16 ~ 34，找到磁盘块1中的指针p2\n3. 由p2找到磁盘块3，读到内存中\n4. 比较得出28在区间25 ~ 31，找到其中的指针p2\n5. 由p2找到磁盘块8，读到内存中\n6. 比较得出key=28的key-value，结束\n\n优点：降低了树高，虽然每次读进内存中的数据多，但是读取的次数少\n\n缺点：每个节点都有key-value，磁盘块/页的存储空间是有限的，所以当value很大时，能存储的key的数量减少。\n\n如何解决以上问题：\n\n在非叶子节点的磁盘页中不存value，只存储key，具体的key-value全部存储到叶子节点中。即B+树的方案。\n\n\n\n### B+树\n\n在B树的基础上进行优化，不同点为：\n\n* 非叶子节点只存储Key，叶子节点存储key-value\n* 每个叶子节点都有相邻叶子节点的指针\n* 子节点为左闭右开\n* 除叶子节点外，所有节点孩子数量等于当前的key-value数量\n\n\n\n查询数据：\n\n存在两种搜索方式：\n\n1. B树的搜索方式：$O(logN)$\n2. 链表搜索：叶子节点构成链表形成搜索，从最左下的叶子节点开始顺序搜索。\n\n优点：\n\n1. 非叶子节点只存储key，所以相比B树，能存储更多的Key，因此能更大地降低树高与将范围分成更多的区间，数据检索更快。\n2. 叶子节点都有相邻节点的指针，符合磁盘预读的特性，范围查询性能更快\n3. 一般三到四层的B+树足以支撑千万级别的数据存储，更大则需分表\n\n\n\nB+树所能存储的数据量计算：\n\n* 非叶子节点指针数：\n\n  InnoDB一个页的大小为16K，假设索引key的bigint占8个字节，指针占字节数为6，8 + 6 = 14，则一个page所能存放的key和指针个数为：16k / 14 ，约等于1170\n\n* 叶子节点记录数：\n\n  常规互联网单条行记录大小约为1k，则一个page能存储16k / 1k = 16条\n\n  * 如果为2层，则能存储记录数为：1170 * 16 = 18720\n  * 如果为3层，则能存储：1170 * 1170 * 16 约为2190w\n\n\n\n## 索引设计\n\n由上文分析，B+树非叶子节点的空间占用时，指针占用的为固定空间大小6个字节，所以影响其内存占用的因素为key\n\n* key为int：都占用4个字节\n\n* key为char：根据指定长度占用（英文字符一个长度一个字节，中文：utf8 - 3个, gbk - 2个）\n\n  > char(n) / varchar(n)：n表示字符数\n  >\n  > **char(n) vs. varchar(n)**\n  >\n  > * char(n)：\n  >   * 不管实际value的长度，都会占用n个字符的空间。【不够长则填充空格，固定长度】\n  >   * 存储时会自动截断尾部空格\n  >   * 上限255字节\n  >   * 不指定n时默认为1\n  > * varchar(n)：\n  >   * 占用value的实际空间 + 1，且该值 <= n。【可变长度】\n  >   * 不会截断尾部空格\n  >   * 上限65535字节【2^16】\n  >   * 不指定n时报错\n  >\n  > 空间占用超过n后，字符串会被截断\n  >\n  > **varchar vs. text**\n  >\n  > * text：用于保存文本类型的字符串，有四种类型：\n  >\n  > | 文本字符串类型 | 特点               | 长度 | 长度范围                         | 占用的存储空间 |\n  > | :------------- | :----------------- | :--- | :------------------------------- | :------------- |\n  > | TINYTEXT       | 小文本、可变长度   | L    | 0 <= L <= 255                    | L + 2 个字节   |\n  > | TEXT           | 文本、可变长度     | L    | 0 <= L <= 65535                  | L + 2 个字节   |\n  > | MEDIUMTEXT     | 中等文本、可变长度 | L    | 0 <= L <= 16777215               | L + 3 个字节   |\n  > | LONGTEXT       | 大文本、可变长度   | L    | 0 <= L<= 4294967295（相当于4GB） | L + 4 个字节   |\n  >\n  > 由于实际存储的长度不确定，MySQL 不允许 TEXT 类型的字段做主键\n  >\n  > **varchar转换为text**\n  >\n  > 1. 大于varchar（255）变为 tinytext\n  > 2. 大于varchar（500）变为 text\n  > 3. 大于varchar（20000）变为 mediumtext\n  >\n  > **为什么经常使用varchar(255)？**\n  >\n  > MYSQL5.6及以前，InnoDB支持的前缀索引最大为767个字节，采用utf8编码时， $\\lfloor 767 / 3 \\rfloor = 255$\n  >\n  > 255刚好为能建立前缀索引的最大值，不是最优，但是能减少出错\n\n目标：让key占用尽可能少的空间\n\n\n\n### 前缀索引\n\n**索引的选择性Index Selectivity** =  基数 / 数据表的总记录数【即为唯一索引值占比】\n\n> 基数为不重复索引值的数量，即唯一索引值数量\n>\n> MYSQL中使用HyperLogLog做基数统计，这是一个预估值。\n\n索引的选择性越高，查询效率越高，但是所占用的空间也就越多。\n\n\n\n**前缀索引定义**\n\n选择目标列的部分字符作为索引，从而节约空间，提高索引效率，但是会降低索引的选择性。【性能与空间之间寻找平衡】\n\n大部分存储引擎都支持前缀索引，目前只有字符类型或二进制类型的字段可以建立前缀索引，如：CHAR/VARCHAR、TEXT/BLOB、BINARY/VARBINARY\n\n* 字符类型基于前缀字符长度\n* 二进制类型基于字节大小\n* TEXT/ BLOB类型只支持前缀索引，不支持整个字段建索引。\n\n\n\n怎么选定合适的前缀？即如何确定合适的前缀长度？\n\n1. 统计指定字段出现重复值最多的前10个以及其重复出现次数\n\n   ````sql\n   select count(*) as count, city_name from city group by city_name order by count desc limity 10;\n   ````\n\n2. 统计该字段前3个字符出现重复值最多的前10个以及其重复出现次数\n\n   ````sql\n   select count(*) as count, left(city_name, 3) as prefix from city group by prefix order by count desc limit 10;\n   ````\n\n   > left(str , length)返回指定str从左边返回length长度的字符串\n\n3. 观察第1次与第2次统计结果差距大不大，如果大，则向右扩1个字符，在比较前3个和前4个字符的统计结果【如果仍然差距大，继续扩展重复】\n\n4. 知道结果差不多，则当时的前n个字符可作为前缀索引的最终长度，以此建立前缀索引\n\n优点：索引更小，节约索引空间，提高索引效率\n\n缺点：\n\n* 降低索引的选择性\n* 无法使用前缀索引做groupby和orderby，也无法做覆盖扫描\n\n\n\n### 聚簇 / 非聚簇索引\n\n并不是一种单独的具体索引类型，而是一种数据存储方式，具体依赖于其实现方式。\n\n\n\n#### 聚簇索引\n\n即Clustered Index。\n\n定义：按表的主键构造一棵B+树，叶子节点存放表的行记录数据，即将表的索引与数据存储在一起，找到索引的同时也找到了数据。\n\n按照以上定义，很显然**一张表只能有一个聚簇索引**。\n\nInnoDB中存储主键选用的就是聚簇索引的方式，如果未定义主键，则会选择非空唯一性(not null unique)字段，若不存在，则会隐式定义一个长整型，占6个字节的rowid作为主键来作为聚簇索引。\n\n\n\n#### 非聚簇索引\n\nNon-Clustered Index，也叫辅助索引或二级索引。\n\n非聚簇索引为在聚簇索引上创建的索引，即将数据与索引分开存储。\n\n常见非聚簇索引：\n\n* 复合索引\n* 前缀索引\n* 唯一性索引\n* MyISAM中的主键做因\n\n同样由B+树构成，但是树的叶子节点不再存储表的行记录数据，而是主键或指定索引字段\n\n* InnoDB中，存储的未主键\n* MyISAM中，主键索引存的是主键。非主键索引存的是指定索引字段。\n\n如：存在表user，id为主键，name字段有索引，除此之外还有一个字段为company\n\n则以下两个SQL：\n\n````sql\nselect * from user where id = 7;\nselect * from user where name = 'Jobs';\n````\n\nInnoDB中其查找流程为：\n\n![image-20240107133730133](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202401071337598.png)\n\n\n\nSQL1：聚簇索引查找，主键为聚簇索引，所以可以直接通过主键查找到对应叶子节点，访问行记录\n\nSQL2：非聚簇索引查找，InnoDB除主键外都是非聚簇索引，通过二阶索引的B+树查询到其对应的主键id，然后再在主键索引建立的B+树中查询到对应的叶子节点，访问行数据。\n\n> 以上操作也叫**回表**。即包含两次具体的查询动作，非聚簇索引查找性能低，在能使用聚簇索引解决的情况下，尽量规避使用回表查询。\n\n\n\nMyISAM中查询流程为：\n\n![image-20240107133821045](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202401071338530.png)\n\n\n\nSQL1与SQL2都为非聚簇索引查找。\n\nMyISAM中无无论是主键索引还是非主键索引，都为非聚簇索引。其B+树中叶子节点还需存储地址，指向表中的某一行，因此，每个B+树都相互独立，不需要相互访问【与InnoDB不同】\n\n\n\n聚簇索引优缺点：\n\n优点：\n\n1. 查找速度快于非聚簇索引，因为在InnoDB中无需二次查询，在MyISAM中无需寻址\n2. 聚簇索引行数据在叶子节点中，同一个数据页可能有多条行数据，访问同一数据页的不同行数据是，其已被加载到内存中，再次访问可以直接在内存中访问，减少了IO\n3. InnoDB中使用主键值做非聚簇索引的value而非地址，是为了保证B+树分裂时，出现行移动的情况下，主键索引的B+树的变化不会影响非主键索引。\n4. 适用于排序场合、选取一定范围数据的场景\n\n缺点：\n\n1. 一张表中只能有一个聚簇索引，可以有多个非聚簇索引\n\n2. 维护聚簇索引很昂贵，因为行移动会造成碎片\n\n3. 若使用UUID(通用唯一标识码)做主键，其本身特性会导致数据稀疏，则会出现使用聚簇索引查询速度慢于全字典扫描，因此建议用自增主键做聚簇索引。\n\n   > 为什么？\n   >\n   > 因为聚簇索引的数据的物理存放顺序与索引顺序是一致的，只要索引相邻，则对应数据也存放在相邻磁盘上。\n   >\n   > 如主键不是自增id，则不可能顺序插入，存储引擎会不断调整数据的物理地址，会不断分页。\n   >\n   > 若主键为自增id，则只需一页一页写入数据，索引结构也相对紧凑，磁盘碎片少，效率更高。\n\n如果涉及到大量数据的排序、全表扫描、count之类的操作的话，建议使用MyISAM引擎。因为所有占用空间小，这些操作是需要在内存中完成的。\n\n\n\n### 索引覆盖\n\ncovering inex\n\n当`explain`命令输出结果的`Extra`字段为：`Using index`时，则可触发索引覆盖 / 覆盖索引。\n\n定义：只要在一棵索引树上就能获取SQL所需的所有数据，无需回表。\n\n实现：将被查询的字段，建立到**联合索引**中\n\n如：存在表user，id为主键，name字段有普通索引，除此之外还有一个字段为company\n\n以下两条SQL：\n\n````sql\n# 1\nselect id, name from user where name = 'Gates';\n# 2\nselect id, name, company from user where name = 'Gates';\n````\n\nSQL1：name字段索引的B+树，访问name字段后可以获得对应的id，满足所需数据，无需回表，符合覆盖索引，效率高。\n\nSQL2：前面等同于SQL1，获取name和id后，无法在当前B+树获取company字段，需要二次查询聚簇索引获得company字段，回表，效率底。\n\n解决方案：将索引建立时：`index(name)`升级为联合索引`index(name, company)`，则再次执行SQL2，等同于SQL1执行过程。无需回表，符合索引覆盖，效率高。\n\n\n\n### 联合索引\n\n#### 最左匹配原则\n\n建立联合索引时需遵循最左匹配原则。\n\n如创建一个索引`index(a , b)`，则其B+树为以下：\n\n![image-20240107134103148](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202401071341236.png)\n\n`a`字段是有序的，而`b`字段是建立在`a`字段的基础上的，所以在固定`a`字段上来看是有序的，整体看是无序的。\n\n什么条件查询才能利用联合索引呢？\n\n由以上B+树，b字段只有在a字段固定时才有序，所以：\n\n1. where b = 2：无法使用联合索引，索引整体按照a字段排序，无法单独确定b\n2. where a = 2 and b = 2：可以使用\n3. where a > 2 and b = 2：a使用，b未使用。在a字段的固定范围中，b依然整体是无序状态\n\n由以上可以得出**最左匹配定义**：查询条件中，以联合索引最左边定义的字段为起点，且所有字段和顺序都与联合索引中一致，构成的查询条件能够利用联合索引，查询条件中出现**范围查询、模糊查询、排序则需具体分析**。\n\n**注**：查询条件没有按联合索引的顺序排列时：同级查询会被MYSQL中的查询优化器**自动优化查询顺序**，即尽量会满足按照联合索引顺序排列。**MySQL的查询优化器无法对于group by，order by进行优化**\n\n[索引是否失效：](https://dbaplus.cn/news-11-4972-1.html)\n\n**范围查询**：\n\n1. `>`, `<`：最左用到了联合索引，范围之后的不会使用\n2. `>=`, `<=`：最左使用了，范围之后的对于`=`的情况用到了\n3. `between x and y`：mysql中是闭区间，所以对于边界值等于的地方，范围也用到了联合索引。\n\n**模糊查询like**：\n\n当涉及字符型数据的模糊查询和范围查询时，除最左原则外，还需考虑其本身是否能通过B+树查询。\n\n如：\n\n````sql\n// SQL1\nselect * from user where name like 'Ga%';\n// SQL2\nselect * from user where name like '%tes';\n````\n\nSQL1符合最左，提提供了查询前缀，使用联合索引。\n\nSQL2符合最左，但是只提供了中缀，无法在B+树上进行节点搜索，所以无法使用联合索引。\n\n\n\n多条件情况：\n\n````sql\nselect * from user where company like 'Mic%' and name like 'Ga%';\n````\n\n首先优化器会自动优化为`name`在前，`company`在后。\n\n对于name字段进行查询，形成的区间为`['Ga~','Gb~')`，虽然在符合Ga为前缀的name的二级索引范围中，company是无序的，但是对于符合name = Ga的记录中，company的值是有序的，所以company字段也会用到联合索引。\n\n\n\n**Q：使用`like \"%x\"`，索引一定会失效吗？**\n\n**A**：不一定，取决于表中字段数量，如果表中所有字段都有索引，则走的为全扫描二级索引B+树。\n\n比如只有两个字段，id为聚簇索引，name为普通索引。\n\n````sql\nselect * from user where name like \"%tes\";\n````\n\n则直接全扫描二级索引B+树则可得到想要结果，无需回表，保证了索引覆盖\n\n\n\n## 常见索引失效\n\n1. 模糊查询非前缀\n\n2. 对索引使用函数。因为索引保存的是字段原始值，而不是经过函数计算后的值，所以使用函数计算后就无法再使用索引了。\n\n   > MySQL8.0开始增加了函数索引，即可以对函数计算后的值建立索引。\n   >\n   > 如：\n   >\n   > ````SQL\n   > alter table t_user add key idx_name_length ((length(name)));\n   > ````\n\n3. 对索引进行表达式计算，原因类似使用函数\n\n4. 对索引进行隐式类型转换\n\n   >如：phone字段定义的为varchar，但是查询时：\n   >\n   >````sql\n   >select * from user where phone = 12345678901;\n   >````\n   >\n   >则会走全表扫描。\n   >\n   >因为其等价于：\n   >\n   >````sql\n   >select * from user where CAST(phone AS signed int) = 12345678901;\n   >````\n   >\n   >则**相当于对索引字段使用了函数。**\n   >\n   >**但是**，id字段定义为int，查询：\n   >\n   >````sql\n   >select * from user where id = '1';\n   >````\n   >\n   >会正常使用索引。\n   >\n   >为什么？\n   >\n   >MySQL会自动将字符串转为数字。\n   >\n   >其等价于：\n   >\n   >````sql\n   >select * from user where id = CAST('1' AS signed int);\n   >````\n   >\n   >CAST 函数是用在了输入参数，因此是可以走索引扫描的。\n\n5. 联合索引非最左匹配【见最左匹配部分】\n\n6. `WHERE`子句中的`OR`\n\n   > 在 WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效。\n   >\n   > 因为 OR 的含义就是两个只要满足一个即可，因此只有一个条件列是索引列是没有意义的，只要有条件列不是索引列，就会进行全表扫描。\n   >\n   > 解决方案：增加索引列\n\n\n\n## 索引下推\n\nindex condition pushdown，ICP，全称为索引条件下推优化。MySQL5.6推出，默认开启，用于优化查询。\n\n使用索引下推的表示：explain 结果中的Extra值为Using index condition\n\n\n\n### 原理\n\nMySQL架构：\n\n* Client\n* Server\n* 存储引擎\n\n**未使用ICP时，MySQL如何查询？**\n\n1. 存储引擎读取索引记录\n2. 根据索引中的主键值，定位并读取完整的行记录\n3. 存储引擎把记录交给`Server`层去检测该记录是否满足`WHERE`条件\n\n**使用ICP后，查询过程为：**\n\n1. 存储引擎读取索引记录（不是完整的行记录）\n2. 判断`WHERE`条件部分是否能用索引中的列来做检查【即做一次筛选过滤】\n   * 条件不满足则处理下一条索引记录\n   * 条件满足，回表读取完整行记录\n3. 存储引擎把记录交给`Server`层，`Server`层检测该记录是否满足`WHERE`条件的其余部分\n\n\n\n### 使用条件\n\n* 只能用于`range`, `ref`, `eq_ref`, `ref_or_null`访问方法\n\n* 只能用于InnoDB和MyISAM存储引擎及其分区表\n\n* 对InnoDB而言，ICP只适用于二级索引\n\n  > 为什么？\n  >\n  > 因为ICP的目的是**减少回表次数**，而对聚簇索引而言，其完整的行记录已经在缓存区，ICP无意义。\n\n* 引用了子查询的条件不能下推\n\n* 引用了存储函数的条件不能下推，因为存储引擎无法调用存储函数。\n\n\n\n## count()性能问题\n\n### count()作用\n\ncount()作用：统计符合查询条件的记录中，函数指定的参数不为 NULL 的记录有多少个。\n\n* count(name)：统计表中name不为空的记录条数\n* count(1)：在当前表中，1永远不为空，所以统计的为当前表的记录总数\n* count(*)：当前表中记录总数\n\n\n\n### count(primary key)执行过程\n\n1. Server层维护名为count的变量\n2. Server层循环向InnoDB中读取一条记录，id不为NULL，则count += 1\n3. 所有记录读取完毕，退出循环，将count变量值发送给Client\n\nInnoDB遍历选择：\n\n* 无二级索引：遍历聚簇索引\n* 有二级索引：遍历二级索引【树更小】【优化器选择】\n\n\n\n### count(1)执行过程\n\nInnoDB遍历选择：\n\n* 无二级索引：遍历聚簇索引，但是**不会读取value**\n* 有二级索引：遍历二级索引【树更小】【优化器选择】\n\n\n\n### count(*)执行过程\n\n对于`select *`而言是读取所有记录，但是对于count不是\n\n`count(*)`相当于`count(0)`，所以，其执行过程与`count(1)`相同\n\n\n\n### count(字段)执行过程\n\n如`count(name)`，name不为索引\n\n会采用全表扫描的方式，所以效率很低。\n\n\n\n### 性能对比\n\ncount(1) = count(*) > count(primary key) > count(字段)\n\n\n\n### count(*)优化\n\n数据量过大时，count(*)也很耗时，如何优化？\n\n1. 近似值：当无需精确值统计时，可以使用近似值，如使用`show table status`或`explain`来估算\n\n2. 额外表保存字段：如果是想精确的获取表的记录总数，我们可以将这个计数值保存到单独的一张计数表中。\n\n   当我们在数据表插入一条记录的同时，将计数表中的计数字段 + 1。也就是说，在新增和删除操作时，都需要额外维护这个计数表。\n\n\n\n参考：\n\n[【MySQL】索引进阶(B+树，前缀索引，聚簇索引等)](https://juejin.cn/post/7028851379078692895)\n\n[MySQL一个全网都在说的错误结论](https://dbaplus.cn/news-11-4972-1.html)\n\n[一文读懂什么是MySQL索引下推（ICP）](https://www.jianshu.com/p/31ceadace535)\n\n","tags":["MySQL","存储引擎","索引"],"categories":["Learning","DataBase"]},{"title":"数位DP思路","url":"/post/da4a5ffe.html","content":"\n\n\n一般用于统计某个范围的数，而这个范围一般都很大，难以直接暴力枚举求解，所以一般将其每位数拆分，一位一位地看。\n\n<!-- more -->\n\n如：判断在`[0,x]`范围中，满足某条件的数的个数\n\n**先做规约：**\n\n* 0特殊判断，然后数位dp判断`[1,x]`\n* 不填前导0，即保证每个数的最高位为正数\n\n**填数过程，遵循以下：**\n\n* 从高位往低位枚举数位\n* 在第`i`位填上了数，则其后面的数位都需填上数，保证数据不重复\n* 保证填入的数组成的数据不大于x\n\n\n\n如：令`x = 324783729`，求`[1,x]`内有多少个数满足其数位上的数字之和为16\n\n1. 先看第一位：\n   * 不填\n   * 填：可以填1, 2, 3\n2. 再看第二位：\n   * 不填\n   * 填：\n     * 第一位没填数：可以填[1,9]任意一个数\n     * 第一位填数了：\n       * 第一位填的1或2：可以填[0,9]任意一个数\n       * 第一位填的3：可以填[0,2]任意一个数\n3. ...\n4. 如处理到第七位：\n   * 不填\n   * 填：\n     * 前面都没有填数：可以填[1,9]任意一个数\n     * 前面填了：\n       * 前面位数没满，即前面填的数没有六位：可以填[0,9]任意一位数\n       * 前面数位满了：\n         * 前面存在一位，其数字小于其对应的数字，即nums[i]：可以填[0,9]任意一位数\n         * 前面所有数字都与对应数字相同：可以填[0,7]任意一位\n\n**规律分析总结：**\n\n第`i`位填数：\n\n* 前面都没有填数：[1,9]\n* 前面没填满或填满了但存在一位所填的数小于x中对应位数的数值：[0,9]\n* 前面所有数字都与x中对应数字相同：[0, nums[i]]\n\n所以，可以引入变量`limit`来判断前面所填数字是否都与x中对应数字相同\n\n则在填入第一个数时，即情况1，前面都没有填数时，对`limit`进行初始化\n\n第二种情况下：limit = 0\n\n第三种情况下： limit = 1\n\n\n\n**limit转移：**\n\n填完第`i`个数字，`limit`怎么转移到第`i + 1`位：\n\n当前limit = 1且填入的数字为nums[i]，则下一位的limt = 1;\n\n否则下一位的limit = 0;\n\n\n\n**特殊情况处理：**\n\n即最高位，第0位的处理\n\n其填入的值的范围：[1, nums[0]]\n\n其limit = 填值 == nums[i] ? 1 : 0\n\n\n\n分析转移方程：使用`dp[i][limit][sum]`表示在前`i`位数字和为sum的数据个数\n\n* 前面都没有填数：[1,9]\n\n  ````java\n  //初始化\n  //填入数字为c,取值为1，9\n  dp[i][0][c] = 1;\n  ````\n\n* 前面没填满或填满了但存在一位所填的数小于x中对应位数的数值：[0,9]\n\n  ````java\n  dp[i][0][cur_sum + c] += dp[i - 1][0][cur_sum];\n  ````\n\n  \n\n* 前面所有数字都与x中对应数字相同：[0, nums[i]]\n\n  ````java\n  c != nums[i]\n  dp[i][0][cur_sum + c] += dp[i - 1][1][cur_sum];\n  else c == nums[i]\n  dp[i][1][cur_sum + c] += dp[i - 1][1][cur_sum];\n  ````\n\n* 最终答案为：\n\n  ````java\n  dp[n - 1][0][sum] + dp[n - 1][1][sum]\n  ````\n\n  ","tags":["算法","数位DP"],"categories":["Learning","Algorithm"]},{"title":"集成JWT实现token验证与注销","url":"/post/0.html","content":"JWT（Java Web Token）定义了一种简洁的，自包含的方法用于通信双方之间以 `JSON` 对象的形式安全的传递信息。因为数字签名的存在，这些信息是可信的，JWT 可以使用 `HMAC` 算法或者是 `RSA` 的公私秘钥对进行签名。\n\n<!-- more -->\n\n## 流程\n\n![图片.png](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202309022123414.png)\n\n1. 用户使用账号和面发出 post 请求；\n2. 服务器使用私钥创建一个 jwt；\n3. 服务器返回这个 jwt 给浏览器；\n4. 浏览器将该 jwt 串在请求头中向服务器发送请求；\n5. 服务器验证该 jwt；\n6. 返回响应的资源给浏览器。\n\n\n\n## JWT结构\n\n包含三个部分：\n\n1. Header 头部 (包含了令牌的元数据，并且包含签名和 / 或加密算法的类型)\n2. Payload 负载 (类似于飞机上承载的物品)\n3. Signature 签名 / 签证\n\n以上三段信息用`.`连接在一起，构成了JWT字符串\n\n\n\n### Header\n\n包含两部分信息：\n\n1. token类型\n2. 采用的加密算法\n\n````\n{ \n  \"alg\": \"HS256\",//加密算法，通常直接用HMAC SHA256\n   \"typ\": \"JWT\" //类型\n}\n````\n\n\n\n### Payload\n\n载荷就是存放有效信息的地方\n\n有效信息包含：\n\n1. 标准中注册的声明\n2. 公共的声明\n3. 私有的声明\n\n\n\n### 1. 标准中注册的声明\n\n建议但不强制使用\n\n* iss: jwt 签发者\n* sub: 面向的用户 (jwt 所面向的用户)\n* aud: 接收 jwt 的一方\n* exp: 过期时间戳 (jwt 的过期时间，这个过期时间必须要大于签发时间)\n* nbf: 定义在什么时间之前，该 jwt 都是不可用的.\n* iat: jwt 的签发时间\n* jti: jwt 的唯一身份标识，主要用来作为一次性 token, 从而回避重放攻击。\n\n\n\n#### 2. 公共的声明\n\n可以添加任何信息。一般添加用户的相关信息或其他业务需要的必要信息。\n\n不建议添加敏感信息，因为该部分在客户端可解密。\n\n\n\n#### 3. 私有的声明\n\n为提供者和消费者所共同定义的声明。\n\n不建议存放敏感信息，因为base64是对称解密的，即该部分信息可以归类为明文信息\n\n\n\n### Signature\n\n签证信息，包含以下三部分：\n\n1. header(base64后)\n2. payload(base64后)\n3. seceret\n\n需要 base64 加密后的 header 和 base64 加密后的 payload 使用`. `连接组成的字符串，然后通过 header 中声明的加密方式进行加盐 secret 组合加密，然后就构成了 jwt 的第三部分。\n密钥 secret 是保存在服务端的，服务端会根据这个密钥进行生成 token 和进行验证，所以需要保护好。\n\n\n\n## Springboot和jwt集成\n\n1. 引入jwt依赖\n\n   ````xml\n   <dependency>\n         <groupId>com.auth0</groupId>\n         <artifactId>java-jwt</artifactId>\n         <version>3.4.0</version>\n   </dependency>\n   ````\n\n2. ","tags":["studying","springboot","jwt","token"],"categories":["Coding","Mo1isting"]},{"title":"遇到的问题及思路","url":"/post/0.html","content":"\n\n\n\n一些开发过程中的问题rec.\n\n<!-- more -->\n\n\n\n1. maven直接引入jdbc失败，搜索后发现时maven3后oracle不支持直接引入了，手动下载jdbc引入，使用如下命令：\n\n   ````shell\n   mvn install:install-file -Dfile=D:\\Code\\oracle\\ojdbc11.jar -DgroupId=com.oracle -DartifactId=ojdbc11 -Dversion=11 -Dpackaging=jar -DgeneratePom=true\n   ````\n\n   但是报错误：\n\n   ````\n   [ERROR] Unknown lifecycle phase \".oracle\". You must specify a valid lifecycle phase or a goal in the format <plugin-pre\n   fix>:<goal> or <plugin-group-id>:<plugin-artifact-id>[:<plugin-version>]:<goal>. \n   ````\n\n   查询后发现为使用powershell的问题，应该是powershell对`.`的判定规则引起，切换到cmd后正常\n\n   参考：https://blog.csdn.net/without_mercy/article/details/81474648\n\n2. https://jasonkayzk.github.io/2020/01/25/%E5%85%B3%E4%BA%8EMybatis-plus%E8%B0%83%E7%94%A8baseMapper%E6%8A%A5%E9%94%99Invalid-bound-statement%E7%9A%84%E8%A7%A3%E5%86%B3/\n\n   以及记得关闭下划线驼峰转换：\n\n   ````\n   mybatis:\n     configuration:\n       map-underscore-to-camel-case: false #下划线转驼峰\n   ````\n\n3. A component required a bean of type 'com.mo1isting.backend.service.CoffeeService' that could not be found.\n\n   解决方案：CoffeeService忘记加@Service注解了\n\n4. hashmap在类中方法外定义后赋值，提示：\n\n   Cannot resolve symbol 'put'\n\n   解决方案：将其赋值放入static块中\n\n   原因：https://luyu05.github.io/2018/07/10/HashMap/\n\n   即hashmap存放数据采用Node[] table的形式，而Node结构是static的，其中的变量 hash为final , key为final，所以其要么在定义时赋值，要么在static块中赋值。\n\n5. git-ssh-error解决方案：\n\n   问题：\n\n   ````shell\n   $ git clone git@github.com:xxxxx/xxxx.git my-awesome-proj\n   Cloning into 'my-awesome-proj'...\n   ssh: connect to host github.com port 22: Connection timed out\n   fatal: Could not read from remote repository.\n   ````\n\n   解决方案：\n\n   ````shell\n   $ # This should also timeout\n   $ ssh -T git@github.com\n   ssh: connect to host github.com port 22: Connection timed out\n   \n   $ # but this might work\n   $ ssh -T -p 443 git@ssh.github.com\n   Hi xxxx! You've successfully authenticated, but GitHub does not provide shell access.\n   $ # Override SSH settings\n   $ vim ~/.ssh/config\n   ```\n   # Add section below to it\n   Host github.com\n     Hostname ssh.github.com\n     Port 443\n   ```\n   $ ssh -T git@github.com\n   Hi xxxxx! You've successfully authenticated, but GitHub does not\n   provide shell access.\n   \n   $ git clone git@github.com:xxxxxx/xxxxx.git my-awesome-proj\n   Cloning into 'my-awesome-proj'...\n   remote: Enumerating objects: 15, done.\n   remote: Counting objects: 100% (15/15), done.\n   remote: Compressing objects: 100% (14/14), done.\n   remote: Total 15 (delta 0), reused 15 (delta 0), pack-reused 0\n   Receiving objects: 100% (15/15), 22.90 KiB | 4.58 MiB/s, done.\n   ````\n\n   [参考](https://gist.github.com/Tamal/1cc77f88ef3e900aeae65f0e5e504794)\n\n","tags":["问题","Mo1isting"],"categories":["Coding","Mo1isting"]},{"title":"It should be in Theater - 其实是剧推荐","url":"/post/94b1f2b2.html","content":"\n\n\n随着年纪的增加，对不同音乐的喜好程度有了很大变化。\n\n就该在剧院！很主观的剧目推荐。\n\n大致有：\n\n* 音乐剧\n* 话剧\n* 舞剧\n\n <!-- more -->\n\n# 音乐剧\n\n## Hamilton\n\n![image-20230928164639070](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202309281646018.png)\n\n目前仍是我的最爱之一，很难想象为什么会有LMM这么天才的人。\n\n舞美、剧情、演唱都非常非常好看，在我这儿属于不看非常亏的剧。希望有天能看到现场。\n\n喜爱程度：⭐⭐⭐⭐⭐\n\n目前可以看[Disney的官摄版本](https://tv.apple.com/movie/hamilton/umc.cmc.54rv4esv3qomlthreamvbd34v?at=11l4BH&itscg=30200&itsct=tv_box_link)\n\n\n\n## Rent\n\n![RENT - O MUSICAL](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202309281632766.jpeg)\n\n再放一张很喜欢的：\n\n![rent](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202309281636284.png)\n\n其实某种意义上这算是我的第一步音乐剧。诚挚、动人，在混乱的世界怎么才能pay自己的rent，最喜欢的是那句\n\n**Everything is Rent**\n\n很触动内心。而且这部剧的歌，都好好听，每一首都是精品。\n\n喜爱程度：⭐⭐⭐⭐⭐\n\n推荐查看[2008Broadway Film](https://www.imdb.com/title/tt1273675/)版\n\n\n\n## SIX\n\n![SIX | Broadway in Spokane](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202309281644058.jpeg)\n\n该怎么形容？真的太太太太好看了，不好描述所以推荐每个人都去看一遍。\n\n喜爱程度：⭐⭐⭐⭐⭐\n\n目前无官摄，最近在韩巡，希望有一天能看到现场！\n\n\n\n## Les Misérables\n\n![Les Misérables – Hennepin Theatre Trust](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202309281649714.jpeg)\n\n谁能不看？\n\n非常非常喜欢10th的音乐会，只能说看了的都不会不喜欢。\n\n喜爱程度：⭐⭐⭐⭐⭐\n\n23年法语版音乐会会到国内巡，英语的没听说。\n\n推荐看[10th的音乐会官摄](https://www.imdb.com/title/tt11918512/)。25th的也还行。\n\n\n\n## SpringAwakening\n\n![image-20230928165811680](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202309281658375.png)\n\n如果你也喜欢死亡诗社，那你肯定会喜欢这部剧。\n\n值得所有人看。\n\n喜爱程度：⭐⭐⭐⭐⭐\n\n目前有很多版本，都可以看。\n\n\n\n## Dear Evan Hansen\n\n![Dear Evan Hansen – Official Website of the Morris Performing Arts Center](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202309281640618.jpeg)\n\n其实这个故事并不算很触动我，但是ben的演绎我觉得太适合了，第一次见他是在Pitch Perfect1，当时我觉得他就很适合这类角色，看了evan国货发现我曾经的觉得太对了，很迷茫很恐怯，演得太好了，歌也非常非常好听！\n\n喜爱程度：⭐⭐⭐⭐\n\n目前无官摄。\n\n\n\n## Anastasia\n\n![Anastasia | The Musical - Video Dailymotion](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202309281654838.jpeg)\n\n感觉是一部很冷门的剧，但是舞美非常妙非常好看，切换也很好看。\n\n有官摄可看。\n\n喜爱程度：⭐⭐⭐⭐\n\n\n\n## Mozart!\n\n![Mozart! Das Musical - Vorstellungen & Tickets](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202309281700457.jpeg)\n\n我的人生挚爱剧之一。\n\n非常非常非常喜欢。\n\n希望有一天能巡。\n\n喜爱程度：⭐⭐⭐⭐⭐\n\n推荐看2015官摄版，同时非常推荐Thomas Hohler2019上海巡演版\n\n\n\n## Elisabeth\n\n![Elisabeth\" in Wien (2004) | Seite 2 von 5 | Mucke und mehr](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202309281707893.jpeg)\n\n也是人生剧之一，看的maya和麻袋版，serkan太帅了，唱得太好听了。\n\n表哥版据说也很不错。\n\n喜爱程度：⭐⭐⭐⭐⭐\n\n\n\n\n\n## Notre-Dame de Paris\n\n![Notre Dame de Paris (Musical)](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202309281704637.jpeg)\n\n非常非常完美的一部剧\n\n喜爱程度：⭐⭐⭐⭐⭐\n\n有官摄可看，虽然很糊\n\n\n\n# Mozart, L'Opéra Rock\n\n![image-20230928171004655](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202309281710900.png)\n\n因为太喜欢德扎了所以我觉得一般，不过歌很好听。\n\n喜爱程度：⭐⭐⭐⭐\n\n有官摄可看。\n\n\n\n## 粉丝来信\n\n![聚焦1940年代上海文学青年，音乐剧《粉丝来信》来了_郑微岚_徐均_中文版](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202309281712727.jpeg)\n\n我真的挺喜欢的，歌也挺好听的，5.20午场演得也很不错。\n\n喜爱程度：⭐⭐⭐⭐\n\n目前还在巡，会再去刷。\n\n可以看韩版官摄。\n\n\n\n\n\n# 话剧\n\n## 蒋公的面子\n\n![喜剧《蒋公的面子》讲了一个什么故事？-黄河票务网](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202309281714186.jpeg)\n\n很好看，整体节奏紧凑，语言幽默，非常有意思。\n\n目前在南京驻演，全国偶尔巡演。\n\n喜爱程度：⭐⭐⭐⭐⭐\n\n\n\n## 惊梦\n\n![img](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202309281718618.jpeg)\n\n非常好看，整体剧情，演绎，节奏都很舒服，适当的幽默，全程只使用天地麦，非常好看，总让我想到莫言的《檀香刑》。看一场少一场，碰到巡演一定冲冲冲！\n\n喜爱程度：⭐⭐⭐⭐⭐\n\n\n\n# 舞剧\n\n## 红楼梦\n\n![image-20230928173423264](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202309281734566.png)\n\n太太太喜欢了，已经看过两次了，想再看无数次！\n\n一直在巡，票很难买。\n\n喜欢程度：⭐⭐⭐⭐⭐\n\n\n\n## 永不消逝的电波\n\n![img](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202309281726845.jpeg)\n\n好喜欢，剧情流的。今年末会在南京演，期待期待。\n\n喜爱程度：⭐⭐⭐⭐⭐\n\n\n\n## 只此青绿\n\n![舞蹈诗剧：只此青绿– 舞绘千里江山图](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202309281728805.jpeg)\n\n意识流，很美。年末也会巡到南京嘿嘿。\n\n喜爱程度：⭐⭐⭐⭐⭐\n\n\n\n\n\n","tags":["thoughts","Music","theater","I'm alive"],"categories":["Let's think","Life"]},{"title":"2022.8-2022.9暑期学校总结","url":"/post/6ba0d0e7.html","content":"\n  很难形容的一个月，确实增长了不少见识。\n\n<!-- more -->\n\n如果非得让我列一下时间线，那应该是\n\n1. 暑期初始，校企发布让大家选项目的要求以及多次@全体成员\n  * 心情：无语+心烦\n2. 填完项目后，暑期中后段，发布分组情况，要求大家在暑假期间完成训前作业\n\n   * 心情：得知分组为我+两个隔壁班同学+一个狂重修哥，心情复杂，非常不道德地去查了隔壁俩同学的绩点，了解基本情况后晴天霹雳，当时和朋友聊天出现得最多的词语是“麻麻的”。本来准备我当组长好了，结果隔壁有个同学拉群了，询问大家当组长的意愿，不知道怎么脑子抽了说自己也不想当组长，隔壁某同学遂成为组长，胡乱分工开始训前作业。\n   * 当时分完工还和朋友说可能没有想得那么差，如今看来当时已经铺好了烂掉的基石。\n   * 得知分组后第一时间开始学习前端相关知识。说来其实也很好笑，本来未放假时的计划就是学习前端知识，结果回家了一点儿没实施，但是分组结果一出来就马上去学了，果然是有压迫才有动力.....\n\n3. 临近开学，合训前作业\n\n   * 以为自己在来学校前一天正式写完就是最慢了，结果貌似除了我没人写完，合模块也相当于没有合，只是随意拼凑。\n   * 再次对分组感到无语+心灰意冷\n\n4. 正式开学开始实训，线上写文档\n\n   * 反感企业老师只是装模做样而讲不出有价值的知识点；反感小组没有交流或是交流后没有有用的结果；反感每次分工都是按照demo的页数进行分工，没有根据自己的项目进行；反感每次分工都是“先到先得”，没有相对合理地安排大家的工作。\n   * 开始后悔自己为什么不当组长。\n\n5. 三天过后线下写文档\n\n   * 天气真的好热，到教室也是大家开腾讯会议上课。不明白为什么要这样，开始无止境的抱怨，生气，写文档依然重复之前的模式，甚至出现了我因为完成了自己的任务而必须开始接受未分配的新任务，没完成的不用因为他们“任务重”.....\n   * 第一天线下就碰到了勤工俭学的老师，于是收放排插的任务自然而然地被交给了我和yc同学，真的很累，也有一点尴尬，开始自己生闷气\n\n6. 文档写完开始编码阶段\n\n   * 再次抱怨老师没有有用的知识输出\n   * 分工变成了前后端分开，相对合理\n   * 组内分工结束三天后才和前端某同学商量页面分工，初步分了一下，开始写\n   * 中途逃课被逮住一次\n\n7. 前端我的部分完成\n\n   * 基本写完我的部分，老师第一次检查进度，发现后端除了基本的增删改查几乎没写，联系另一个前端同学O一直不回消息\n\n   * 尝试再次联系另一个前端同学O，不回\n\n   * 和组长L商量那个同学的情况，组长说把这部分工作分给了另外一个后端同学Z，他一个人写后端就行\n\n   * 与同学Z联系问他进度，他说还卡在登录注册.....\n\n   * 鉴于后端写得有些乱七八糟以及同学Z不会后端，于是说前端全部给我写好了，他们俩把后端写好就行\n\n   * 三天后同学O终于回消息说自己这几天发病了精神状态不太对，问啥时候截止，此时他的部分我已写一大半\n\n   * 无法判别是否真的生病，只能和朋友说“如果是真的我希望是假的，如果是假的我希望是真的”，理解生病但是不理解为什么不和大家说进度\n\n   * 和同学O说他不用写了我写就行，如下\n\n     <img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202209101459911.png\" alt=\"image-20220910145932831\" style=\"zoom:50%;\" />\n\n   * 第三周周末前端几乎完成，与后端整合开始\n\n8. 开始与后端整合\n\n   * 几乎是我一个人的工作\n\n   * 后端非常多接口都没写\n\n   * 中途我去做了根管，，\n\n   * 开始整合\n\n     1. 后端没跨域处理\n\n        <img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202209101502103.png\" alt=\"image-20220910150225047\" style=\"zoom:50%;\" />\n\n     2. 注册传不进参数，同学L说swagger测试没问题，我用的前端以及postman都有问题，换成swagger问题依然存在，遂以为是我电脑环境的问题，后来发现是代码的问题......\n\n        <img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202209101504764.png\" alt=\"image-20220910150448708\" style=\"zoom:50%;\" />\n\n        <img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202209101505485.png\" alt=\"image-20220910150533359\" style=\"zoom: 40%;\" />\n\n     3. 一个人合前后端没人帮忙的情况下多次催进度，，\n\n        <img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202209101508483.png\" alt=\"image-20220910150811416\" style=\"zoom:50%;\" />\n\n     4. 后端改动后不列出具体改动哪里，一个所有的打包文件发过来。。\n\n        <img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202209101508583.png\" alt=\"image-20220910150839534\" style=\"zoom:50%;\" />\n\n     5. 后端需改动让前端改一下\n\n        <img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202209101510316.png\" alt=\"image-20220910151005239\" style=\"zoom:50%;\" />\n\n     6. 这个尼玛就是我的心情\n\n        <img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202209101510737.png\" alt=\"image-20220910151032690\" style=\"zoom:50%;\" />\n\n     7. 第二次进度组长上讲台给老师展示\n\n        <img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202209101511170.png\" alt=\"image-20220910151123121\" style=\"zoom:50%;\" />\n\n     8. 数据库表的连接删除有问题，哈哈非说swagger测试了没问题\n\n        <img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202209101512189.png\" alt=\"image-20220910151236120\" style=\"zoom:50%;\" />\n\n        <img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202209101515178.png\" alt=\"image-202209101515178\" style=\"zoom:50%;\" />\n\n     9. 不知道说什么，，，\n\n        <img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202209101513046.png\" alt=\"image-20220910151316006\" style=\"zoom:50%;\" />\n\n        <img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202209101513947.png\" alt=\"image-20220910151337864\" style=\"zoom:50%;\" />\n\n     10. 给出问题所在还是不同意，以为他理解了其实没理解\n\n         <img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202209101519021.png\" alt=\"image-20220910151924924\" style=\"zoom:50%;\" />\n\n         <img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202209101519841.png\" alt=\"image-20220910151924924\" style=\"zoom:50%;\" />\n\n         <img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202209101521802.png\" alt=\"image-20220910152137721\" style=\"zoom:50%;\" />\n\n     11. 懂了过后说方案结果不改，我直接震惊了\n\n         <img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202209101522502.png\" alt=\"image-20220910152235445\" style=\"zoom:50%;\" />\n\n     12. 接口“写了”不好测哈哈\n\n         <img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202209101523191.png\" alt=\"image-20220910152307130\" style=\"zoom:50%;\" />\n\n         <img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202209101523313.png\" alt=\"image-20220910152307130\" style=\"zoom:50%;\" />\n\n     13. 提出解决方案后问我怎么做，\n     \n         <img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202209101525941.png\" alt=\"image-20220910152535868\" style=\"zoom:50%;\" />\n     \n     14. 接口传参有问题，说了不改，，\n     \n         <img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202209101526899.png\" alt=\"image-20220910152632813\" style=\"zoom:50%;\" />\n     \n     15. 分页接口写得不对还非要写分页，，\n     \n         <img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202209101527128.png\" alt=\"image-20220910152732057\" style=\"zoom:50%;\" />\n     \n     16. 答辩前一天还在大改，，\n     \n         <img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202209101528552.png\" alt=\"image-20220910152822473\" style=\"zoom:50%;\" />\n     \n     17. 在我明确说过看板娘之类的元素不好看的情况下，在答辩前还是改了我的前端加上去了哈哈\n     \n         <img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202209101529406.png\" alt=\"image-20220910152915364\" style=\"zoom:50%;\" />\n     \n     18. 答辩当天说电脑不行要用我的电脑\n     \n         <img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202209101530799.png\" alt=\"image-20220910153018737\" style=\"zoom:50%;\" />\n     \n         他不肯呐哈哈\n     \n         <img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202209101530970.png\" alt=\"image-20220910153045924\" style=\"zoom:50%;\" />\n     \n     19. 上午答辩结束后已经去食堂吃饭忽然给我说\n     \n         <img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202209101531512.png\" alt=\"image-20220910153156461\" style=\"zoom:50%;\" />\n     \n     20. 觉得自己很幽默吗？\n     \n         <img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202209101532546.png\" alt=\"image-20220910153229506\" style=\"zoom:50%;\" />\n     \n     21. 我说1点过去非得12：40，说要录视频，最后精彩的是什么朋友们，2点开始下午答辩，1：57视频还没录，视频也是我录的哈哈哈麻麻的\n     \n         <img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202209101533275.png\" alt=\"image-20220910153352211\" style=\"zoom:50%;\" />\n     \n     22. 让我12：40过去，12：40教室没人，说没找到空的教室，可是我在的教室就是空的哈哈\n     \n         <img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202209101534774.png\" alt=\"image-20220910153450721\" style=\"zoom:50%;\" />\n     \n     23. 哈哈结果就是改了我的前端\n     \n         <img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202209101535611.png\" alt=\"image-20220910153536577\" style=\"zoom:50%;\" />\n\n9. 答辩过程\n\n   * 讲得稀烂，演示稀烂，改了我的前端这件事我是不可能能原谅的\n\n10. 答辩结束\n\n   * 希望这辈子都不会碰到，希望这辈子都不会再碰到这么烂的组。\n   * 结束后飞速退掉了两个小组群\n\n\n\n**写在最后：**\n\n并不是不能接受和成绩不好的同学组队，而是接受不了无法沟通以及摆烂的组员，他们可能挂科无所谓，可是我不能接受。舍友说得很对，烂的应该在一个队，这样大家的情绪都是一样的。而不是像我们组，只有我一个人在地狱。真是你觉得负重前行是因为有人在替你岁月静好。\n\n希望再也不会遇到烂组员！\n\n","tags":["studying","thoughts"],"categories":["Let's think","Life"]},{"title":"前端学习笔记","url":"/post/91ce7628.html","content":"\n## Before Reading\n\n1. 请点击左下方小框打开目录配合阅读\n2. 只有基础与大致的内容\n3. 大部分参考来自<a href=\"https://www.runoob.com\">菜鸟教程</a>\n4. 点击可见<a href=\"https://www.runoob.com/cssref/css-colornames.html\">颜色名称表</a>\n\n\n\n***\n\n\n\n[TOC]\n\n<!-- more -->\n\n## HTML\n\nHTML(Hypertext Makeup Language)，即超文本**标记**语言，主要负责网页内容的展示，大小写不敏感。\n\n### 标记\n\n   一般以<标签名>...</标签名>的形式成对出现，自结束标签无需结束符\n\n#### 常见的标签\n\n   * 文档声明[html5]：<!doctype html>放在顶端\n\n   * 网页根标签：`<html>...</html>`\n\n   * `<head>...</head>非用户可见，一般为告诉浏览器属性`\n\n     * head中的标题/浏览器头部标题：`<title>text</title>`\n\n     * HTML文档元数据：`<meta>`,可说明编码类型，描述(discription)，作者(author)等等\n\n       `<meta charset=\"utf-8\">`\n\n       `<meta name=\"author\" content=\"moo1\">`\n\n     * 链接：`<link>`，定义文档与外部资源的关系，空元素，只包含属性，常用于来链接样式表。\n\n       * 属性：\n\n         1. herf：被链接文档的位置\n         2. rel：当前文档与被链接文档之间的关系，<mark>必须</mark>\n         3. type：type 属性规定被链接文档/资源的 MIME 类型。只有当设置了 href 属性时，才能使用该属性。`<link>` 标签常用的 MIME 类型是 \"text/css\"，它规定样式表。\n\n         <a href=\"https://www.runoob.com/tags/tag-link.html\">更多与link属性相关可点击查看。</a>\n\n         \n\n* `<body>...</body>`用户可见，具体内容\n  \n* 标题：`<hn>text</hn>`,n=1~6\n  \n* 段落：`<p>text</p>`\n  \n* 超链接：`<a>text</a>`，一般与herf属性一起使用\n  \n  <a href=\"https://mooyi.xyz\">welcome to mooyi's channel!</a>\n  \n* 换行：`<br>`\n  \n* 粗体：`<b>text</b>`\n  \n     **Atten**:`<strong>text</strong>`也有加粗的效果，但是还表示重要呈现\n   \n* 按钮：`<button>text</button>`\n  \n  <button>text</button>\n  \n* 文档中的节：`<div>text</div>`\n  \n* 文本中的节：`<span>text</span>`\n  \n* 斜体：`<i>text</i>`\n  \n     **Atten**:`<em>text</em>`也有斜体效果，同样表示重要呈现\n   \n* 输入：`<input>`\n  \n* 高亮：`<mark>text</mark>`\n  \n  <mark>text</mark>\n  \n* 下标：`1<sub>text</sub>`\n  \n  1<sub>text</sub>\n  \n* 上标：`1<sup>text</sup>`\n  \n  1<sup>text</sup>\n  \n* 删除线：`<del>text</del>`\n  \n  <del>text</del>\n  \n* 插入/下划线：`<ins>text</ins>`\n  \n  <ins>text</ins>\n\n<a href=\" https://www.runoob.com/tags/ref-byfunc.html\">更多标签可点击查看。</a>\n\n\n\n### 标签属性\n\n  在开始标签中设置，属性是键值对结构(\"key\"=\"value\")\n\n#### 常见属性\n\n   * id(唯一)\n\n   * style:指定行内样式，多个样式以;分隔\n\n     `style=\"color:red;text-align:center\"`\n\n     <p style=\"color:red;text-align:center\">\n         style-showing.\n     </p>\n\n   * title：额外信息/工具条\n\n     `<p><ins title=\"格外信息\">move</ins> on this</p>`\n\n     <p><ins title=\"格外信息\">move</ins> on this</p>\n\n<a href=\"https://www.runoob.com/tags/ref-standardattributes.html\">更多属性可点击查看。</a>\n\n\n\n### 注释\n\n`<!--this is unshown.-->`\n\n\n\n### HTML事件\n\n事件可以触发浏览器行为，与JS联合使用。\n\n表示：`event=\"script()\"`\n\n#### 窗口事件属性(Window Event Attributes)\n\n窗口触发，适用于`<body>`标签\n\n* onresize：调整窗口大小时运行脚本\n\n  `<body onresize=\"Function()\">`\n\n* 文档触发，窗口失焦...\n\n\n\n#### 表单事件(Form Events)\n\n表单中触发，HTML元素需在form表单内。\n\n\n\n#### 键盘事件(Mouse Events)\n\n* onkeydown：按下键盘\n* onkeypress：按下并松开\n* onkeyup：松开按键\n\n\n\n#### 鼠标事件(Mouse Events)\n\n* onclick：单击\n* ondblclick：双击\n* ondrag：拖动元素\n\n...\n\n\n\n#### 多媒体事件(Media Events)\n\n通过视频（videos），图像（images）或者音频（audio） 触发该事件，多应用于 HTML 媒体元素比如 `<audio>, <embed>, <img>, <object>, 和<video>`:\n\n\n\n#### 其他事件\n\n\n\n<a href=\"https://www.runoob.com/tags/ref-eventattributes.html\">更多事件可点击查看。</a>\n\n\n\n其余HTML相关内容可参考https://www.runoob.com/html/html-tutorial.html\n\n\n\n***\n\n\n\n## CSS\n\nCSS(Cascading Style Sheets)，主要负责网页布局，描述HTML/XML的呈现，即其如何被渲染。\n\n```css\np{\n\tfont-size: 20px;\n\tcolor:red;\n}\n```\n\n&lt;<span style='background-color:red'>p</span>&gt;text&lt;/p&gt;\n\np:选择器\n\nfont-size/color:属性，冒号后为其值\n\n大括号括着的为声明，声明以;结束\n\n\n\n### 选择器\n\n#### id选择器\n\n  以#定义，不以数字开头(避免在Mozilla/Firefox不起作用)\n\n  eg.: <mark>**#test**</mark>{\n\n  ​\ttext-align:center;\n\n  ​\tcolor:red;\n\n  }\n\n  &lt;p <mark>**id=\"test\"**</mark>&gt;text&lt;/p&gt;\n\n#### class选择器\n\n  以.显示，多个用空格区分，类名第一个字符非数字\n\n  eg.:\n\n  <span style=\"background-color:#7FFFD4\">**.center**</span>{\n\n  text-align:center;\n\n  }\n\n  &lt;p <span style=\"background-color:#7FFFD4\">**class=\"center\"**</span>&gt;text&lt;/p&gt;\n\n注释：`/*text*/`\n\n\n\n### 组合选择符\n\n#### 后代选择器\n\n选取某元素的后代元素，以空格` ` 分离。\n\n```html\n<style>\ndiv p\n{\n\tbackground-color:yellow;\n}\n</style>\n\n<div>\n<p>段落 1。 在 div 中。</p>\n<p>段落 2。 在 div 中。</p>\n</div>\n\n<p>段落 3。不在 div 中。</p>\n<p>段落 4。不在 div 中。</p>\n```\n\n<img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202207311311428.png\" alt=\"image-20220731131103323\" style=\"zoom:67%;\" />\n\n#### 子元素选择器\n\n只能选择作为某元素<span style=\"background-color:#E0FFFF\">直接/一级子元素的元素</span>，大于符号`>`分隔。\n\n\n```html\n<style>\ndiv>p\n{\n\tbackground-color:yellow;\n}\n</style>\n\n<h1>Welcome to My Homepage</h1>\n<div>\n\t<h2>My name is Donald</h2>\n\t<p>I live in Duckburg.</p>//highlight\n</div>\n\n<div>\n\t<span><p>I will not be styled.</p></span>//no highlight with the first child \"span\"\n    <p><span>I will be styled.</span></p>//highlight because \"p\" is the first child\n</div>\n\n<p>My best friend is Mickey.</p>\n```\n\n<img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202207311322609.png\" alt=\"image-20220731132236565\" style=\"zoom: 50%;\" />\n\n#### 相邻兄弟选择器\n\n选择<span style=\"background-color:#E0FFFF\">**紧接**在另一元素后的元素，且二者有相同父元素</span>，用`+`分隔。\n\n```html\n<style>\ndiv+p\n{\n\tbackground-color:yellow;\n}\n</style>\n\n<div>\n<h2>DIV 内部标题</h2>\n<p>DIV 内部段落。</p>\n</div>\n\n<p>DIV 之后的第一个 P 元素。</p>//adjacent to the \"div\"\n\n<p>DIV 之后的第二个 P 元素。</p>\n```\n\n<img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202207311326422.png\" alt=\"image-20220731132642385\" style=\"zoom:67%;\" />\n\n\n\n#### 后续兄弟元素\n\n后续兄弟选择器选取<span style=\"background-color:#E0FFFF\">所有指定元素**之后**的相邻兄弟元素</span>。用`~`隔开。\n\n```html\n<style>\ndiv~p\n{\n\tbackground-color:yellow;\n}\n</style>\n\n<p>之前段落，不会添加背景颜色。</p>\n<div>\n<p>段落 1。 在 div 中。</p>\n<p>段落 2。 在 div 中。</p>\n</div>\n\n<p>段落 3。不在 div 中。</p>\n<p>段落 4。不在 div 中。</p>\n```\n\n<img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202207311331016.png\" alt=\"image-20220731133141976\" style=\"zoom: 67%;\" />\n\n\n\n\n\n\n### 插入样式表\n\n#### 外部样式表(external style sheet)\n\n  一般用于*同一样式需用于很多页面*，通过mystyle.css文件改变站点整体样式【页面使用`<link>`标签链接到样式表，该标签位于文档头部`<head>`中】\n\n  `<link rel=\"stylesheet\" href=\"mystyle.css\">`\n\n#### 内部样式表(internal style sheet)\n\n  一般用于*单个文件*，利用`<style>`标签在头部文件内部定义。\n\n  <img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202207291021544.png\" alt=\"image-20220729102140460\" style=\"zoom: 80%;\" />\n\n#### 内联样式(inline style)\n`<p style=\"color:sienna;margin-left:20px\">text</p>`\n\n<p style=\"color:sienna;margin-left:20px\">text</p>\n\n**Atten:<span style=\"background-color:#ADFF2F\">多重样式优先级</span>**\n内联>内部>外部>默认\n\n\n\n### 背景\n\n- background-color\n- background-image\n- background-repeat：水平或垂直方向平铺或不平铺(repeat-x/repeat-y/no-repeat)\n- background-attachment：是否固定/滚动\n- background-position：起始位置\n\n背景可简写属性，属性顺序如上顺序，属性可不全部使用。\n\n`body {background:#ffffff url('img_tree.png') no-repeat right top;}`\n\n\n\n### 对齐\n\n* 元素居中对齐\n\n使用`margin: auto`\n\n图片居中对其需放入块元素中\n\n\n\n* 文本居中对齐\n\n`text-align: center`\n\n\n\n* 左右对齐-定位\n\n`position:absolute`\n\n注释：绝对定位元素会被从正常流中删除，并且能够交叠元素。\n\n**Atten:** 当使用 **position** 来对齐元素时, 通常`<body>`元素会设置 **margin** 和 **padding** 。 这样可以避免在不同的浏览器中出现可见的差异。\n\n\n\n* 左右对齐-float\n\n`float:left/right`\n\n**Atten**：如果子元素的高度大于父元素，且子元素设置了浮动，那么子元素将溢出，这时候你可以使用 \"***clearfix***(清除浮动)\" 来解决该问题。可以在父元素上加`overflow:auto`来解决子元素溢出。\n\n\n\n* 垂直居中-padding\n\n```css\n.center {\n    padding: 70px 0;//水平居中\n    border: 3px solid green;\n    text-align: center;//垂直居中\n}\n```\n\n\n\n* 垂直居中-line-height\n\n```css\n.center {\n    line-height: 200px;\n    height: 200px;\n    border: 3px solid green;\n    text-align: center;\n}\n \n/* 如果文本有多行，添加以下代码: */\n.center p {\n    line-height: 1.5;\n    display: inline-block;\n    vertical-align: middle;\n}\n```\n\n\n\n* 垂直居中-position&transform\n\n```css\n.center { \n    height: 200px;\n    position: relative;\n    border: 3px solid green; \n}\n \n.center p {\n    margin: 0;\n    position: absolute;\n    top: 50%;\n    left: 50%;\n    transform: translate(-50%, -50%);\n}\n```\n\n\n\n### 伪类(Pseudo-classes)&伪元素\n\n#### 伪类\n\n伪类语法：`selector:pseudo-class {property:value;}`\n\nCSS类使用伪类：`selector.class:pseudo-class {property:value;}`\n\n#### 伪元素\n\n语法：`selector:pseudo-element {property:value;}`\n\nCSS类使用伪元素：`selector.class:pseudo-element {property:value;}`\n\n\n\n<a href=\"https://www.runoob.com/css/css-tutorial.html\">其余相关内容请点击查看。</a>\n\n\n\n\n\n***\n\n\n\n\n\n## JavaScript\n\nJavaScript是一种脚本语言，控制了网页的行为，插入HTML页面后，由浏览器执行。\n\n浏览器逐行读取并执行代码(不是先全部编译再执行)。\n\n\n\n### 使用\n\n* 在HTML文件页中使用`<script>...</script>`标签。\n\n  Atten:一般放在head中或页面底部(body)\n\n* HTML文件可使用外部的.js文件，利用script标签的<span style=\"color:red\">src</span>属性\n\n  `<script src=\"myScript.js\">...</script>`\n\n使用时，为`事件=函数名()`.\n\n\n\n### 输出/显示数据\n\n* window.alert()弹出警告\n```html\n<script>\n\twindow.alert(2);\n\t</script>\n```\n\n* document.write()将内容写入HTML文档\n\n```html\n  <script>\n  document.write(\"11\");\n  </script>\n```\n\n\n  **Atten**:仅向文档输出写内容，<span style=\"background-color:#E0FFFF\">若在文档加载完成后执行，整个页面将被覆盖</span>。\n\n  <span style=\"background-color:#E0FFFF\">Example</span>\n\n```html\n\t<button onclick=\"test()\">test1</button>\n\t<script>\n\t document.write(\"document1\");\n\t \tfunction test(){\n\t \tdocument.write(\"refreshing\");\n\t \t}\n\t </script>\n```\n\n   result:<img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202207312149397.png\" alt=\"image-20220731212404112\" style=\"zoom:67%;\" />\n\n   After clicking the botton:<img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202207312150251.png\" alt=\"image-20220731213114137\" style=\"zoom:80%;\" />\n\n\n* innerHTML写入到HTML文档中\n\n```html\n   <script>\n   document.getElementById(\"id1\").innerHTML=\"new text\";\n   </script>\n```\n\n* console.log()写入到控制台\n\n```html\n   <script>\n   console.log(2);\n   </script>\n```\n\n   一般为利用浏览器进行调试。\n\n   \n\n### 语法\n\n#### 字面量(固定值)\n\n* 数字(Number)：整数/小数`3.14`\n\n* 字符串(String)：单引号/双引号`'text'`/`\"text\"`\n\n  * 可使用索引位置访问单个字符\n  * 字符串中可含引号，不能与字符串的相同/使用转义字符`\\'`or`\\\"`以使用引号\n  * 可使用.length计算长度\n  * 可使用new关键字将字符串定义为对象\n\n* 表达式：`1+1`\n\n* 数组(Array)：`[1,2,3]`/`['apple','orange']`\n\n* 对象(Object)：`{key1:\"value1\",key2:\"value2\"}`，可跨行定义\n\n  访问对象属性：\n\n  ```js\n  var person={\n      name:\"Lee\",\n      age:\"22\",\n      information:function(){\n      return \"name:\"+this.name+\" \"+\"age:\"+this.age;\n  }};\n  //access attributes1\n  person.name;\n  //access attributes2\n  person[\"name\"];\n  //access function\n  var infor=person.information();//without(),the strings of \"information\" will be displayed\n  ```\n\n  **Atten**:<span style=\"background-color:#FFFACD\">数组索引为数字，对象索引为名字(key/name)</span>\n\n* 函数(Function)：`function myFunction(){}`\n\n\n\n#### 数据类型\n\n<img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202207312329738.png\" alt=\"image-20220731232911606\" style=\"zoom: 67%;\" />\n\n\n\n#### 变量\n\n使用关键字<span style=\"color:red\">var</span>定义变量，`var a=1;`\n\n* 变量名使用驼峰命名法，大小写敏感。\n\n* 变量声明`var name;`,此时name的值为undefined\n\n* 重新声明变量，其值不会丢失\n\n* JS拥有动态类型，相同变量可作不同类型\n\n* const关键字定义常量，声明时初始化`const x=10;`，作用域与let相似\n\n  <mark>Atten</mark>：const定义的并不是严格意义上的常量，它定义了一个常量引用一个值。使用 const 定义的对象或者数组，其实是可变(<span style=\"color:red\">可修改/增加元素，不可重新赋值</span>)的。\n\n  ```js\n  const person={name:\"Lee\",age:\"22\"};//常量对象\n  person.name=\"Ham\";//修改属性\n  person.location=\"xxx\";//添加属性\n  //不可对常量对象重新赋值\n  //person={name:\"Ham\",age:\"22\"} //wrong\n  ```\n\n  可以使用Object.freeze()来冻结变量放置修改。\n\n##### 变量作用域\n\n* 函数体外声明的变量为全局变量，函数内声明的变量为局部变量(var)\n\n* <span style=\"color:green\">在块中声明var变量，其在块外依然可被访问</span>\n\n  <img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202207312223668.png\" alt=\"image-20220731222319625\" style=\"zoom: 80%;\" />\n\n* 使用<span style=\"background-color:#B4EEB4\">let</span>关键字可实现只在块内有效\n\n  <img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202207312225564.png\" alt=\"image-20220731222514523\" style=\"zoom:80%;\" />\n\n* 重新定义变量\n\n  * var：可在任意地方修改,<img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202207312231711.png\" alt=\"image-20220731223151672\" style=\"zoom:67%;\" />\n  * let：<img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202207312231209.png\" alt=\"image-20220731223135155\" style=\"zoom:67%;\" />\n  * 相同作用域/块级作用域中，不能用let关键字重置var/let声明的变量\n  * 相同作用域/块级作用域中，不能用 var关键字重置let声明的变量\n  * 相同作用域/块级作用域中，不能用 const关键字重置var/let/const声明的变量\n\n* 使用var声明的全局变量<span style=\"background-color:#FFC1C1\">属于window对象</span>.\n\n* 使用let声明的全局变量<span style=\"background-color:#FFC1C1\">不属于window对象</span>.\n\n* <b><span style=\"color: #FF8247\">var变量可以先使用再声明</span>(作为全局变量，可删除,<span style=\"background-color:#4682B4;color:white\">严格模式下不允许</span>)，let变量必须声明才能使用。</b>\n\n  * 严格模式(use strict)\n\n    >在脚本或函数头部添加`\"use strict\";`表达式来声明\n    >\n    >* 不允许使用未声明变量\n    >\n    >* 不允许删除变量或对象\n    >\n    >* 不允许删除函数\n    >\n    >* 不允许变量重名\n    >\n    >* 不允许使用八进制\n    >\n    >* 不允许使用转义字符`\\`\n    >\n    >* 不允许对只读属性赋值(writable:false)\n    >\n    >* 不允许对使用getter方法读取的属性赋值\n    >\n    >  ```js\n    >  \"use strict\";\n    >  var obj = {get x() {return 0} };\n    >  \n    >  obj.x = 3.14;            // 报错\n    >  ```\n    >\n    >* 不允许删除不允许删除的属性\n    >\n    >* 变量名不能使用`\"eval\"/\"arguments\"`字符串\n    >\n    >* 不允许使用如下语句\n    >\n    >  ```js\n    >  \"use strict\";\n    >  with (Math){x = cos(2)}; // 报错\n    >  ```\n    >\n    >* 由于一些安全原因，在作用域 eval() 创建的变量不能被调用\n    >\n    >  ```js\n    >  \"use strict\";\n    >  eval (\"var x = 2\");\n    >  alert (x);               // 报错\n    >  ```\n    >\n    >* 禁止this关键字指向全局对象：严格模式下this为undefined\n    >\n    >函数内部使用作用域为函数内部\n\n\n\n##### 程序块作用域\n\n在每个代码块中 JavaScript 不会创建一个新的作用域，一般各个代码块的作用域都是全局的。\n\n  ```js\nfor (var i = 0; i < 10; i++) {\n    // some code\n}\nreturn i;//i=10, not undefined\n  ```\n\n \n\n##### 声明提升\n\n> * 函数及变量的<span style=\"background-color:#EEE0E5\">声明都将被提升到函数的最顶部</span>，即声明位于任意位置都等同与在函数顶部\n> * <span style=\"background-color:#E0EEE0\">初始化不会提升</span>，即初始化后位置确定\n> * 一般在每个作用域前声明所有变量\n\n\n\n\n\n#### 语句\n\n* 语句自动忽略多余空格\n\n* 语句以，分隔\n\n* 可在文本字符串中使用反斜杠对代码换行\n\n  ```js\n  document.write(\"hello\\\n  world!\");\n  ```\n\n* 注释为`//`与`/*...*/`\n\n* return语句自动看作加分号的语句（代码结束[默认为最后一句]）\n\n##### 比较运算符\n\n![image-20220731231259574](https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202207312312796.png)\n\n* 普通比较\"=\\=\"忽略数据类型，严格比较\"===\"同时检查值与类型\n* switch语句中case的比较为严格比较(===)\n\n\n\n##### For/In循环\n\n遍历对象属性\n\n  ```js\nvar infor;\nvar person={name:\"Ham\",age:22};\nfor(x in person){//x为属性名\n    infor=person[x]+\" \";\n}\n//infor=Ham 22 ;\n  ```\n\n\n\n##### Typeof/null/undefined\n\n* typeof可用于检测变量的数据类型，`typeof  'Ham'`/`typeof 3.14\t`\n\n* NaN的数据类型为number\n\n* Atten:数组时对象的特殊类型，所以`typeof Array/Date`返回对象\n\n  * constructor属性返回所有JS变量的<mark>构造函数</mark>\n\n  * 通过constructor判断类型：检验返回值是否包含相应字符串\n\n\n  ```js\nfunction isArray(arr){\n    return arr.constructor.toString().indexOf(\"Array\")>-1;\n}\n  ```\n\n\n\n\n* null 表示空对象引用，`typeof null`返回对象\n\n* 可以利用null来清空对象\n\n* undefined表示未设置值的变量，`typeof 未设置值的变量`返回undefined\n\n* 可以利用undefined来清空变量\n\n* <span style=\"color:orange\"> null== undefined //true</span>\n\n  <span style=\"color:orange\">  null===undefined //false </span>\n\n\n\n##### 类型转换\n\n* 数字->字符串\n\n  * String(number) `String(123)`\n  * Number.toString() `(123).toString()`\n\n* 布尔值->字符串\n\n  * String(false)\n  * false.toString()\n  * <a href=\"https://www.runoob.com/jsref/jsref-obj-number.html\">更多请参考</a>\n\n* 日期->字符串\n\n  * String(new Date())\n  * Date.toString() `obj.toString()`\n  * <a href=\"https://www.runoob.com/jsref/jsref-obj-date.html\">更多请参考</a>\n\n* 字符串->数字\n\n  * Number(\"3.00\")//3.00\n\n    Number(\"isd\")//NaN：非数字值\n\n  * parseFloat()\n\n  * parseInt()\n\n* 一元运算符+：将变量转换为数字\n\n\n  ````js\n  var a=\"1\";\n  var b+=a;//b是一个数字1\n  var c=\"hdai\";\n  var d+=c;//d为数字，值为NaN\n  ````\n\n\n\n\n* 日期->数字\n\n  * Number(new Date())\n  * Date.getTime()\n\n* 自动转换\n\n  <img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202207312347452.png\" alt=\"image-20220731234708405\" style=\"zoom:80%;\" />\n\n* 自动转换为字符串\n\n  尝试输出一个对象或一个变量时 JavaScript 会自动调用变量的 toString() 方法\n\n<a href=\"https://www.runoob.com/js/js-type-conversion.html\">更多请查看</a>\n\n\n\n### 正则表达式(Regular Expression/regex/regexp/RE)\n\n* 正则表达式是由一个字符序列形成的搜索模式。\n\n* 当你在文本中搜索数据时，你可以用搜索模式来描述你要查询的内容。\n\n* 正则表达式可以是一个简单的字符，或一个更复杂的模式。\n\n* 正则表达式可用于所有文本搜索和文本替换的操作。\n\n#### 语法\n\n`/正则表达式主体/修饰符(可选)`\n\n主体用于检索，不区分大小写\n\n* 修饰符\n  * i： 执行对大小写不敏感的匹配。\n  * g：执行全局匹配（查找所有匹配而非在找到第一个匹配后停止）。\n  * m：执行多行匹配。\n\n#### 使用字符串方法\n\n* search()\n\n  检索字符串中指定的子字符串，或检索与正则表达式相匹配的子字符串，并返回子串的起始位置。可使用字符串作参数（自动转化为正则表达式）。\n\n\n  ```js\n  var str=\"HelloWorld\";\n  var n=str.search(/World/i);//n=5\n  var m=str.search(\"World\");//字符串参数自动转化为正则表达式,m=5\n  ```\n\n\n\n* replace()\n\n  使用正则表达式且不区分大小写将字符串中的A替换为B，可使用字符串作参数\n\n\n  ```js\n  var str=\"HelloWorld\";\n  var text=str.replace(/world/i,\"JS\");//text=\"HelloJS\"\n  var text1=str.replace(\"World\",\"JS\");\n  ```\n\n\n\n#### 正则表达式模式\n\n* 方括号用于查找某个范围内的字符\n\n  <img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202208010007126.png\" alt=\"image-20220801000731016\" style=\"zoom:90%;\" />\n\n* 元字符拥有特殊含义\n\n  <img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202208010008921.png\" alt=\"image-20220801000804874\" style=\"zoom:80%;\" />\n\n* 量词\n\n  <img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202208010008243.png\" alt=\"image-20220801000823200\" style=\"zoom:90%;\" />\n\n\n\n#### RegExp对象\n\n一个预定义了属性和方法的正则表达式对象。\n\n##### test()\n\n用于检测一个字符串是否匹配某个模式，如果字符串中含有匹配的文本，则返回 true，否则返回 false。\n\n\n  ``` js\n/e/.test(\"hello\");//true\n  ```\n\n##### exec()\n\n用于检索字符串中的正则表达式的匹配。该函数返回一个数组，其中存放匹配的结果。如果未找到匹配，则返回值为 null。\n\n  ```js\n/e/.exec(\"hello\");//输出e\n  ```\n\n\n\n<a href=\"https://www.runoob.com/jsref/jsref-obj-regexp.html\">更多有关RegExp请参考</a>\n\n\n\n### 错误处理：throw, try, catch\n\n  ```js\ntry{\n    ...//exception\n    //can throw exception  defined by the author\n   throw exception //exception can be string/number/logical value/object\n}catch(err){\n    ...//catch exception and handle\n}finally{\n    ...//execute all the time\n}\n  ```\n\n\n\n### 调试\n\n断点/debugger关键字：停止执行JS代码，调用调试函数\n\n\n\n### 验证API\n\n#### 约束验证DOM（Document Object Model）方法\n\n* checkValidity()：如果 input 元素中的数据是合法的返回 true，否则返回 false\n\n  ```html\n  <input id=\"id1\" type=\"number\" min=\"100\" max=\"300\" required>\n  <button onclick=\"myFunction()\">验证</button>\n   \n  <p id=\"demo\"></p>\n   \n  <script>\n  function myFunction() {\n      var inpObj = document.getElementById(\"id1\");\n      if (inpObj.checkValidity() == false) {//输入值不在100~300之间\n          document.getElementById(\"demo\").innerHTML = inpObj.validationMessage;\n      }\n  }\n  </script>\n  ```\n\n  \n\n* setCustomValidity()：设置 input 元素的 validationMessage 属性，用于自定义错误提示信息的方法。\n\n  使用 setCustomValidity 设置了自定义提示后，validity.customError 就会变成 true，checkValidity 总是会返回 false。如果要重新判断需要取消自定义提示，方式如下：\n\n  ```js\n  //使用前取消自定义提示方式，否则下次checkValidity总是false\n  setCustomValidity('')\n  setCustomValidity(null) \n  setCustomValidity(undefined)\n  ...//check and set...\n  ```\n\n\n\n#### 约束验证DOM属性\n\n* validity：布尔属性值，返回 input 输入值是否合法\n\n  <img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202208011500025.png\" alt=\"image-20220801150057861\" style=\"zoom:67%;\" align=\"left\" />\n\n  \n\n* validationMessage：浏览器错误提示信息\n\n* willValidate：指定 input 是否需要验证\n\n\n\n\n\n### JSON\n\nJSON(JavaScript Object Notation)，使用JS语法，但是独立于语言，JSON是轻量级的文本数据交换格式。\n\n\n\n#### 语法规则\n\n> * 数据为键值对(`\"key\":value`)，key必须是字符串，必须在双引号中\n>\n>   > 访问对象值\n>   >\n>   > * obj.key\n>   > * obj[\"key\"]\n>\n> * 数据由`,`分隔\n>\n> * 大括号`{}`保存对象，方括号`[]`保存数组\n\n\n\n#### JSON字符串转换为JS对象\n\n使用<mark>JSON.parse(**text**,reviver)</mark>将接受的数据(字符串)转化为JS对象\n\n* text：必需，一个有效的JSON字符串\n* reviver：可选，一个转换结果的函数， 将为对象的每个成员调用此函数。\n* <a href=\"https://c.runoob.com/front-end/53/\">检验JSON格式是否合法</a>\n\n\n\n##### Atten\n\n1. JSON不能存储Date对象，如果需要存储 Date 对象，需要将其转换为字符串。之后再将字符串转换为 Date 对象。\n\n ```js\nvar text = '{ \"name\":\"Google\", \"initDate\":\"2011-11-11\", \"site\":\"www.google.com\"}';\nvar obj = JSON.parse(text);\nobj.initDate = new Date(obj.initDate);\n ```\n\n​       可以使用reviver参数，一个转换结果的函数，对象的每个成员调用此函数。\n\n ```js\nvar text = '{ \"name\":\"Google\", \"initDate\":\"2011-11-11\", \"site\":\"www.google.com\"}';\nvar obj = JSON.parse(text, function (key, value) {\n    if (key == \"initDate\") {\n        return new Date(value);\n    } else {\n        return value;\n}});\n ```\n\n2. JSON 不允许包含函数，但以将函数作为字符串存储，之后再将字符串转换为函数。\n\n   不建议使用函数\n\n\n\n#### JS对象转换为字符串\n\n使用<mark>JSON.stringify(**value**,replacer,space)</mark>将 JavaScript 对象转换为字符串。\n\n* value:必须， 要转换的 JavaScript 值（通常为对象或数组）。\n\n* replacer:可选。用于转换结果的函数或数组。\n\n  如果 replacer 为函数，则 JSON.stringify 将调用该函数，并传入每个成员的键和值。使用返回值而不是原始值。如果此函数返回 undefined，则排除成员。根对象的键是一个空字符串：\"\"。\n\n  如果 replacer 是一个数组，则仅转换该数组中具有键值的成员。成员的转换顺序与键在数组中的顺序一样。当 value 参数也为数组时，将忽略 replacer 数组。\n\n* space:可选，文本添加缩进、空格和换行符，如果 space 是一个数字，则返回值文本在每个级别缩进指定数目的空格，如果 space 大于 10，则文本缩进 10 个空格。space 也可以使用非数字，如：\\t。\n\n\n\n##### Atten\n\n1. JSON 不能存储 Date 对象。JSON.stringify() 会将所有日期转换为字符串。\n2. JSON 不允许包含函数，JSON.stringify() 会删除 JavaScript 对象的函数，包括 key 和 value。\n\n\n\n\n\n### javascript:void(0) \n\nvoid:指定要计算一个表达式但是不返回值。\n\n> void func()\n>\n> javascript: void func()\n\n> void(func())\n>\n> javasript: void(func())\n\n```html\n<a href=\"javascript:void(0)\">单击此处什么也不会发生</a>\n```\n\n<a href=\"javascript:void(0)\">单击此处什么也不会发生</a>\n\n\n\n```html\n<p>点击以下链接查看结果：</p>\n<a href=\"javascript:void(alert('Warning!!!'))\">点我!</a>\n```\n\n<p>点击以下链接查看结果：</p> <a href=\"javascript:void(alert('Warning!!!'))\">点我!</a>\n\n\n\n#### href=\"#\"与href=\"javascript:void(0)\"的区别\n\n**#** 包含了一个位置信息，默认的锚是**#top** 也就是网页的上端。\n\n而javascript:void(0), 仅仅表示一个死链接。\n\n在页面很长的时候会使用 **#** 来定位页面的具体位置，格式为：**# + id**。\n\n如果你要定义一个死链接请使用 javascript:void(0) 。\n\n```html\n<a href=\"javascript:void(0);\">点我没有反应的!</a>\n<a href=\"#pos\">点我定位到指定位置!</a>\n<br>\n...\n<br>\n<p id=\"pos\">尾部定位点</p>\n```\n\n<a href=\"javascript:void(0);\">点我没有反应的!</a> <a href=\"#pos\">点我定位到指定位置!</a> <br> ... <br> <p id=\"pos\">尾部定位点</p>\n\n\n\n<a herg=\"https://www.runoob.com/js\">更多JavaScript内容可参考</a>\n\n\n\n## ES6\n\nES6(ECMAScript 6.0)为js的一种标准\n\n* Babel转码器可以将ES6代码转为ES6\n\n  Babel的配置文件<span style=\"color:red\">.babelrc</span>存放在项目的根目录，使用前需先配置\n\n  ```\n  {\n  \"presets\": [//设定转码规则\n   \"@babel/env\",\n   \"@babel/preset-react\"\n  ],\n  \"plugins\": []\n  }\n  ```\n\n* 命令行转码\n\n  ```\n  # 转码结果输出到标准输出\n  $ npx babel example.js\n  \n  # 转码结果写入一个文件\n  # --out-file 或 -o 参数指定输出文件\n  $ npx babel example.js --out-file compiled.js\n  # 或者\n  $ npx babel example.js -o compiled.js\n  \n  # 整个目录转码\n  # --out-dir 或 -d 参数指定输出目录\n  $ npx babel src --out-dir lib\n  # 或者\n  $ npx babel src -d lib\n  \n  # -s 参数生成source map文件\n  $ npx babel src -d lib -s\n  ```\n\n* babel-node 支持直接运行ES6代码\n\n","tags":["studying","front-end","coding"],"categories":["Learning","front-end"]},{"title":"不同年纪对应的音乐喜爱度变化","url":"/post/7b89dc1f.html","content":"\n\n\n随着年纪的增加，对不同音乐的喜好程度有了很大变化。\n\n <!-- more -->\n\n## 听歌软件的使用\n\n  最开始用的是咪咕音乐，后面开始用酷我音乐，然后开始用酷狗音乐，过渡到QQ音乐，网易云音乐，Apple Music以及现在用得较多的Spotify。\n\n\n\n## 小学期间\n\n  应该算是到了五年纪才有了自己找歌听的意识，在此之前都是被动地接受别人所放的歌曲。自己找歌听听得最多的是什么呢？徐良、许嵩、汪苏泷，也就是现在的所谓的童年”三巨头“。三人比较的话听得最多的应该是徐良，当时非常痴迷他和孙雨幽的合唱。\n\n《情话》这张专的好多歌我都还会唱，前段时间宿舍放歌放童年回忆歌曲，放到他们的歌我还能完整唱出来，不得不说确实算是刻在了我的脑子中。\n\n  其二就是许嵩，听许嵩其实应该算是受到一个发小的影响，当时没有什么自己找歌听的概念，一般是看到别人做什么就开始跟着听，但是好像几乎全是有关感情的歌，为什么小学生喜欢听这个？\n\n  汪苏泷其实好像就听了一两首，记忆最深的是小星星，现在也还会唱。\n\n  因为当时比较喜欢宋茜还听了挺多fx的歌来着，现在连歌名是什么都忘记了。\n\n\n\n## 初中\n\n  刚进入初中最开始其实还是保留小学的审美，后面因为主流审美的变化以及接触到了不同的同学才开始有所变化。\n\n  受湖南卫视我是歌手的影响，其实听到了很多算还不错的歌，刚刚去重新登录了酷我的账号，发现列表里几乎都是我是歌手里的歌以及一些电影主题曲。\n\n  受身边好朋友以及当时主流追星的影响，听了当时的TFBOYS的几乎全部歌曲，后面开始追韩国男团女团，听了当时的BTS以及GOT7的很多歌，也听了几首Bigbang的，现在几乎全忘了。\n\n  受身边一个朋友的影响开始听英文歌曲，听的第一个歌手应该是Taylor Swift，因为当时朋友很喜欢她。后面比较喜欢欧美音乐，开始了自己探索，大量听欧美歌曲，听b榜的歌曲，当时非常喜欢断眉，那个时期他发行的所有单曲都会唱。也很喜欢霉霉，不过好像只听了部分，最喜欢的是1989这张专，还记得当时QQ音乐这张专要付费，我还买了。\n\n\n\n## 高中\n\n  高中其实是初中的延续以及自己探索的延续。保留了听欧美的耳朵，不断听欧美流行歌曲，逐渐从断眉转变到喜欢萌德(Shawn Mendes)，后面觉得他从阳光大男孩转变到油腻大叔了以及出的专奇奇怪怪就放弃了(说的就是你senorita).但是还是一直在听欧美流行。\n\n  逐渐找到自己喜欢的歌曲的样子，开始听country music以及一些杂七杂八不同语言的歌曲。\n\n  过渡到后面非常喜欢看歌舞相关电影，开始听电影插曲，列表几乎全是pitch perfect 1-3以及High School Musical 1-3(歌舞青春)相关歌曲。偶尔穿插一切华语歌曲。\n\n  找到自己喜欢的电影的类型——歌舞剧，从现在来看也就是musical的电影拍摄版，开始大量看电影以及听里面的曲子，Moulin Rouge(红磨坊)，The Greatest Showman(马戏之王)，以及其他很有名的音乐剧的电影出品版。\n\n  一般而言是电影带动了我的曲库，有几个相反的算是：\n\n1. Try - Asher Monroe，真的太好听，因为这首歌去看的Fame\n2. Way back into love - Haley Bennett&Hugh Grant，非常非常喜欢电影demo版，真的很甜，所以去看了Music and Lyrics(K歌情人)\n\n  真的非常感谢声入人心这个节目，真的明白与找到了心中所爱，开始真正看音乐剧，第一部剧应该是Rent，其实应该也是Seasons of love吸引我去看的这部剧，真的入股不亏！\n\n\n\n## 大学\n\n  延续了高中的音乐剧，时间、资源充足所以较大量看剧，歌单几乎全是宽街原声。\n\n  大一考试周狠狠emo开始听五月天，也开始从网易云过渡到QQ音乐和Spotify，直到现在。\n\n\n\n## Some thoughts\n\n* 音乐真的是很私人的东西，每个人的口味都不太相同，献上我给朋友推荐音乐剧的图。\n\n  <img src=\"https://raw.githubusercontent.com/Mooyi646/ImageSaver/main/202207271017461.jpg\" alt=\"img\" style=\"zoom: 50%;\" />\n\n* 所有音乐都不分高低贵贱，自己喜欢即可。\n\n* 音乐口味的变化真的很神奇，现在去听我高一的歌单，我甚至会生出”我当时怎么去听这首歌并把它加入我的歌单“的想法。\n\n\n\n希望所有人都能找到自己喜欢的音乐！;-)","tags":["thoughts","Music"],"categories":["Let's think","Music"]},{"title":"关于拖延以及失去动力","url":"/post/72693323.html","content":"\n  这是从大二上一直到这学期期末周末尾都给自己定下的目标，没有想过现在才实现，也没有想过现在居然实现了。\n\n <!-- more -->\n\n  上大学以来一直都是行动力底下。高中的自己还能夸夸自己说“我觉得我的自制力还算不错啊”，到大学过后，从不敢说出这话了。\n\n  两年了，说什么事情也没做成的话，倒也是给自己的人生转了个弯。从工商管理大类到了如今的软工，你说没付出努力，别人说你骗谁呢，说我真的努力了啊，我说这是骗自己啊。\n\n  经常会想到底是什么让我失去了动力，亦或者说是向上的精神与对等的行动。我不知道。高中真的算是过得最快乐的三年的吧，中考的幸运延续，使得高中初始就算站在了还不错的起点，然后一直保持，偶尔徘徊，偶尔向上，总体都还算不错，为什么大学就截然不同了呢？或许是我没有从一开始就在相对的高处吧，我又怎么能够站得到高处呢？\n\n  总归是絮絮叨叨，实力与行动配不上自己的“野心”，确实是“卷也卷不赢，摆也不敢摆”。","tags":["thoughts","doer","procrastination"],"categories":["Let's think","Life"]}]